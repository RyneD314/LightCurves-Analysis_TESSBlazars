{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dee3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lc_analysis.py\n",
    "\n",
    "Created 08/2022\n",
    "\n",
    "Original Author: Ryne Dingler\n",
    "\n",
    "Some functions useful for operations are obtained from \n",
    "Connolly 2015: http://arxiv.org/abs/1503.06676\n",
    "\n",
    "Python version of the light curve variability statistic algorithm from \n",
    "Dingler & Smith 2023.\n",
    "\n",
    "\n",
    "requires:\n",
    "    os, sys, numpy, scipy, pandas, csv, matplotlib\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize as op\n",
    "import scipy.special as sp\n",
    "import scipy.constants as cst\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats as st\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "plt.style.use('tableau-colorblind10')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2e26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition of various functions which are used to fit distribution models and linear fits \n",
    "'''\n",
    "\n",
    "def linear(x,m,b):\n",
    "    return(m*x+b)\n",
    "\n",
    "def gaussian(x, A, μ, σ):\n",
    "    return(A * np.exp(-(x - μ)**2 / (2*σ**2)))\n",
    "\n",
    "# def gaussian_adv(x, A, μ, σ):\n",
    "#     return((A/(np.sqrt(2*np.pi)*σ)) * np.exp(-(x - μ)**2 / (2*σ**2)))\n",
    "\n",
    "def lognormal(x, A, μ, σ):\n",
    "    return(gaussian(np.log(x), A, μ, σ)/x)\n",
    "\n",
    "def bimodal(x, p, A, μ1, σ1, B, μ2, σ2):\n",
    "    ϕ = 0.5 + np.arctan(p)/np.pi\n",
    "    return(ϕ * gaussian(x, A, μ1, σ1) + (1-ϕ) * gaussian(x, B, μ2,σ2))\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "###########################################################################################################\n",
    "'''\n",
    "Definition of various functions regarding rounding \n",
    "'''\n",
    "\n",
    "def roundedfractionalrange(arr,fraction = 0.5):\n",
    "    \"\"\"\n",
    "    Returns a value for fractional length of an array.\n",
    "    \"\"\"\n",
    "    return(int(fraction*len(arr) + 0.5))\n",
    "\n",
    "def round_up_decimals(num:float, dec:int):\n",
    "    \"\"\"\n",
    "    Returns a value rounded up to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    round_good = False\n",
    "    count = 0\n",
    "    while round_good == False:\n",
    "\n",
    "        if not isinstance(dec, int) or dec < 0:\n",
    "            raise TypeError(\"decimal places must be a positive integer\")\n",
    "            if count != 0:\n",
    "                dec = int(input(\"round to how many decimal places? \"))\n",
    "        elif dec == 0:\n",
    "            return(np.ceil(num))\n",
    "            round_good = True\n",
    "        else:\n",
    "            round_good = True\n",
    "        count += 1   \n",
    "\n",
    "    scale = 10**dec\n",
    "    return(np.ceil(num * scale) / scale)\n",
    "\n",
    "\n",
    "def ticklabels(bin_center):\n",
    "    \n",
    "    tick_labels = [str(np.round(x,decimals=2)) for x in bin_center]\n",
    "    \n",
    "    n = 3    \n",
    "    while len(np.unique(np.array(tick_labels, dtype = float))) != len(bin_center):\n",
    "        tick_labels = [str(np.round(x,decimals=n)) for x in bin_center]\n",
    "        n += 1\n",
    "        \n",
    "    return(tick_labels)\n",
    "###########################################################################################################\n",
    "###########################################################################################################\n",
    "###########################################################################################################\n",
    "def Min_PDF(params,hist,model,force_scipy=True):\n",
    "    '''\n",
    "    PDF chi squared function allowing the fitting of a mixture distribution\n",
    "    using a log normal distribution and a gamma distribution\n",
    "    to a histogram of a data set.\n",
    "    \n",
    "    inputs:\n",
    "        params (array)   - function variables - kappa, theta, lnmu,lnsig,weight\n",
    "        hist (array)     - histogram of data set (using numpy.hist)\n",
    "        force_scipy (bool,optional) - force the function to assume a scipy model\n",
    "    outputs:\n",
    "        chi (float) - chi squared\n",
    "        \n",
    "    Ref: Connolly 2015\n",
    "    '''\n",
    "\n",
    "    mids = (hist[1][:-1]+hist[1][1:])/2.0\n",
    "\n",
    "    try:\n",
    "        if model.__name__ == 'Mixture_Dist':\n",
    "            model = model.Value\n",
    "            m = model(mids,params)\n",
    "        elif model.__module__ == 'scipy.stats.distributions' or \\\n",
    "            model.__module__ == 'scipy.stats._continuous_distns' or \\\n",
    "                force_scipy == True:\n",
    "            m = model.pdf    \n",
    "        else:    \n",
    "            m = model(mids,*params)\n",
    "    except AttributeError:\n",
    "        m = model(mids,*params)\n",
    "    \n",
    "    chi = (hist[0] - m)**2.0\n",
    "    \n",
    "    return(np.sum(chi))\n",
    "\n",
    "def OptBins(data, maxbinS=10, maxbinL=20, minbin = 7):\n",
    "    '''\n",
    "     Python version of the 'optBINS' algorithm by Knuth et al. (2006) - finds \n",
    "     the optimal number of bins for a one-dimensional data set using the \n",
    "     posterior probability for the number of bins. WARNING sometimes doesn't\n",
    "     seem to produce a high enough number by some way...\n",
    "    \n",
    "     inputs:\n",
    "         data (array)           - The data set to be binned\n",
    "         maxM (int, optional)   - The maximum number of bins to consider\n",
    "         \n",
    "     outputs:\n",
    "        Opt (int)           - The optimum number of bins\n",
    "    \n",
    "     Ref: Connolly 2015, K.H. Knuth. 2012. Optimal data-based binning for histograms\n",
    "     and histogram-based probability density models, Entropy.\n",
    "     Ref: Shimazaki 2007. Neural Comput 19 1503-1527, 2007\n",
    "    '''\n",
    "    def posterior_opt(binM,data):\n",
    "        logp = []\n",
    "        for M in binM:\n",
    "            n = np.histogram(data,bins=M)[0] # Bin the data (equal width bins)\n",
    "\n",
    "            # calculate posterior probability\n",
    "            part1 = N * np.log(M) + sp.gammaln(M/2.)\n",
    "            part2 = - M * sp.gammaln(0.5)  - sp.gammaln(N + M/2.)\n",
    "            part3 = np.sum(sp.gammaln(n+0.5))\n",
    "            logp.append(part1 + part2 + part3) # add to array of posteriors\n",
    "        \n",
    "        Opt = int(binM[np.argmax(logp)]+0.5)\n",
    "        return(Opt)\n",
    "    \n",
    "    def shimizaki_opt(binM,data):\n",
    "        C = []\n",
    "        for M in binM:\n",
    "            n, bins = np.histogram(data,bins=M) # Bin the data (equal width bins)\n",
    "            width = bins[1] - bins[0]\n",
    "\n",
    "            k = np.nanmean(n)\n",
    "            v = np.nanstd(n)\n",
    "\n",
    "            # calculate posterior probability\n",
    "            numer = 2*k - v\n",
    "            denom = width**2\n",
    "            C.append(numer/denom) # add to array of posteriors\n",
    "        \n",
    "        Opt = int(binM[np.argmin(C)]+0.5)\n",
    "        return(Opt)\n",
    "    \n",
    "       \n",
    "    \n",
    "    N = len(data)\n",
    "\n",
    "    Sqrt = int(np.ceil(np.sqrt(N)))\n",
    "    Sturge = int(np.ceil(np.log2(N)) + 1.5)\n",
    "    Rice = int(np.ceil(2*N**(1./3.)))\n",
    "    \n",
    "    skew = st.skew(data)\n",
    "    try:\n",
    "        Doane = int(1.5+ np.log2(N) + np.log2(1. + np.abs(skew)/np.sqrt(6.*(N-2.)/((N+1.)*(N+3.)))))\n",
    "    except:\n",
    "        Doane = minbin\n",
    "    \n",
    "    std = np.nanstd(data)\n",
    "    try:\n",
    "        Scott = int(0.5 + (N**(1./3.)*(np.nanmax(data) - np.nanmin(data))/(3.5*std)))\n",
    "    except:\n",
    "        Scott = minbin\n",
    "    \n",
    "    iqr = np.quantile(data,0.75) - np.quantile(data,0.25)\n",
    "    try:\n",
    "        FD = int(0.5 + (N**(1./3.)*(np.nanmax(data) - np.nanmin(data)) / (2.*iqr)))\n",
    "    except:\n",
    "        FD = minbin\n",
    "    \n",
    "    minM = np.nanmin([Sqrt,Sturge,Rice,Doane,Scott,FD])\n",
    "    if minM < minbin:\n",
    "        minM = minbin\n",
    "    maxM = np.nanmax([Sqrt,Sturge,Rice,Doane,Scott,FD])\n",
    "    if maxM < minbin:\n",
    "        maxM = minbin\n",
    "\n",
    "    binM = range(minM,maxM+1)\n",
    "          \n",
    "    if N >= 150:  \n",
    "        if minM != maxM:\n",
    "            return(posterior_opt(binM,data)) #find bin number of maximum probability\n",
    "        else:\n",
    "            return(posterior_opt(range(minbin,maxbinL),data))\n",
    "    else:\n",
    "        if minM != maxM:\n",
    "            return(shimizaki_opt(binM,data)) #find bin number of maximum probability\n",
    "        else:\n",
    "            return(shimizaki_opt(range(minbin,maxbinS),data))\n",
    "\n",
    "###########################################################################################################\n",
    "###########################################################################################################\n",
    "\n",
    "def check_col_label(rootdir,bin1,bin2,sample = \"\", raw = False):\n",
    "    '''\n",
    "    Make sure data file to save results exists and has proper headers\n",
    "    \n",
    "    inputs:\n",
    "        rootdir (directory)       - The directory in which figures will be saved\n",
    "        bin1 (string)             - string which specified how many hours for one binning schema\n",
    "        bin2 (string)             - string which specified how many hours for one binning schema\n",
    "        sample (string)           - user-specified sample selection\n",
    "        raw (boolean)             - whether or not raw light curve is available\n",
    "         \n",
    "   '''\n",
    "    \n",
    "    col_title = False\n",
    "    try:\n",
    "        if sample ==\"analysis\":\n",
    "            lc_data = open(os.path.join(rootdir,'LC_variability_analysis.csv') , \"r+\", newline='', encoding='utf-8')\n",
    "        elif sample ==\"removed\":\n",
    "            lc_data = open(os.path.join(rootdir,'LC_variability_rmv.csv') , \"r+\", newline='', encoding='utf-8')\n",
    "\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        if sample ==\"analysis\":\n",
    "            lc_data = open(os.path.join(rootdir,'LC_variability_analysis.csv') , \"w\", newline='', encoding='utf-8')\n",
    "            print(\"\\nCreating file 'LC_variability_analysis.csv'\\n\")\n",
    "        elif sample ==\"removed\":\n",
    "            lc_data = open(os.path.join(rootdir,'LC_variability_rmv.csv') , \"w\", newline='', encoding='utf-8')\n",
    "            print(\"\\nCreating file 'LC_variability_rmv.csv'\\n\")\n",
    "        \n",
    "        \n",
    "        if raw == True:\n",
    "            header = ['Target','<F>(raw)','σ_F(raw)','<ΔF>(raw)', 'σ_ΔF(raw)',\\\n",
    "                      '<F>(unbinned)', 'σ_F(unbinned)','<ΔF>(unbinned)','σ_ΔF(unbinned)',\\\n",
    "                      '<F>('+bin1+'hr)','σ_F('+bin1+'hr)','<ΔF>('+bin1+'hr)','σ_ΔF('+bin1+'hr)',\\\n",
    "                      '<F>('+bin2+'hr)','σ_F('+bin2+'hr)','<ΔF>('+bin2+'hr)','σ_ΔF('+bin2+'hr)',\\\n",
    "                      'σ^2_XS(unbinned)','err(σ^2_XS)(unbinned)',\\\n",
    "                      'σ^2_XS('+bin1+'hr)','err(σ^2_XS)('+bin1+'hr)',\\\n",
    "                      'σ^2_XS('+bin2+'hr)','err(σ^2_XS)('+bin2+'hr)',\\\n",
    "                      'σ_rms(unbinned)','err(σ_rms)(unbinned)',\n",
    "                      'σ_rms('+bin1+'hr)','err(σ_rms)('+bin1+'hr)',\n",
    "                      'σ_rms('+bin2+'hr)','err(σ_rms)('+bin2+'hr)',\\\n",
    "                      'm1','r2_1','m2','r2_2','m3','r2_3','m4','r2_4',\\\n",
    "                      'τ_inc(days)','σ_τ,inc(days)','Δt_inc(days)','τ_exp,inc(days)',\\\n",
    "                      'τ_dec(days)','σ_τ,dec(days)','Δt_dec(days)','τ_exp,dec(days)',\\\n",
    "                      'δ','R_min(km,10^8 Ms)', 'R(km,10^8 Ms)', 'R_max(km,10^8 Ms)',\\\n",
    "                      'Rs_min (10^8 Ms)', 'Rs (10^8 Ms)', 'Rs_max (10^8 Ms)',\\\n",
    "                      'χ^2','dof','χ^2/dof']\n",
    "                                    \n",
    "                                    \n",
    "        \n",
    "        elif raw == False:\n",
    "            header = ['Target','<F>(unbinned)', 'σ_F(unbinned)','<ΔF>(unbinned)','σ_ΔF(unbinned)',\\\n",
    "                      '<F>('+bin1+'hr)','σ_F('+bin1+'hr)','<ΔF>('+bin1+'hr)','σ_ΔF('+bin1+'hr)',\\\n",
    "                      '<F>('+bin2+'hr)','σ_F('+bin2+'hr)','<ΔF>('+bin2+'hr)','σ_ΔF('+bin2+'hr)',\\\n",
    "                      'σ^2_XS(unbinned)','err(σ^2_XS)(unbinned)',\\\n",
    "                      'σ^2_XS('+bin1+'hr)','err(σ^2_XS)('+bin1+'hr)',\\\n",
    "                      'σ^2_XS('+bin2+'hr)','err(σ^2_XS)('+bin2+'hr)',\\\n",
    "                      'σ_rms(unbinned)','err(σ_rms)(unbinned)',\n",
    "                      'σ_rms('+bin1+'hr)','err(σ_rms)('+bin1+'hr)',\n",
    "                      'σ_rms('+bin2+'hr)','err(σ_rms)('+bin2+'hr)',\\\n",
    "                      'm1','r2_1','m2','r2_2','m3','r2_3','m4','r2_4',\\\n",
    "                      'τ_inc(days)','σ_τ,inc(days)','Δt_inc(days)','τ_exp,inc(days)',\\\n",
    "                      'τ_dec(days)','σ_τ,dec(days)','Δt_dec(days)','τ_exp,dec(days)',\\\n",
    "                      'δ','R_min(km,10^8 Ms)', 'R(km,10^8 Ms)', 'R_max(km,10^8 Ms)',\\\n",
    "                      'Rs_min (10^8 Ms)', 'Rs (10^8 Ms)', 'Rs_max (10^8 Ms)',\\\n",
    "                      'χ^2','dof','χ^2/dof']\n",
    "\n",
    "\n",
    "        \n",
    "        writer = csv.writer(lc_data)\n",
    "#         header = [x.encode('utf-8') for x in header]\n",
    "        writer.writerow(header)\n",
    "\n",
    "    lc_data.close()\n",
    "\n",
    "\n",
    "    return()\n",
    "###########################################################################################################\n",
    "###########################################################################################################\n",
    "'''\n",
    "Definition of various functions regarding statistical tests \n",
    "'''\n",
    "\n",
    "def chisquare_per_dof(observed,expected,error):\n",
    "    '''\n",
    "    Chi-squared per degree of freedom test\n",
    "    \n",
    "    inputs:\n",
    "        observed (array or float)    - observed test values\n",
    "        expected (array or float)    - theoretical values\n",
    "        error (array or float)       - observed error on test values\n",
    "    outputs:\n",
    "        test_statistic (float)       - chi-square statistic \n",
    "        dof (float)                  - length of array\n",
    "        test_statistic/dof (float)   - chi-square per dof\n",
    "    '''\n",
    "    \n",
    "    index = np.array(list(np.where(error != 0)[0]), dtype = 'int')\n",
    "    test_statistic = []\n",
    "    for idx in index:\n",
    "        test_statistic.append(np.subtract(observed,expected)[idx]**2 / error[idx]**2)\n",
    "        \n",
    "    dof=len(test_statistic)-1\n",
    "    test_statistic = np.nansum(test_statistic)\n",
    "\n",
    "    return(test_statistic, dof, test_statistic/dof)\n",
    "\n",
    "\n",
    "def shortest_timescale(rootdir, target, uninterp_df, z, sectbysect = False, sectors = ''): \n",
    "    '''\n",
    "    Find shortest timescale for exponential rise and decay for significant flux change\n",
    "    with decreasing iterative kernel smoothing. Smoothing aid in the reduction of single\n",
    "    cadence flares; however, may eliminate significant flux change, hence the decreasing iterations.\n",
    "    \n",
    "    inputs:\n",
    "         rootdir (directory)          - The directory in which lcs are stored\n",
    "         target (string)              - Name of desired object to analyze\n",
    "         uninterp_df (DataFrame)      - Number of lcs (default = 501)\n",
    "         z (float)                    - redshift\n",
    "         sectbysect (boolean)         - sector by sector analysis or not (default is False)\n",
    "         secors (string)              - current sectors under analysis if sectbysect is True\n",
    "         \n",
    "     outputs:\n",
    "        tau_dec_min (float)           - shortest timescale of variability for decreasing flux\n",
    "        err_tau_dec (float)           - error on tau\n",
    "        delt_dec_min (float)          - assosiacted time seperation for timescale \n",
    "        timescale_dec_min (float)     - shortest timescale of exponential decay\n",
    "        tau_inc_min (float)           - shortest timescale of variability for increasing flux\n",
    "        err_tau_dec (float)           - error on tau\n",
    "        delt_inc_min (float)          - assosiacted time seperation for timescale\n",
    "        timescale_inc_min (float)     - shortest timescale of exponential growth\n",
    "    \n",
    "     Ref:  Chaterjee et al 2021\n",
    "    '''\n",
    "    \n",
    "    nonzeroflux = np.nonzero(np.array(uninterp_df[1]))[0]\n",
    "    time = np.divide(np.array(uninterp_df[0][nonzeroflux]),1.+z)\n",
    "    print(\"adjusting time with redshift z = %.3f\"%z)\n",
    "    unfiltered_flux = np.array(uninterp_df[1][nonzeroflux])\n",
    "    flux = []\n",
    "    err = np.array(uninterp_df[2][nonzeroflux])\n",
    "\n",
    "    tau_dec_min = np.inf\n",
    "    tau_inc_min = np.inf\n",
    "    \n",
    "    err_tau_dec = 0.\n",
    "    err_tau_inc = 0.\n",
    "    \n",
    "    delt_dec_min = 0.\n",
    "    delt_inc_min = 0.\n",
    "    timescale_dec_min = 0.\n",
    "    timescale_inc_min = 0.\n",
    "    \n",
    "    t1_dec = 0\n",
    "    f1_dec = 0\n",
    "    e1_dec = 0\n",
    "    t2_dec = 0\n",
    "    f2_dec = 0\n",
    "    e2_dec = 0\n",
    "    \n",
    "    t1_inc = 0\n",
    "    f1_inc = 0\n",
    "    e1_inc = 0\n",
    "    t2_inc = 0\n",
    "    f2_inc = 0\n",
    "    e2_inc = 0\n",
    "    \n",
    "    FWHM = 2\n",
    "    \n",
    "    long_time  = float(time[-1] - time[0])\n",
    "    print(\"Full light curve length %.2f days\"%long_time)\n",
    "    less_than_time = True\n",
    "    \n",
    "    while tau_dec_min == np.inf or tau_inc_min == np.inf:\n",
    "        print(\"\\nSmoothing light curve with FWHM = %i\"%FWHM)\n",
    "        flux = np.array(gaussian_filter(unfiltered_flux,sigma=FWHM))\n",
    "        for i in range(0,len(time)-1):\n",
    "            tmp_time = time[i]\n",
    "            tmp_flux = flux[i]\n",
    "            tmp_rflux = unfiltered_flux[i]\n",
    "            tmp_err = err[i]\n",
    "\n",
    "            if i%500 == 0.:\n",
    "                print(\"Comparing point %i\"%i)\n",
    "\n",
    "            delt = np.subtract(time[i+1:],tmp_time)\n",
    "            min_delt = time[1]-time[0]\n",
    "            delf = np.subtract(flux[i+1:],tmp_flux)\n",
    "\n",
    "            denom = np.log(np.divide(unfiltered_flux[i+1:],tmp_rflux))\n",
    "            timescale = np.abs(np.divide(delt,denom))\n",
    "            tau = np.log(2)*timescale\n",
    "\n",
    "            stats = np.column_stack((delt,delf,tau,timescale))\n",
    "\n",
    "            delt_dec = [w for w,x,y,z in stats if w >= min_delt and x < -3.*tmp_err and np.isfinite(y)]\n",
    "            delf_dec = [x for w,x,y,z in stats if w >= min_delt and x < -3.*tmp_err and np.isfinite(y)]\n",
    "            tau_dec = [y for w,x,y,z in stats if w >= min_delt and x < -3.*tmp_err and np.isfinite(y)]\n",
    "            timescale_dec = [z for w,x,y,z in stats if w >= min_delt and x < -3.*tmp_err and np.isfinite(y)]\n",
    "            \n",
    "            delt_inc = [w for w,x,y,z in stats if w>= min_delt and x > 3.*tmp_err and np.isfinite(y)]\n",
    "            delf_inc = [x  for w,x,y,z in stats if w >= min_delt and x > 3.*tmp_err and np.isfinite(y)]\n",
    "            tau_inc = [y  for w,x,y,z in stats if w >= min_delt and x > 3.*tmp_err and np.isfinite(y)]\n",
    "            timescale_inc = [z for w,x,y,z in stats if w >= min_delt and x > 3.*tmp_err and np.isfinite(y)]\n",
    "\n",
    "\n",
    "            if len(tau_dec) != 0:\n",
    "                if np.nanmin(tau_dec) < tau_dec_min:\n",
    "                    tau_dec_min = np.nanmin(tau_dec)\n",
    "                    delt_dec_min = delt_dec[np.where(tau_dec == tau_dec_min)[0][0]]\n",
    "                    timescale_dec_min = timescale_dec[np.where(tau_dec == tau_dec_min)[0][0]]\n",
    "                    \n",
    "                    t1_dec = tmp_time\n",
    "                    f1_dec = tmp_rflux\n",
    "                    e1_dec = tmp_err\n",
    "                    t2_idx = np.where(time == t1_dec+delt_dec_min)[0][0]\n",
    "                    t2_dec = time[t2_idx]\n",
    "                    f2_dec = unfiltered_flux[t2_idx]\n",
    "                    e2_dec =  err[t2_idx]\n",
    "                        \n",
    "                    \n",
    "                    root = np.sqrt((e1_dec/f1_dec)**2 + (e2_dec/f2_dec)**2)\n",
    "                    denom = (np.log(2)*delt_dec_min)/tau_dec_min\n",
    "                    err_tau_dec = tau_dec_min*root/denom\n",
    "\n",
    "            if len(tau_inc) != 0:\n",
    "                if np.nanmin(tau_inc) < tau_inc_min:\n",
    "                    tau_inc_min = np.nanmin(tau_inc)\n",
    "                    delt_inc_min = delt_inc[np.where(tau_inc == tau_inc_min)[0][0]]\n",
    "                    timescale_inc_min = timescale_inc[np.where(tau_inc == tau_inc_min)[0][0]]\n",
    "                        \n",
    "                    t1_inc = tmp_time\n",
    "                    f1_inc = tmp_rflux\n",
    "                    e1_inc = tmp_err\n",
    "                    t2_idx = np.where(time == t1_inc+delt_inc_min)[0][0]\n",
    "                    t2_inc = time[t2_idx]\n",
    "                    f2_inc = unfiltered_flux[t2_idx]\n",
    "                    e2_inc = err[t2_idx]\n",
    "                    \n",
    "                    root = np.sqrt((e1_inc/f1_inc)**2 + (e2_inc/f2_inc)**2)\n",
    "                    denom = (np.log(2)*delt_inc_min)/tau_inc_min\n",
    "                    err_tau_inc = tau_inc_min*root/denom\n",
    "\n",
    "\n",
    "        print(\"tau_inc = %.2f +/- %.2e days;\\n tau_dec = %.2f +/- %.2e days\\n\"%(tau_inc_min,err_tau_inc,\\\n",
    "                                                                                tau_dec_min,err_tau_dec))\n",
    "        if (less_than_time) & (FWHM != 0) & (tau_inc_min > long_time or tau_dec_min > long_time):\n",
    "            tau_inc_min = np.inf \n",
    "            tau_dec_min = np.inf\n",
    "            \n",
    "        if tau_inc_min != np.inf and tau_dec_min != np.inf:\n",
    "            break\n",
    "        elif FWHM == 0:\n",
    "            if tau_inc_min == np.inf or tau_dec_min == np.inf:\n",
    "                FWHM = 2\n",
    "                less_than_time = False\n",
    "                continue\n",
    "        \n",
    "        FWHM-=1\n",
    "                    \n",
    "    plt.figure(figsize=(25,6))\n",
    "    plt.title(target+\": shortest timescales of variability, increasing and decreasing flux\")\n",
    "    plt.errorbar(time,unfiltered_flux,yerr=err, color = 'k', alpha = 0.75, linestyle = 'None')\n",
    "    plt.vlines((t1_dec,t2_dec), np.nanmin(flux)-6, np.nanmax(flux)+6,color = 'r', label = r\"$τ_{dec}$ = %.3f\"%tau_dec_min)\n",
    "    plt.vlines((t1_inc,t2_inc), np.nanmin(flux)-6, np.nanmax(flux)+6,color = 'b', label = r\"$τ_{inc}$ = %.3f\"%tau_inc_min)\n",
    "    \n",
    "    if FWHM == 0:\n",
    "        plt.plot(time,flux, label = 'Running average')\n",
    "    else:\n",
    "        plt.plot(time,flux, label = r'Smoothed lc $\\sigma$=%i'%FWHM)\n",
    "    plt.ylim(np.nanmin(flux)-5, np.nanmax(flux)+5)\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.tight_layout()\n",
    "    if sectbysect == True:\n",
    "        plt.savefig(rootdir+target+'/exponential_rise&decay_timescales/'+target+'_sectors'+sectors+'_shortest_timescales_smoothedlc.png')\n",
    "    else:\n",
    "        plt.savefig(rootdir+target+'/exponential_rise&decay_timescales/'+target+'_shortest_timescales_smoothedlc.png')\n",
    "#         plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(target+\": shortest timescales of variability, increasing and decreasing flux\")\n",
    "    plt.errorbar(time,unfiltered_flux,yerr=err, color = 'k', alpha = 0.75, linestyle = 'None')\n",
    "    plt.vlines((t1_dec,t2_dec), np.nanmin(flux)-6, np.nanmax(flux)+6,color = 'r', label = r\"$τ_{dec}$ = %.3f\"%tau_dec_min)\n",
    "    \n",
    "    if FWHM == 0:\n",
    "        plt.plot(time,flux, label = 'Running average')\n",
    "    else:\n",
    "        plt.plot(time,flux, label = r'Smoothed lc $\\sigma$=%i'%FWHM)\n",
    "    plt.xlim(t1_dec-0.5,t2_dec+0.5)\n",
    "    plt.ylim(np.nanmin(flux)-5, np.nanmax(flux)+5)\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.tight_layout()\n",
    "    if sectbysect == True:\n",
    "        plt.savefig(rootdir+target+'/exponential_rise&decay_timescales/'+target+'_sectors'+sectors+'_shortest_decaytimescale_smoothedlc.png')\n",
    "    else:\n",
    "        plt.savefig(rootdir+target+'/exponential_rise&decay_timescales/'+target+'_shortest_decaytimescale_smoothedlc.png')\n",
    "#         plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(target+\": shortest timescales of variability, increasing and decreasing flux\")\n",
    "    plt.errorbar(time,unfiltered_flux,yerr=err, color = 'k', alpha = 0.75, linestyle = 'None')\n",
    "    plt.vlines((t1_inc,t2_inc), np.nanmin(flux)-6, np.nanmax(flux)+6,color = 'b', label = r\"$τ_{inc}$ = %.3f\"%tau_inc_min)\n",
    "    if FWHM == 0:\n",
    "        plt.plot(time,flux, label = 'Running average')\n",
    "    else:\n",
    "        plt.plot(time,flux, label = r'Smoothed lc $\\sigma$=%i'%FWHM)\n",
    "    plt.xlim(t1_inc-0.5,t2_inc+0.5)\n",
    "    plt.ylim(np.nanmin(flux)-5, np.nanmax(flux)+5)\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.tight_layout()\n",
    "    if sectbysect == True:\n",
    "        plt.savefig(rootdir+target+'/exponential_rise&decay_timescales/'+target+'_sectors'+sectors+'_shortest_growthtimescale_smoothedlc.png')\n",
    "    else:\n",
    "        plt.savefig(rootdir+target+'/exponential_rise&decay_timescales/'+target+'_shortest_growthtimescale_smoothedlc.png')\n",
    "#         plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    return(tau_dec_min, err_tau_dec, delt_dec_min, timescale_dec_min,\\\n",
    "           tau_inc_min, err_tau_inc, delt_inc_min, timescale_inc_min)\n",
    "\n",
    "###########################################################################################################\n",
    "def excess_variance(flux,err, mean = 0., std = 0.):\n",
    "    '''\n",
    "    inputs:\n",
    "         flux (array)             - array of flux from the light curve (or segment)\n",
    "         err (array)              - array of error from the light curve (or segment)\n",
    "         \n",
    "    outputs:\n",
    "        sig2_rms (float)          - RMS-scatter\n",
    "        sig2_rms_err (float)      - Error for RMS-scatter\n",
    "    '''\n",
    "    \n",
    "    len_flux = len(flux)\n",
    "\n",
    "    if mean == 0.:\n",
    "        mean_flux = np.nanmean(flux)\n",
    "        samp_var = np.nanvar(flux,ddof = 1)\n",
    "    else:\n",
    "        mean_flux = mean\n",
    "        samp_var = std**2\n",
    "        \n",
    "    mean_square_err = np.nanmean(err**2.)\n",
    "    err_err = np.sqrt(np.nanvar(err**2.)/len_flux)    \n",
    "    \n",
    "    if samp_var <= mean_square_err:\n",
    "        return(0.,0.)\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            sig2_XS = np.subtract(samp_var,mean_square_err)\n",
    "            sig2_XS_err = np.sqrt((2./len_flux)*mean_square_err**2 + (4./len_flux)*mean_square_err*sig2_XS)\n",
    "        except:\n",
    "            return(0.,0.)\n",
    "            \n",
    "        return(sig2_XS,sig2_XS_err)\n",
    "\n",
    "\n",
    "def calc_excess_variance(time, flux, err, flux_mean = 0., stdev = 0., len_lc = 0.,\\\n",
    "                    MSE = 0., MSE_err = 0., total=True, normalize = True):\n",
    "    '''\n",
    "    Find excess variance and rms-scatter for either the \n",
    "    entire light curve or within user-specified bins\n",
    "    \n",
    "    inputs:\n",
    "         time (array)             - array of time from the light curve (or segment)\n",
    "         flux (array)             - array of flux from the light curve (or segment)\n",
    "         err (array)              - array of error from the light curve (or segment)\n",
    "         stdev (float)            - standard deviation of entire flux sample\n",
    "         len_lc (float)           - length of the light curve (or segment)\n",
    "         MSE (float or array)     - mean squared error from of error from the light curve (or segment)\n",
    "         total (boolean)          - indicator if analyzing the total light curve or analyzing intrabin\n",
    "         normalize (boolean)      - indicator if excess variance is to be normalized\n",
    "         \n",
    "     outputs (total = False):\n",
    "        Xvar (float)              - Excess Variance\n",
    "        RMSvar (float)            - RMS-scatter\n",
    "        XvarErr (float)           - error on Excess Variance\n",
    "        RMSvarErr (float)         - error on RMS-scatter\n",
    "        \n",
    "    `outputs (total = True, normalize = True):\n",
    "        Xvar (float)             - Excess Variance\n",
    "        RMSvar (float)           - RMS-scatter\n",
    "        XvarErr (float)          - error on Excess Variance\n",
    "        RMSvarErr (float)        - error on RMS-scatter\n",
    "    \n",
    "     Ref:  Chaterjee et al 2021\n",
    "    '''\n",
    "    \n",
    "    nonzeroflux = np.nonzero(np.array(flux))[0]\n",
    "    time = np.array(time[nonzeroflux])\n",
    "    flux = np.array(flux[nonzeroflux])\n",
    "    err = np.array(err[nonzeroflux])\n",
    "    \n",
    "\n",
    "    if total == True:\n",
    "        \n",
    "        len_lc = len(flux)\n",
    "        MSE = np.nanmean(err**2.)\n",
    "        \n",
    "        if flux_mean == np.nanmean(flux):\n",
    "            Xvar, XvarErr = excess_variance(flux,err)\n",
    "        else:\n",
    "            Xvar, XvarErr = excess_variance(flux,err, mean = flux_mean, std = stdev)\n",
    "        \n",
    "        \n",
    "        RMSvar = np.sqrt(Xvar)\n",
    "        if Xvar > 0.:\n",
    "            RMSvarErr = XvarErr/(2.*RMSvar)\n",
    "        else:\n",
    "            RMSvarErr = 0.\n",
    "\n",
    "        return(Xvar, RMSvar, XvarErr, RMSvarErr)      \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        Xvar = np.subtract(stdev**2,MSE)\n",
    "        \n",
    "        RMSvar = np.sqrt(Xvar)\n",
    "        \n",
    "        idx = np.where(np.isfinite(np.array(RMSvar)) & np.isreal(np.array(RMSvar)))[0]\n",
    "        \n",
    "        XvarErr = np.sqrt(np.divide(np.multiply(2.,\\\n",
    "                        MSE[idx]**2),len_lc[idx]) + np.divide(np.multiply(4.,\\\n",
    "                                                    np.multiply(MSE[idx],Xvar[idx])),len_lc[idx]))               \n",
    "        \n",
    "        RMSvarErr = np.divide(XvarErr,np.multiply(2.,RMSvar[idx]))\n",
    "\n",
    "        for i in range(0,len(Xvar)):\n",
    "            if Xvar[i] < 0.:\n",
    "                Xvar[i] = 0.\n",
    "                RMSvar[i] = 0.\n",
    "                XvarErr[i] = 0\n",
    "                RMSvarErr[i] = 0.\n",
    "                         \n",
    "        return(Xvar,RMSvar, XvarErr, RMSvarErr)\n",
    "   \n",
    "            \n",
    "###########################################################################################################################################\n",
    "        \n",
    "def plot_excess_variance(subdir, df, binneddf, Xvar, XvarErr, Xvar_mean,\\\n",
    "                         RMSvar, RMSvarErr, RMSvar_mean, bin_time, sectbysect, group):\n",
    "    \n",
    "    '''\n",
    "    Plot the light curves, binned light curves, & itrabin excess/rms-scatter, w/ confidence intervals\n",
    "    inputs:\n",
    "        subdir (directory)        - The directory in which figures will be saved\n",
    "        df (DataFrame)            - dataframe containing unbinned light curve data (time,flux,err)\n",
    "        binneddf (DataFrame)      - dataframe containing binned light curve data (time,flux,err)\n",
    "        Xvar (float)              - Excess Variance\n",
    "        XvarErr (float)           - error on Excess Variance\n",
    "        Xvar_mean (float)         - mean of Excess Variance\n",
    "        RMSvar (float)              - rms-scatter\n",
    "        RMSvarErr (float)           - error on rms-scatter\n",
    "        RMSvar_mean (float)         - mean of rms-scatter\n",
    "        bin_time (string)         - string which specified how many hours are in one bin of binned lc\n",
    "        sectbysect (boolean)      - sector by sector analysis or not (default is False)\n",
    "        group (string)            - current sectors under analysis if sectbysect is True\n",
    "        \n",
    "    outputs:\n",
    "        plots: \n",
    "            light curves\n",
    "            binned light curves,\n",
    "            itrabin excess/rms-scatter and confidence intervals\n",
    "\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,10))\n",
    "    gs = gridspec.GridSpec(nrows=4, ncols= 1,hspace=0.0)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    ax0 = fig.add_subplot(gs[0, :])\n",
    "    ax0.errorbar(df[0],df[1],yerr=df[2], linestyle =\"None\", color = 'k')\n",
    "    ax0.set_ylabel(\"F\")\n",
    "    ax0.minorticks_on()\n",
    "    ax0.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "    ax0.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "    ax0.set_title(target+r': $σ_{XS}^{2}$ & $\\sigma_{XS}$, '+bin_time+'hr bins',fontsize='x-large')\n",
    "\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[1, :],sharex=ax0)\n",
    "    ax1.errorbar(binneddf[0],binneddf[1],yerr=np.sqrt(binneddf[2]), linestyle =\"None\",  color = 'k')\n",
    "    ax1.set_ylabel(r\"$\\langle F \\rangle$\")\n",
    "    ax1.minorticks_on()\n",
    "    ax1.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "    ax1.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "\n",
    "    idx = np.where((Xvar != 0.) & (np.isfinite(Xvar)))[0]\n",
    "    ax2 = fig.add_subplot(gs[2, :],sharex=ax1)\n",
    "    ax2.errorbar(binneddf[0][idx], Xvar[idx], yerr = XvarErr[idx], linestyle =\"None\", fmt='+', markersize = 5, color = 'k')\n",
    "    ax2.axhline(Xvar_mean, color = 'k', linestyle = 'solid', label = r'$\\langle σ_{XS}^{2} \\rangle$ = %.2e'%Xvar_mean)\n",
    "    \n",
    "    try:\n",
    "        try:\n",
    "            unique, counts = np.unique(Xvar[idx], return_counts=True)\n",
    "            pk = [x/len(Xvar[idx]) for x in counts]\n",
    "            CI_Xvar = st.rv_discrete(a = -np.inf,values=(unique, pk))  \n",
    "        except:\n",
    "            CI_Xvar = st.rv_discrete(a = -np.inf,values=(Xvar[idx], np.array(len(Xvar[idx])*[1/len(Xvar[idx])])))                       \n",
    "        ax2.fill_between([np.nanmin(binneddf[0][idx])-1, np.nanmax(binneddf[0][idx])+1],\\\n",
    "                         CI_Xvar.interval(0.68)[0], CI_Xvar.interval(0.68)[1], color = 'g', alpha = 0.5)\n",
    "        ax2.fill_between([np.nanmin(binneddf[0][idx])-1, np.nanmax(binneddf[0][idx])+1],\\\n",
    "                         CI_Xvar.interval(0.95)[0], CI_Xvar.interval(0.95)[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "    except:\n",
    "        CI68_Xvar = st.norm.interval(alpha=0.68, loc= Xvar_mean, scale=np.sqrt(np.nanvar(Xvar[idx])))\n",
    "        CI95_Xvar = st.norm.interval(alpha=0.95, loc= Xvar_mean, scale=np.sqrt(np.nanvar(Xvar[idx])))\n",
    "        ax2.fill_between([np.nanmin(binneddf[0][idx])-1, np.nanmax(binneddf[0][idx])+1],\\\n",
    "                         CI68_Xvar[0], CI68_Xvar[1], color = 'g', alpha = 0.5)\n",
    "        ax2.fill_between([np.nanmin(binneddf[0][idx])-1, np.nanmax(binneddf[0][idx])+1],\\\n",
    "                         CI95_Xvar[0], CI95_Xvar[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "    ax2.set_ylabel(r\"$σ_{XS}^{2}$\")\n",
    "    ax2.minorticks_on()\n",
    "    ax2.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "    ax2.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "    ax2.legend(loc = 'upper right')\n",
    "\n",
    "\n",
    "    ax3 = fig.add_subplot(gs[3, :],sharex=ax2)\n",
    "    ax3.errorbar(binneddf[0][idx], RMSvar[idx], yerr= RMSvarErr[idx], linestyle =\"None\", color = 'k')\n",
    "    ax3.axhline(RMSvar_mean, color = 'k', linestyle = 'solid', label = r'$\\langle \\sigma_{rms} \\rangle$ = %.2e'%RMSvar_mean)\n",
    "    ax3.set_ylabel(r\"$\\sigma_{rms}$\")\n",
    "    ax3.minorticks_on()\n",
    "    ax3.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "    ax3.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "    ax3.set_xlabel('Time (BTJD - days)')\n",
    "    ax3.legend(loc = 'upper right')\n",
    "    \n",
    "    RMSvar_finite = [x for x in RMSvar[idx] if np.isfinite(x)]\n",
    "    try:\n",
    "        try:\n",
    "            unique, counts = np.unique(RMSvar_finite , return_counts=True)\n",
    "            pk = [x/len(RMSvar_finite) for x in counts]\n",
    "            CI_RMSvar = st.rv_discrete(a = -np.inf,values=(unique, pk))  \n",
    "        except:\n",
    "            CI_RMSvar = st.rv_discrete(a = -np.inf,values=(RMSvar_finite,np.array(len(RMSvar_finite)*[1/len(RMSvar_finite)])))\n",
    "        ax3.fill_between([np.nanmin(binneddf[0][idx])-1,np.nanmax(binneddf[0][idx])+1],\\\n",
    "                         CI_RMSvar.interval(0.68)[0], CI_RMSvar.interval(0.68)[1], color = 'g', alpha = 0.5)\n",
    "        ax3.fill_between([np.nanmin(binneddf[0][idx])-1,np.nanmax(binneddf[0][idx])+1],\\\n",
    "                         CI_RMSvar.interval(0.95)[0], CI_RMSvar.interval(0.95)[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "    except:\n",
    "        CI68_RMSvar = st.norm.interval(alpha=0.68, loc= RMSvar_mean, scale=np.sqrt(np.nanvar(RMSvar[idx])))\n",
    "        CI95_RMSvar = st.norm.interval(alpha=0.95, loc= RMSvar_mean, scale=np.sqrt(np.nanvar(RMSvar[idx])))\n",
    "        ax3.fill_between([np.nanmin(binneddf[0][idx])-1,np.nanmax(binneddf[0][idx])+1],\\\n",
    "                         CI68_RMSvar[0], CI68_RMSvar[1], color = 'g', alpha = 0.5)\n",
    "        ax3.fill_between([np.nanmin(binneddf[0][idx])-1,np.nanmax(binneddf[0][idx])+1],\\\n",
    "                         CI95_RMSvar[0], CI95_RMSvar[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "    \n",
    "    plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax2.get_xticklabels(), visible=False)\n",
    "    \n",
    "    if sectbysect == True:\n",
    "        plt.savefig(subdir+'/excess_variance/'+target+'_excess_rms_variance_'+bin_time+'hr_sectors'+group+'.pdf', format = 'pdf',bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(subdir+'/excess_variance/'+target+'_excess_rms_variance_'+bin_time+'hr.pdf', format = 'pdf',bbox_inches='tight')\n",
    "#     plt.savefig(subdir+'/'+target+'_excess_rms_variance_'+bin_time+'hr.png', format = 'png',bbox_inches='tight',dpi=1200)\n",
    "    #             plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    try:\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        gs = gridspec.GridSpec(nrows=2, ncols= 1,hspace=0.0)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[0, :])\n",
    "        ax2.errorbar(binneddf[0][idx], Xvar[idx], yerr = XvarErr[idx], linestyle =\"None\", fmt='+', markersize = 4, color = 'k')\n",
    "        ax2.axhline(Xvar_mean, color = 'k', linestyle = 'solid', label = r'$\\langle σ_{XS}^{2} \\rangle$ = %.2e'%Xvar_mean)\n",
    "\n",
    "        # create custom discrete random variable from data set\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                unique, counts = np.unique(Xvar[idx], return_counts=True)\n",
    "                pk = [x/len(Xvar[idx]) for x in counts]\n",
    "                CI_Xvar = st.rv_discrete(a = -np.inf,values=(unique, pk))  \n",
    "            except:\n",
    "                CI_Xvar = st.rv_discrete(a = -np.inf,values=(Xvar[idx], np.array(len(Xvar[idx])*[1/len(Xvar[idx])])))                       \n",
    "            ax2.fill_between([np.nanmin(binneddf[0][idx])-1, np.nanmax(binneddf[0][idx])+1],\\\n",
    "                             CI_Xvar.interval(0.68)[0], CI_Xvar.interval(0.68)[1], color = 'g', alpha = 0.5)\n",
    "            ax2.fill_between([np.nanmin(binneddf[0][idx])-1, np.nanmax(binneddf[0][idx])+1],\\\n",
    "                             CI_Xvar.interval(0.95)[0], CI_Xvar.interval(0.95)[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "        except:\n",
    "            CI68_Xvar = st.norm.interval(alpha=0.68, loc= Xvar_mean, scale=np.sqrt(np.nanvar(Xvar[idx])))\n",
    "            CI95_Xvar = st.norm.interval(alpha=0.95, loc= Xvar_mean, scale=np.sqrt(np.nanvar(Xvar[idx])))\n",
    "            ax2.fill_between([np.nanmin(binneddf[0][idx])-1, np.nanmax(binneddf[0][idx])+1],\\\n",
    "                             CI68_Xvar[0], CI68_Xvar[1], color = 'g', alpha = 0.5)\n",
    "            ax2.fill_between([np.nanmin(binneddf[0][idx])-1, np.nanmax(binneddf[0][idx])+1],\\\n",
    "                             CI95_Xvar[0], CI95_Xvar[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "\n",
    "        ax2.set_ylabel(r\"$σ_{XS}^{2}$\")\n",
    "        ax2.minorticks_on()\n",
    "        ax2.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "        ax2.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "        ax2.set_title(target+r': $σ_{XS}^{2}$ & $\\sigma_{XS}$, '+bin_time+'hr bins',fontsize='x-large')\n",
    "        ax2.legend(loc = 'upper right')\n",
    "\n",
    "        ax3 = fig.add_subplot(gs[1, :],sharex=ax2)\n",
    "        ax3.errorbar(binneddf[0][idx], RMSvar[idx], yerr= RMSvarErr[idx], linestyle =\"None\", color = 'k')\n",
    "        ax3.axhline(RMSvar_mean, color = 'k', linestyle = 'solid', label = r'$\\langle \\sigma_{rms} \\rangle$ = %.2e'%RMSvar_mean)\n",
    "\n",
    "        # create custom discrete random variable from data set\n",
    "        RMSvar_finite = [x for x in RMSvar[idx] if np.isfinite(x)]\n",
    "        try:\n",
    "            try:\n",
    "                unique, counts = np.unique(RMSvar_finite , return_counts=True)\n",
    "                pk = [x/len(RMSvar_finite) for x in counts]\n",
    "                CI_RMSvar = st.rv_discrete(a = -np.inf,values=(unique, pk))  \n",
    "            except:\n",
    "                CI_RMSvar = st.rv_discrete(a = -np.inf,values=(RMSvar_finite,np.array(len(RMSvar_finite)*[1./len(RMSvar_finite)])))\n",
    "            ax3.fill_between([np.nanmin(binneddf[0][idx])-1.,np.nanmax(binneddf[0][idx])+1.],\\\n",
    "                             CI_RMSvar.interval(0.68)[0], CI_RMSvar.interval(0.68)[1], color = 'g', alpha = 0.5)\n",
    "            ax3.fill_between([np.nanmin(binneddf[0][idx])-1.,np.nanmax(binneddf[0][idx])+1.],\\\n",
    "                             CI_RMSvar.interval(0.95)[0], CI_RMSvar.interval(0.95)[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "        except:\n",
    "            CI68_RMSvar = st.norm.interval(alpha=0.68, loc= RMSvar_mean, scale=np.sqrt(np.nanvar(RMSvar[idx])))\n",
    "            CI95_RMSvar = st.norm.interval(alpha=0.95, loc= RMSvar_mean, scale=np.sqrt(np.nanvar(RMSvar[idx])))\n",
    "            ax3.fill_between([np.nanmin(binneddf[0][idx])-1.,np.nanmax(binneddf[0][idx])+1.],\\\n",
    "                             CI68_RMSvar[0], CI68_RMSvar[1], color = 'g', alpha = 0.5)\n",
    "            ax3.fill_between([np.nanmin(binneddf[0][idx])-1.,np.nanmax(binneddf[0][idx])+1.],\\\n",
    "                             CI95_RMSvar[0], CI95_RMSvar[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "\n",
    "        ax3.set_ylabel(r\"$\\sigma_{rms}$\")\n",
    "        ax3.minorticks_on()\n",
    "        ax3.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "        ax3.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "        ax3.set_xlim(xmin = np.nanmin(binneddf[0][idx])-1, xmax = np.nanmax(binneddf[0][idx])+1.)\n",
    "        ax3.legend(loc = 'upper right')\n",
    "        ax3.set_xlabel('Time (BTJD - days)')\n",
    "        \n",
    "        plt.setp(ax2.get_xticklabels(), visible=False)\n",
    "    \n",
    "        if sectbysect == True:\n",
    "            plt.savefig(subdir+'/excess_variance/'+target+'_excess_rms_varianceCI_'+bin_time+'hr_sectors'+group+'.pdf', format = 'pdf',bbox_inches='tight') \n",
    "        else:\n",
    "            plt.savefig(subdir+'/excess_variance/'+target+'_excess_rms_varianceCI_'+bin_time+'hr.pdf', format = 'pdf',bbox_inches='tight')\n",
    "        #                 plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    except:\n",
    "        plt.close()\n",
    "        try:\n",
    "            fig = plt.figure(figsize=(8,4))\n",
    "\n",
    "            plt.errorbar(binneddf[0][idx], Xvar[idx], yerr = XvarErr[idx], linestyle =\"None\", fmt='+', markersize = 4, color = 'k')\n",
    "            plt.axhline(Xvar_mean, color = 'k', linestyle = 'solid', label = r'$\\langle σ_{XS}^{2} \\rangle$ = %.2e'%Xvar_mean)\n",
    "            try:\n",
    "                try:\n",
    "                    unique, counts = np.unique(Xvar[idx], return_counts=True)\n",
    "                    pk = [x/len(Xvar[idx]) for x in counts]\n",
    "                    CI_Xvar = st.rv_discrete(a = -np.inf,values=(unique, pk))  \n",
    "                except:\n",
    "                    CI_Xvar = st.rv_discrete(a = -np.inf,values=(Xvar, np.array(len(Xvar[idx])*[1/len(Xvar[idx])])))         \n",
    "                plt.fill_between([np.nanmin(binneddf[0][idx])-1,np.nanmax(binneddf[0][idx])+1],\\\n",
    "                                 CI_Xvar.interval(0.68)[0], CI_Xvar.interval(0.68)[1], color = 'g', alpha = 0.5)\n",
    "                plt.fill_between([np.nanmin(binneddf[0][idx])-1,np.nanmax(binneddf[0][idx])+1],\\\n",
    "                                 CI_Xvar.interval(0.95)[0], CI_Xvar.interval(0.95)[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "            except:\n",
    "                CI68_Xvar = st.norm.interval(alpha=0.68, loc= Xvar_mean, scale=np.sqrt(np.nanvar(Xvar[idx])))                \n",
    "                CI95_Xvar = st.norm.interval(alpha=0.95, loc= Xvar_mean, scale=np.sqrt(np.nanvar(Xvar[idx])))\n",
    "                plt.fill_between([binneddf[0].min()-1,np.nanmax(binneddf[0])+1],\\\n",
    "                                 CI68_Xvar[0], CI68_Xvar[1], color = 'g', alpha = 0.5)\n",
    "                plt.fill_between([binneddf[0].min()-1,np.nanmax(binneddf[0])+1],\\\n",
    "                                 CI95_Xvar[0], CI95_Xvar[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "            plt.minorticks_on()\n",
    "            plt.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "            plt.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "            plt.legend(loc = 'upper right')\n",
    "\n",
    "            plt.xlabel('Time (BTJD - days)')\n",
    "            plt.ylabel(r\"$σ_{XS}^{2}$\")\n",
    "\n",
    "            plt.xlim(xmin = np.nanmin(binneddf[0][idx])-1, xmax = np.nanmax(binneddf[0][idx])+1)\n",
    "            \n",
    "            if sectbysect == True:\n",
    "                plt.title(target+r': $σ_{XS}^{2}$, '+bin_time+'hr bins sectors '+group,fontsize='x-large')\n",
    "                plt.savefig(subdir+'/excess_variance/'+target+'_excess_rms_varianceCI_'+bin_time+'hr_sectors'+group+'.pdf', format = 'pdf',bbox_inches='tight') \n",
    "            else:\n",
    "                plt.title(target+r': $σ_{XS}^{2}$, '+bin_time+'hr bins',fontsize='x-large')\n",
    "                plt.savefig(subdir+'/excess_variance/'+target+'_excess_rms_varianceCI_'+bin_time+'hr.pdf', format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "        #                     plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        except:\n",
    "            plt.close()\n",
    "            print(\"I was givin' 'er all she's got Cap'n\")\n",
    "\n",
    "    return()\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "###########################################################################################################\n",
    "'''\n",
    "Definition of various functions regarding light curve modification \n",
    "including interpolation, stitching, and rebinning \n",
    "'''\n",
    "\n",
    "def interpolate_data(target, df, pcm, directory):\n",
    "    '''\n",
    "    Interpolation of light curve or light curve secgments\n",
    "    \n",
    "     inputs:\n",
    "         target (string)        - Name of desired object to analyze\n",
    "         df (DataFrame)         - dataframe of uninterpolated light curve\n",
    "         pcm (int)              - specifier of regression pricipal component method\n",
    "         \n",
    "     outputs:\n",
    "        interp_df (DataFrame)   - dataframe of interpolated light curve\n",
    "        \n",
    "    '''\n",
    "\n",
    "    \n",
    "    sampspace = np.round(df[0][1]-df[0][0],6)\n",
    "    delt_crit = round_up_decimals(sampspace,5)\n",
    "#     print(delt_crit)\n",
    "    \n",
    "                        \n",
    "    time = [df[0][0]]\n",
    "    flux = [df[1][0]]\n",
    "    err = [df[2][0]]\n",
    "  \n",
    "    ## Sequence of finding gaps in data, linearly interpolating between gaps, and plotting of new figures.\n",
    "                        \n",
    "    for i in range(1,len(df[0])):\n",
    "        \n",
    "        delt = df[0][i] - df[0][i-1]\n",
    "        \n",
    "        if delt > delt_crit:\n",
    "            buffer_bad = True\n",
    "            pts = 15\n",
    "                        \n",
    "            early_time_buffer = []\n",
    "            late_time_buffer = []\n",
    "            \n",
    "            early_flux_buffer = []\n",
    "            late_flux_buffer = []\n",
    "\n",
    "            while buffer_bad and pts >=1:\n",
    "                try:\n",
    "                    early_time_buffer = df[0][i-pts:i]\n",
    "                    late_time_buffer = df[0][i:i+pts]\n",
    "\n",
    "                    early_flux_buffer = df[1][i-pts:i]\n",
    "                    late_flux_buffer = df[1][i:i+pts]\n",
    "                    \n",
    "                    buffer_bad = False\n",
    "                \n",
    "                    \n",
    "                except:\n",
    "                    pts -= 1\n",
    "                    \n",
    "            \n",
    "            t_gap = np.arange(start = df[0][i-1] + sampspace, stop = df[0][i], step = sampspace)\n",
    "            f_gap = np.interp(x = t_gap, xp = np.append(early_time_buffer, late_time_buffer),\\\n",
    "                              fp = np.append(early_flux_buffer,late_flux_buffer))\n",
    "            e_gap = np.zeros(len(t_gap))\n",
    "                               \n",
    "            time.extend(np.array(t_gap))\n",
    "            flux.extend(np.array(f_gap))\n",
    "            err.extend(np.array(e_gap))\n",
    "            \n",
    "        else: \n",
    "            time.append(df[0][i])\n",
    "            flux.append(df[1][i])\n",
    "            err.append(df[2][i])\n",
    "    \n",
    "\n",
    "    interp_df = pd.DataFrame(np.column_stack((time,flux,err)),columns = None, index = None)\n",
    "    \n",
    "    interp_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    interp_df = interp_df.dropna()\n",
    "    \n",
    "    if pcm == 1: \n",
    "        interp_df.to_csv(directory+'/lightcurve_datafiles/'+target+'_cycle1_PCA_interpolated_lc.dat',\\\n",
    "                         sep = ' ',header = False, index = False)\n",
    "    if pcm == 2: \n",
    "        interp_df.to_csv(directory+'/lightcurve_datafiles/'+target+'_cycle1_simple_hybrid_interpolated_lc.dat',\\\n",
    "                         sep = ' ',header = False, index = False)\n",
    "    if pcm == 3: \n",
    "        interp_df.to_csv(directory+'/lightcurve_datafiles/'+target+'_cycle1_full_hybrid_interpolated_lc.dat',\\\n",
    "                         sep = ' ',header = False, index = False)\n",
    "\n",
    "    \n",
    "    return(interp_df)\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "def bin_error(n, bins, flux):\n",
    "    '''\n",
    "    Calculate error on binned photometric flux\n",
    "    \n",
    "     inputs:\n",
    "         n (array)        - bin counts\n",
    "         bins (array)     - flux bins\n",
    "         flux (array)     - flux values\n",
    "         \n",
    "     outputs:\n",
    "        bin_err (array)   - error on flux bins\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    bin_err = np.zeros(len(n))\n",
    "\n",
    "    for i in range(0,len(n)):\n",
    "        bin_flux = [x for x in flux if x >= bins[i] and x < bins[i+1]]\n",
    "        bin_err[i] = np.nanstd(bin_flux)/np.sqrt(n[i])\n",
    "        \n",
    "    return(bin_err)\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "def rebinning(df,bin1,bin2):\n",
    "    '''\n",
    "    Rebin light curve under two user-specified schema (in hours)\n",
    "    \n",
    "     inputs:\n",
    "        n (array)         - bin counts\n",
    "        bin1 (string)     - string which specified how many hours for one binning scheme\n",
    "        bin2 (string)     - string which specified how many hours for one binning scheme\n",
    "        \n",
    "     outputs:\n",
    "        binnedflux_bin1 (DataFrame)   - data frame for binned flux under \n",
    "                                            specified binning scheme (time,flux,error)\n",
    "        binnedflux_bin2 (DataFrame)   - data frame for binned flux under \n",
    "                                            specified binning scheme (time,flux,error)\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    print(\"Rebinning.\\n\")\n",
    "    # Fill gaps in time with NaN as flux values\n",
    "    time, flux, err = df[0], df[1], df[2]\n",
    "    \n",
    "    ## Rebinning:\n",
    "    bin1, bin2 = float(bin1), float(bin2)\n",
    "    \n",
    "    time_bin1 = []\n",
    "    time_bin2 = []\n",
    "    \n",
    "    binflux_bin1 = []\n",
    "    binflux_bin2 = []\n",
    "    \n",
    "    binerr_bin1 = []\n",
    "    binerr_bin2 = []\n",
    "    \n",
    "    binstd_bin1 = []\n",
    "    binstd_bin2 = []\n",
    "\n",
    "    binN_bin1 = []\n",
    "    binN_bin2 = []\n",
    "    \n",
    "    binMSE_bin1 = []\n",
    "    binMSE_bin2 = []\n",
    "    \n",
    "    binMSEerr_bin1 = []\n",
    "    binMSEerr_bin2 = []\n",
    "    \n",
    "    binRMS_bin1 = []\n",
    "    binRMS_bin2 = []\n",
    "    \n",
    "    binRMSerr_bin1 = []\n",
    "    binRMSerr_bin2 = []\n",
    "    \n",
    "\n",
    "    for j in range(0,2):\n",
    "        tmp_time = time[0]\n",
    "        tmp_time_idx = 0\n",
    "        \n",
    "        tbin = [time[0]]\n",
    "        fbin = [flux[0]]\n",
    "        ebin = [err[0]]\n",
    "        \n",
    "        for i in range(1,len(time)):\n",
    "                 \n",
    "            if j == 0 and (time[i] - tmp_time) >= np.round((bin1/24.),4): \n",
    "                \n",
    "                temp_bin = np.column_stack((fbin,ebin))\n",
    "                \n",
    "                time_bin1.append(np.nanmean(tbin))\n",
    "                binflux_bin1.append(np.nanmean([x for x,y in temp_bin if y != 0.]))\n",
    "                N = len([x for x,y in temp_bin if y != 0.])\n",
    "                binN_bin1.append(N)\n",
    "                binstd_bin1.append(np.sqrt(np.nanvar([x for x,y in temp_bin if y != 0.], ddof = 1)))\n",
    "                binerr_bin1.append(np.sqrt(np.nanvar([x for x,y in temp_bin if y != 0.], ddof = 1))/np.sqrt(N))\n",
    "                binMSE_bin1.append(np.nanmean([y**2. for x,y in temp_bin if y != 0.]))\n",
    "                binMSEerr_bin1.append(np.sqrt(np.nanvar([y**2. for x,y in temp_bin if y != 0.], ddof = 1))/np.sqrt(N))\n",
    "                XS, XSerr = excess_variance(np.array([x for x,y in temp_bin if y != 0.],dtype = float),\\\n",
    "                                           np.array([y for x,y in temp_bin if y != 0.],dtype = float))\n",
    "                binRMS_bin1.append(np.sqrt(XS))\n",
    "                if XS > 0.:\n",
    "                    binRMSerr_bin1.append(XSerr/(2.*np.sqrt(XS)))\n",
    "                else:\n",
    "                    binRMSerr_bin1.append(0.)\n",
    "                \n",
    "                \n",
    "                tmp_time = time[i]\n",
    "                tbin = [time[i]]\n",
    "                fbin = [flux[i]]\n",
    "                ebin = [err[i]]\n",
    "                                \n",
    "                 \n",
    "            elif j == 1 and (time[i] - tmp_time) >= np.round((bin2/24.),4): \n",
    "                \n",
    "                temp_bin = np.column_stack((fbin,ebin))\n",
    "                \n",
    "                time_bin2.append(np.nanmean(tbin))\n",
    "                binflux_bin2.append(np.nanmean([x for x,y in temp_bin if y != 0.]))\n",
    "                N = len([x for x,y in temp_bin if y != 0.])\n",
    "                binN_bin2.append(N)\n",
    "                binstd_bin2.append(np.sqrt(np.nanvar([x for x,y in temp_bin if y != 0.], ddof = 1)))\n",
    "                binerr_bin2.append(np.sqrt(np.nanvar([x for x,y in temp_bin if y != 0.], ddof = 1))/np.sqrt(N))\n",
    "                binMSE_bin2.append(np.nanmean([y**2 for x,y in temp_bin if y != 0.]))\n",
    "                binMSEerr_bin2.append(np.sqrt(np.nanvar([y**2 for x,y in temp_bin if y != 0.], ddof = 1))/np.sqrt(N))\n",
    "                XS, XSerr = excess_variance(np.array([x for x,y in temp_bin if y != 0.],dtype = float),\\\n",
    "                                           np.array([y for x,y in temp_bin if y != 0.],dtype = float))\n",
    "                binRMS_bin2.append(np.sqrt(XS))\n",
    "                if XS > 0.:\n",
    "                    binRMSerr_bin2.append(XSerr/(2.*np.sqrt(XS)))\n",
    "                else:\n",
    "                    binRMSerr_bin2.append(0.)\n",
    "                \n",
    "                \n",
    "                tmp_time = time[i]\n",
    "                tbin = [time[i]]\n",
    "                fbin = [flux[i]]\n",
    "                ebin = [err[i]]\n",
    "                                \n",
    "            elif i == len(time):\n",
    "                \n",
    "                if j == 0:                 \n",
    "                    time_bin1.append(np.nanmean(tbin))\n",
    "                    binflux_bin1.append(np.nanmean([x for x,y in temp_bin if y != 0.]))\n",
    "                    N = len([x for x,y in temp_bin if y != 0.])\n",
    "                    binN_bin1.append(N)\n",
    "                    binstd_bin1.append(np.sqrt(np.nanvar([x for x,y in temp_bin if y != 0.], ddof = 1)))\n",
    "                    binerr_bin1.append(np.sqrt(np.nanvar([x for x,y in temp_bin if y != 0.], ddof = 1))/np.sqrt(N))\n",
    "                    binMSE_bin1.append(np.nanmean([y**2 for x,y in temp_bin if y != 0.]))\n",
    "                    binMSEerr_bin1.append(np.sqrt(np.nanvar([y**2 for x,y in temp_bin if y != 0.], ddof = 1))/np.sqrt(N))\n",
    "                    XS, XSerr = excess_variance(np.array([x for x,y in temp_bin if y != 0.],dtype = float),\\\n",
    "                                               np.array([y for x,y in temp_bin if y != 0.],dtype = float))\n",
    "                    binRMS_bin1.append(np.sqrt(XS))\n",
    "                    if XS > 0.:\n",
    "                        binRMSerr_bin1.append(XSerr/(2.*np.sqrt(XS)))\n",
    "                    else:\n",
    "                        binRMSerr_bin1.append(0.)\n",
    "                    \n",
    "                elif j == 1:\n",
    "                    \n",
    "                    time_bin2.append(np.nanmean(tbin))\n",
    "                    binflux_bin2.append(np.nanmean([x for x,y in temp_bin if y != 0.]))\n",
    "                    N = len([x for x,y in temp_bin if y != 0.])\n",
    "                    binN_bin2.append(N)\n",
    "                    binstd_bin2.append(np.sqrt(np.nanvar([x for x,y in temp_bin if y != 0.], ddof = 1)))\n",
    "                    binerr_bin2.append(np.sqrt(np.nanvar([x for x,y in temp_bin if y != 0.], ddof = 1))/np.sqrt(N))\n",
    "                    binMSE_bin2.append(np.nanmean([y**2 for x,y in temp_bin if y != 0.]))\n",
    "                    binMSEerr_bin2.append(np.sqrt(np.nanvar([y**2 for x,y in temp_bin if y != 0.], ddof = 1))/np.sqrt(N))\n",
    "                    XS, XSerr = excess_variance(np.array([x for x,y in temp_bin if y != 0.],dtype = float),\\\n",
    "                                               np.array([y for x,y in temp_bin if y != 0.],dtype = float))\n",
    "                    binRMS_bin2.append(np.sqrt(XS))\n",
    "                    if XS > 0.:\n",
    "                        binRMSerr_bin2.append(XSerr/(2.*np.sqrt(XS)))\n",
    "                    else:\n",
    "                        binRMSerr_bin2.append(0.)\n",
    "                    \n",
    "            else:\n",
    "                tbin.append(time[i])\n",
    "                fbin.append(flux[i])\n",
    "                ebin.append(err[i])\n",
    "                                \n",
    "                        \n",
    "\n",
    "    binnedflux_bin1 = pd.DataFrame(np.column_stack((time_bin1,binflux_bin1,binerr_bin1,\\\n",
    "                                                    binstd_bin1,binN_bin1,binMSE_bin1,binMSEerr_bin1,\\\n",
    "                                                    binRMS_bin1,binRMSerr_bin1)))\n",
    "    \n",
    "    binnedflux_bin2 = pd.DataFrame(np.column_stack((time_bin2,binflux_bin2,binerr_bin2,\\\n",
    "                                                    binstd_bin2,binN_bin2,binMSE_bin2,binMSEerr_bin2,\\\n",
    "                                                    binRMS_bin2,binRMSerr_bin2)))\n",
    "    \n",
    "    binnedflux_bin1 = binnedflux_bin1.replace([np.inf, -np.inf], np.nan).dropna().reset_index(drop=True)\n",
    "    binnedflux_bin2 = binnedflux_bin2.replace([np.inf, -np.inf], np.nan).dropna().reset_index(drop=True)\n",
    "\n",
    "    return(binnedflux_bin1,binnedflux_bin2)\n",
    "\n",
    "\n",
    "def lc_stitch(unstitched_lc):\n",
    "    '''\n",
    "    Stitch together multiple sectors of light curve if not already stitched\n",
    "    \n",
    "     inputs:\n",
    "        unstitched_lc (array of arrays)   - multi-sector light curve\n",
    "     outputs:\n",
    "        full_lc_time (array)              - stitched light curve component\n",
    "        full_lc_flux (array)              - stitched light curve component\n",
    "        full_lc_err (array)               - stitched light curve component\n",
    "    '''\n",
    "\n",
    "    for j in range(0,len(unstitched_lc)):\n",
    "        if j!=0:\n",
    "            sector = str(j+1)\n",
    "\n",
    "        lc = unstitched_lc[j]\n",
    "\n",
    "        t = lc[:,0]\n",
    "        f = lc[:,1]\n",
    "        err = lc[:,2]\n",
    "\n",
    "\n",
    "        if j == 0:\n",
    "\n",
    "            full_lc_time = t\n",
    "            full_lc_flux = f\n",
    "            full_lc_err= err\n",
    "\n",
    "        else:\n",
    "\n",
    "            first_flux = np.nanmean(f[:10])\n",
    "            last_flux = np.nanmean(full_lc_flux[-10:])\n",
    "\n",
    "            scale_factor= first_flux - last_flux\n",
    "\n",
    "            if scale_factor > 0:\n",
    "\n",
    "                scaled_flux = f - abs(scale_factor)\n",
    "\n",
    "            if scale_factor < 0:\n",
    "\n",
    "                scaled_flux = f + abs(scale_factor)\n",
    "\n",
    "            full_lc_time = np.append(full_lc_time,t)\n",
    "            full_lc_flux = np.append(full_lc_flux,scaled_flux)\n",
    "            full_lc_err = np.append(full_lc_err,err)\n",
    "\n",
    "    return(full_lc_time,full_lc_flux,full_lc_err)\n",
    "\n",
    "###########################################################################################################\n",
    "###########################################################################################################\n",
    "def r_squared(flux, rms, params):\n",
    "    \n",
    "    resid = np.subtract(rms,linear(flux,*params))\n",
    "    Sresid = np.nansum(resid**2.)\n",
    "    Stot = np.nansum(np.subtract(rms,np.nanmean(rms))**2.)\n",
    "    \n",
    "    rsq = 1. - Sresid/Stot\n",
    "    \n",
    "    if rsq >= 0.9:\n",
    "        rsq_sig = \"very strong\"\n",
    "    elif 0.75 <= rsq <= 0.9:\n",
    "        rsq_sig = \"strong\"\n",
    "    elif 0.5 <= rsq <= 0.75:\n",
    "        rsq_sig = \"mild\"\n",
    "    elif 0.25 <= rsq <= 0.5:\n",
    "        rsq_sig = \"weak\"\n",
    "    else: \n",
    "        rsq_sig = \"none\"\n",
    "        \n",
    "    return(rsq, rsq_sig)\n",
    "\n",
    "\n",
    "def KStest(mean,std,flux, mean2 = 0.,std2 = 0., div= 0., model = \"normal\"):\n",
    "    \n",
    "    KS_D = []\n",
    "    KS_p = []\n",
    "\n",
    "    if model == \"lognormal\":\n",
    "        for x in range(0,5000):\n",
    "            try:\n",
    "                rnd_dist = np.random.lognormal(mean = mean, sigma = std, size = len(flux))\n",
    "            except:\n",
    "                rnd_dist = np.random.lognormal(mean = mean, sigma = np.abs(std), size = len(flux))\n",
    "            KS = st.ks_2samp(flux, rnd_dist)\n",
    "            KS_D.append(KS[0])\n",
    "            KS_p.append(KS[1])\n",
    "    \n",
    "    elif model == \"bimodal\":\n",
    "        ϕ = 0.5 + np.arctan(div)/np.pi\n",
    "        for x in range(0,5000):\n",
    "            try:\n",
    "                try:\n",
    "                    rnd_distA = np.random.normal(loc = mean, scale = std, size = int(ϕ*len(flux) + 0.5))\n",
    "                    rnd_distB = np.random.normal(loc = mean2, scale = std2, size = int((1-ϕ)*len(flux) + 0.5))\n",
    "                    rnd_dist = np.concatenate([rnd_distA, rnd_distB], axis = 0)\n",
    "                except:\n",
    "                    rnd_distA = np.random.normal(loc = mean, scale = np.abs(std), size = int(ϕ*len(flux) + 0.5))\n",
    "                    rnd_distB = np.random.normal(loc = mean2, scale = np.abs(std2), size = int((1-ϕ)*len(flux) + 0.5))\n",
    "                    rnd_dist = np.concatenate([rnd_distA, rnd_distB], axis = 0)\n",
    "            except:\n",
    "                rnd_distA = np.random.normal(loc = mean, scale = np.abs(std), size = int(len(flux)/2. + 0.5))\n",
    "                rnd_distB = np.random.normal(loc = mean2, scale = np.abs(std2), size = int(len(flux)/2. + 0.5))\n",
    "                rnd_dist = np.concatenate([rnd_distA, rnd_distB], axis = 0)\n",
    "\n",
    "            KS = st.ks_2samp(flux, rnd_dist)\n",
    "            KS_D.append(KS[0])\n",
    "            KS_p.append(KS[1])\n",
    "    \n",
    "    else:\n",
    "        for x in range(0,5000):\n",
    "            rnd_dist = np.random.normal(loc = mean, scale = np.abs(std), size = len(flux))\n",
    "            KS = st.ks_2samp(flux, rnd_dist)\n",
    "            KS_D.append(KS[0])\n",
    "            KS_p.append(KS[1])\n",
    "    \n",
    "    return([np.nanmean(KS_D),np.nanmean(KS_p)] )\n",
    "\n",
    "\n",
    "\n",
    "def lognormal_fit(n, flux, bins, bin_center, bin_err, i, directory, save_tail, bin1, bin2, α = 0.05, visual = False):    \n",
    "    '''\n",
    "    Algorithm to fit distribution to lognormal curve\n",
    "    \n",
    "     inputs:\n",
    "        n (array)                    - bin counts\n",
    "        flux (array)                 - flux values\n",
    "        bins (array)                 - flux bins\n",
    "        bin_center (array)           - flux bin centers\n",
    "        bin_err (array)              - bin errors\n",
    "        i (int)                      - specifier for which version of light curve is being analyzed \n",
    "        directory (directory)        - The directory in which figures will be saved\n",
    "        save_tail (string)           - tail of name assigned to file to be saved\n",
    "        bin1 (string)                - string which specified how many hours for one binning scheme\n",
    "        bin2 (string)                - string which specified how many hours for one binning scheme)\n",
    "        α (float)                    - value between 0 and 1 to set significance of KS test\n",
    "        visual (boolean)             - should figures be shown\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    maxfreq = np.nanmax(n)\n",
    "\n",
    "    tick_labels = ticklabels(bin_center)\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    shape, loc, scale = st.lognorm.fit(np.array(flux), method = \"MM\")\n",
    "    init_params = (maxfreq, np.log(scale), shape)\n",
    "    \n",
    "    lognorm_m = op.minimize(Min_PDF, [*init_params],\\\n",
    "                            args=(np.array((n,bins),dtype='object'),lognormal),\\\n",
    "                            method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "    lognorm_pars = lognorm_m['x']\n",
    "    \n",
    "    plt.bar(bin_center, n, width = 0.8*(bin_center[1]-bin_center[0]), align='center',tick_label=tick_labels)\n",
    "\n",
    "       \n",
    "    logbins = np.linspace(bins[0],bins[-1:],num=500)\n",
    "    lognorm_fit = st.lognorm.pdf(logbins,shape,loc,scale)\n",
    "\n",
    "    fit_max = np.nanmax(lognorm_fit)\n",
    "    fit_mean = loc\n",
    "\n",
    "    c_α = np.sqrt(-np.log(α/2.)/2.)\n",
    "    D_crit= c_α*np.sqrt(2./len(flux))\n",
    "    \n",
    "    KS = KStest(lognorm_pars[1],lognorm_pars[2], flux, model = \"lognormal\")\n",
    "    \n",
    "    if KS[0] <= D_crit:\n",
    "        plt.plot(logbins,lognorm_fit,color='g',\\\n",
    "                 label='lognormal fit\\n'+r'$\\frac{D}{D_{crit}}$: %.3e; p: %.3e'%(KS[0]/D_crit,KS[1]))\n",
    "    else:\n",
    "        plt.plot(logbins,lognorm_fit,color='r',\\\n",
    "                 label='lognormal fit\\n'+r'$\\frac{D}{D_{crit}}$: %.3e; p: %.3e'%(KS[0]/D_crit,KS[1]))\n",
    "        \n",
    "    plt.axvline(fit_mean,color= 'k',linestyle = 'dashed')\n",
    "\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "   \n",
    "    plt.suptitle('Flux distibution: '+target) \n",
    "    plt.xlabel('Flux bins')\n",
    "    plt.ylabel('Normalized N')\n",
    "    \n",
    "    if fit_mean >= bins[-1:][0] or fit_mean <= bins[0]: \n",
    "        # Set a clean x-axis limit.\n",
    "        plt.xlim(xmin = bins[0], xmax = bins[-1:][0])\n",
    "    \n",
    "    # Set a clean upper y-axis limit.\n",
    "    plt.ylim(ymax= 1.15*maxfreq if maxfreq>fit_max else 1.15*fit_max)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    if len(n) < 15:\n",
    "        plt.xticks(rotation=30)\n",
    "    else:\n",
    "        plt.xticks(rotation=90)\n",
    "    \n",
    "    if i==2:\n",
    "        plt.title(bin1+\" hr bins\")\n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_lognorm_'+bin1+'hr'+save_tail, format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "\n",
    "    if i==3:\n",
    "        plt.title(bin2+\" hr bins\")\n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_lognorm_'+bin2+'hr'+save_tail, format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "\n",
    "    if visual == True:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.close()\n",
    "    return()\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "def bimodal_fit(n, flux, bins, bin_center, bin_err, i,\\\n",
    "                directory, save_tail, bin1, bin2, α = 0.05, visual = False, init_params = None):\n",
    "    '''\n",
    "    Algorithm to fit distribution to bimodal normal curve\n",
    "    \n",
    "     inputs:\n",
    "        n (array)                    - bin counts\n",
    "        flux (array)                 - flux values\n",
    "        bins (array)                 - flux bins\n",
    "        bin_center (array)           - flux bin centers\n",
    "        bin_err (array)              - bin errors\n",
    "        i (int)                      - specifier for which version of light curve is being analyzed \n",
    "        directory (directory)        - The directory in which figures will be saved\n",
    "        save_tail (string)           - tail of name assigned to file to be saved\n",
    "        bin1 (string)                - string which specified how many hours for one binning scheme\n",
    "        bin2 (string)                - string which specified how many hours for one binning scheme)\n",
    "        α (float)                    - value between 0 and 1 to set significance of KS test\n",
    "        visual (boolean)             - should figures be shown\n",
    "    '''\n",
    "    \n",
    "    flux = sorted(flux)\n",
    "    \n",
    "    tick_labels = ticklabels(bin_center)\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    plt.bar(bin_center,n, width = 0.85*(bin_center[1]-bin_center[0]), align='center',tick_label=tick_labels)\n",
    "    \n",
    "\n",
    "    if init_params == None:\n",
    "        loc1, scale1 = st.norm.fit(flux[:roundedfractionalrange(flux, np.divide(2,3))])\n",
    "        loc2, scale2 = st.norm.fit(flux[-roundedfractionalrange(flux, np.divide(2,3)):])\n",
    "        init_params = (0.5, sorted(n)[-1:][0], loc1, scale1, sorted(n)[-4:][0], loc2, scale2)\n",
    "    \n",
    "    for j in range(0,len(init_params)):\n",
    "        if np.isnan(init_params[j]) == True:\n",
    "            print(\"nan at init_params[%i]\"%j)\n",
    "\n",
    "    bimod_m = op.minimize(Min_PDF, [*init_params],\\\n",
    "                          args=(np.array((n,bins),dtype='object'),bimodal), method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "    bimod_pars = bimod_m['x']\n",
    "    \n",
    "    bimodbins = np.linspace(bins[0],bins[-1:],num=500) \n",
    "    bimod_fit = bimodal(bimodbins, *bimod_pars)\n",
    "\n",
    "    KS = KStest(bimod_pars[2],bimod_pars[3], flux,\\\n",
    "                mean2 = bimod_pars[5], std2 = bimod_pars[6], div = bimod_pars[0], model = \"bimodal\")\n",
    "    \n",
    "    fit_max = np.nanmax(bimod_fit)\n",
    "    maxfreq = np.nanmax(n)\n",
    "    \n",
    "    mu1 = bimod_pars[2]\n",
    "    mu2 = bimod_pars[5]\n",
    "    \n",
    "    c_α = np.sqrt(-np.log(α/2.)/2.)\n",
    "    D_crit= c_α*np.sqrt(2./len(flux))\n",
    "    \n",
    "    if KS[0] <= D_crit:\n",
    "        plt.plot(bimodbins,bimod_fit,color='g',\\\n",
    "                 label='bimodal fit\\n'+r'$\\frac{D}{D_{crit}}$: %.3e; p: %.3e'%(KS[0]/D_crit,KS[1]))\n",
    "    else:\n",
    "        plt.plot(bimodbins,bimod_fit,color='r',\\\n",
    "                 label='bimodal fit\\n'+r'$\\frac{D}{D_{crit}}$: %.3e; p: %.3e'%(KS[0]/D_crit,KS[1]))\n",
    "        \n",
    "    plt.axvline(mu1,color= 'k',linestyle = 'dashed', label = '$μ_{1}$')\n",
    "    plt.axvline(mu2,color= 'k',linestyle = 'dotted', label = '$μ_{2}$')\n",
    "    \n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.suptitle('Flux distibution: '+target) \n",
    "    plt.xlabel('Flux bins')\n",
    "    plt.ylabel('Normalized N')\n",
    "    \n",
    "    if mu1 >= bins[-1:][0] or mu1 <= bins[0] or mu2 >= bins[-1:][0] or mu2 <= bins[0]:\n",
    "        # Set a clean x-axis limit.\n",
    "        plt.xlim(xmin = bins[0], xmax = bins[-1:][0])\n",
    "        \n",
    "    # Set a clean upper y-axis limit.\n",
    "    plt.ylim(ymax= 1.15*maxfreq if maxfreq>fit_max else 1.15*fit_max)\n",
    "    plt.legend()\n",
    "    ticks = [int(np.round(x)) for x in bin_center]\n",
    "\n",
    "    ## Try to make sure all tick labels show and do not overlap        \n",
    "    if len(n) < 15:\n",
    "        plt.xticks(rotation=30)\n",
    "    else:\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "    if i == 2:\n",
    "        plt.title(bin1+\" hr bins\")\n",
    "            \n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_bimodal_'+bin1+'hr'+save_tail, format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "    if i == 3:\n",
    "        plt.title(bin2+\" hr bins\")\n",
    "            \n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_bimodal_'+bin2+'hr'+save_tail, format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "    \n",
    "    if visual == True:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return()\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "def save_figure(directory,target,save_tail,i,bin1,bin2):\n",
    "    \n",
    "    \n",
    "    if i == 0:\n",
    "        plt.title(\"Raw light curve, unbinned\")\n",
    "        plt.savefig(directory+'/'+target+'_raw_flux_dist_gauss_unbinned'+save_tail, format = 'pdf', bbox_inches = 'tight')\n",
    "\n",
    "    if i == 1:\n",
    "        plt.title(\"Quaver regression, unbinned\")\n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_gauss_unbinned'+save_tail, format = 'pdf', bbox_inches = 'tight')\n",
    "\n",
    "    if i == 2:\n",
    "        plt.title(\"Quaver regression, \"+bin1+\" hr bins\")\n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_gauss_'+bin1+'hr'+save_tail, format = 'pdf', bbox_inches = 'tight')\n",
    "\n",
    "    if i == 3:\n",
    "        plt.title(\"Quaver regression, \"+bin2+\" hr bins\")\n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_gauss_'+bin2+'hr'+save_tail, format = 'pdf', bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "\n",
    "    if i == 4:\n",
    "        plt.title(\"Raw light curve, unbinned\")\n",
    "        plt.savefig(directory+'/'+target+'_raw_subflux_dist_unbinned'+save_tail, format = 'pdf', bbox_inches = 'tight')\n",
    "\n",
    "    if i == 5:\n",
    "        plt.title(\"Quaver regression, unbinned\")\n",
    "        plt.savefig(directory+'/'+target+'_subflux_dist_unbinned'+save_tail, format = 'pdf', bbox_inches = 'tight')\n",
    "\n",
    "    if i == 6:\n",
    "        plt.title(\"Quaver regression, \"+bin1+\" hr bins\")\n",
    "        plt.savefig(directory+'/'+target+'_subflux_dist_'+bin1+'hr'+save_tail, format = 'pdf', bbox_inches = 'tight')\n",
    "\n",
    "    if i == 7:\n",
    "        plt.title(\"Quaver regression, \"+bin2+\" hr bins\")\n",
    "        plt.savefig(directory+'/'+target+'_subflux_dist_'+bin2+'hr'+save_tail, format = 'pdf', bbox_inches = 'tight')\n",
    "        \n",
    "    return()\n",
    "\n",
    "def radii_range(timescale, error, z, δ = 1.0, Mbh = -1., delM = -1., u_mass = 'sol'):\n",
    "    \n",
    "    error = np.abs(error)\n",
    "    c = cst.c                     ## speed of light in m/s\n",
    "    G = cst.G                     ## Gravitational constant in m^3 kg^-1 s^-2\n",
    "    \n",
    "    print(\"Estimating emission region radius\\nc=%.3e m/s; G=%.3e m^3/(kg s^2)\\n\"%(c,G))\n",
    "#     m_to_pc = 3.240779289e-14    ## meter to kpc conversion factor\n",
    "    Msol_to_kg = 1.98847e30       ## solar mass to kg conversion factor\n",
    "    day_to_sec = 86400\n",
    "#     print('\\nEstimating emission region inner radius range')\n",
    "    print('Doppler factor: δ ~ %.2f'%δ)\n",
    "    \n",
    "    if delM == -1:\n",
    "        R_low = 1e-3*(timescale-error)*day_to_sec*c*δ #/(1.+z)   ## apparent R_min, in km, of object\n",
    "        R = 1e-3*timescale*day_to_sec*c*δ #/(1.+z)               ## apparent R, in km, of object\n",
    "        R_high = 1e-3*(timescale+error)*day_to_sec*c*δ #/(1.+z)  ## apparent R_max, in km, of object\n",
    "    else:\n",
    "        R_low = 1e-3*(timescale-error)*day_to_sec*c*δ #/(1.+z)   ## apparent R_min, in km, of object\n",
    "        R = 1e-3*timescale*day_to_sec*c*δ #/(1.+z)               ## apparent R, in km, of object\n",
    "        R_high = 1e-3*(timescale+error)*day_to_sec*c*δ #/(1.+z)  ## apparent R_max, in km, of object\n",
    "    \n",
    "    if u_mass == 'sol':\n",
    "        print('M_BH ~ %.3e solar mass\\n'%Mbh)\n",
    "        Mbh = Mbh*Msol_to_kg\n",
    "        \n",
    "    if Mbh > 0.:\n",
    "#         print('M_BH ~ %.3e kg\\n'%Mbh)\n",
    "        \n",
    "        Rsch = 2e-3*G*Mbh/c**2          ## Schwarzchild radius of object in km\n",
    "        \n",
    "        \n",
    "        Rs_low = R_low/Rsch             ## apparent R_min, in Schwarzchild radii, of object\n",
    "        Rs = R/Rsch                     ## apparent R, in Schwarzchild radii, of object\n",
    "        Rs_high = R_high/Rsch           ## apparent R_max, in Schwarzchild radii, of object\n",
    "        \n",
    "        return(R_low,R,R_high,Rs_low,Rs,Rs_high)\n",
    "    else:\n",
    "        return(R_low,R,R_high)\n",
    "\n",
    "\n",
    "\n",
    "def simple_stats(flux, i, subdir, target, α, bins, sectbysect, group, bin1, bin2):\n",
    "    \n",
    "    nonzeroflux = np.nonzero(flux)[0]\n",
    "    flux = np.array(flux[nonzeroflux])\n",
    "   \n",
    "    flux_mean, flux_stdev = np.nanmean(flux), np.abs(np.nanstd(flux))\n",
    "    flux_min = np.nanmin(flux)\n",
    "    flux_max = np.nanmax(flux)\n",
    "\n",
    "    fivesig = 5.0*flux_stdev\n",
    "    flux = [x for x in flux if np.abs(flux_mean - x) <= fivesig]\n",
    "    \n",
    "    flux_mean, flux_stdev = np.nanmean(flux), np.sqrt(np.nanvar(flux, ddof = 1))\n",
    "    \n",
    "    n, bins = np.histogram(flux, bins=OptBins(flux), range=(flux_min,flux_max), density=False)\n",
    "      \n",
    "    bin_center = bins[:-1] + np.diff(bins) / 2\n",
    "    maxfreq = np.nanmax(n)\n",
    "\n",
    "    tick_labels = ticklabels(bin_center)\n",
    "\n",
    "    KS = KStest(flux_mean,flux_stdev,flux)\n",
    "\n",
    "#     fit_FWHM = 2.0*np.sqrt(2.0*np.log(2.0))*flux_stdev ## assuming gaussian distribution\n",
    "\n",
    "    plt.figure(figsize=(12,6), constrained_layout=True)\n",
    "    # plt.figure(figsize=(15,6))\n",
    "\n",
    "    ## Plot flux histogram as bar chart for special width and error bars    \n",
    "    plt.bar(bin_center, n, width = 0.85*(bin_center[1]-bin_center[0]), alpha=0.9,align='center',tick_label=tick_labels)\n",
    "\n",
    "    c_α = np.sqrt(-np.log(α/2.)/2.)\n",
    "    D_crit = c_α*np.sqrt(2./len(flux))\n",
    "    \n",
    "    ## Mark mean\n",
    "    plt.axvline(flux_mean,color= 'k',linestyle = 'dashed', label = 'Mean = %.3e\\nσ = %.3e'%(flux_mean,flux_stdev))\n",
    "\n",
    "    ## Mark mean +/- stddev\n",
    "    if flux_mean+flux_stdev <= flux_max:\n",
    "        plt.axvline(flux_mean+flux_stdev,color= 'k',linestyle = 'dotted')\n",
    "        plt.annotate(text='', xy=(flux_mean,1.05*maxfreq),\\\n",
    "                     xytext=(flux_mean+flux_stdev,1.05*maxfreq), arrowprops=dict(arrowstyle='<->'))\n",
    "    else:\n",
    "        plt.axvline(flux_mean-flux_stdev,color= 'k',linestyle = 'dotted')\n",
    "        plt.annotate(text='', xy=(flux_mean,1.05*maxfreq),\\\n",
    "                     xytext=(flux_mean-flux_stdev,1.05*maxfreq), arrowprops=dict(arrowstyle='<->'))\n",
    "        \n",
    "    if i < 4 :\n",
    "        if flux_mean+flux_stdev <= flux_max:\n",
    "            plt.text(flux_mean+0.45*flux_stdev,1.07*maxfreq,'σ$_{F}$',fontsize='medium')\n",
    "        else:\n",
    "            plt.text(flux_mean-0.45*flux_stdev,1.07*maxfreq,'σ$_{F}$',fontsize='medium')\n",
    "\n",
    "        plt.suptitle('Flux distibution: '+target)\n",
    "        plt.xlabel('Flux bins', fontsize = 14)\n",
    "\n",
    "    elif i >= 4 :\n",
    "        if flux_mean+flux_stdev <= flux_max:\n",
    "            plt.text(flux_mean+0.45*flux_stdev,1.07*maxfreq,'σ$_{ΔF}$',fontsize='medium')\n",
    "        else:\n",
    "            plt.text(flux_mean-0.45*flux_stdev,1.07*maxfreq,'σ$_{ΔF}$',fontsize='medium')\n",
    "\n",
    "        plt.suptitle('Subsequent Flux distibution: '+target)\n",
    "        plt.xlabel('ΔF$_{ij}$', fontsize = 14)\n",
    "        \n",
    "    if flux_mean >= bins[-1:][0] or flux_mean <= bins[0]:\n",
    "        # Set a clean x-axis limit.\n",
    "        plt.xlim(xmin = bins[0], xmax = bins[-1:][0])\n",
    "    \n",
    "    plt.legend(fontsize='large')\n",
    "\n",
    "    ###############################################################\n",
    "    ## Create or save to new flux distributions directory\n",
    "    try:\n",
    "        directory = os.path.join(subdir, 'flux_distributions')\n",
    "        os.mkdir(directory)\n",
    "\n",
    "        print(\"Directory '%s' created\\n\" %directory)    \n",
    "    except FileExistsError:\n",
    "        directory = subdir+'/flux_distributions'\n",
    "\n",
    "    if sectbysect == True:\n",
    "        save_tail = '_sectors'+group+'_simple.pdf'\n",
    "        try:\n",
    "            directory = os.path.join(subdir, 'flux_distributions/Sector_by_sector')\n",
    "            os.mkdir(directory)\n",
    "\n",
    "            print(\"Directory '%s' created\\n\" %directory)    \n",
    "        except FileExistsError:\n",
    "            directory = subdir+'/flux_distributions/Sector_by_sector'\n",
    "    else:\n",
    "        save_tail = '_simple.pdf'\n",
    "#         print(directory)\n",
    "    ###############################################################\n",
    "\n",
    "    ## Try to make sure all tick labels show and do not overlap        \n",
    "    if len(n) < 15:\n",
    "        plt.xticks(rotation=30)\n",
    "    else:\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.tick_params(labelsize = 14)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.ylabel('Normalized N', fontsize = 15)\n",
    "\n",
    "    # Set a clean upper y-axis limit.\n",
    "    plt.ylim(ymax = 1.15*maxfreq)\n",
    "\n",
    "    save_figure(directory,target,save_tail,i,bin1,bin2)\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    return(flux_mean, flux_stdev, KS)\n",
    "\n",
    "def flat_gauss_fit(df, i, subdir, target, α, sectbysect, group, bin1, bin2):\n",
    "\n",
    "    ## Flatten light curve by removing longest linear trend\n",
    "    mean_flux = np.nanmean(df[1])\n",
    "    linear_fit = np.polyfit(df[0],df[1],1)\n",
    "    \n",
    "    flattened_reallc = np.subtract(df[1],linear_fit[0]*df[0])\n",
    "    new_mean = np.nanmean(flattened_reallc)\n",
    "    \n",
    "    ## Shift light curve back to original mean\n",
    "    flattened_reallc = flattened_reallc + (mean_flux-new_mean)\n",
    "    \n",
    "    nonzeroflux = np.nonzero(np.array(flattened_reallc))[0]\n",
    "    time = np.array(df[0][nonzeroflux])\n",
    "    real_flux = np.array(df[1][nonzeroflux])\n",
    "    flux = np.array(flattened_reallc[nonzeroflux])\n",
    "    \n",
    "    try:\n",
    "        flux_mean, flux_stdev = st.norm.fit(np.array(flux), method = \"MM\")\n",
    "        flux_min = np.nanmin(flux)\n",
    "        flux_max = np.nanmax(flux)\n",
    "\n",
    "        fivesig = 5.0*flux_stdev\n",
    "        flux = np.array([x for x in flux if np.abs(flux_mean - x) <= fivesig])\n",
    "\n",
    "        ## Reestimate statistical parameters without outliers\n",
    "        flux_mean, flux_stdev = st.norm.fit(flux, method = \"MM\")\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        flux_mean, flux_stdev = np.nanmean(flux), np.sqrt(np.nanvar(flux))\n",
    "    \n",
    "    n_real, bins_real = np.histogram(real_flux, bins=OptBins(real_flux), range=(np.nanmin(real_flux),np.nanmax(real_flux)), density=False)\n",
    "    n, bins = np.histogram(flux, bins=OptBins(flux), range=(flux_min,flux_max), density=False)\n",
    "      \n",
    "    bin_center = bins[:-1] + np.diff(bins) / 2\n",
    "    maxfreq = np.nanmax(n)    \n",
    "\n",
    "    tick_labels = ticklabels(bin_center)\n",
    "    \n",
    "    init_params = (np.nanmax(n), flux_mean, flux_stdev)\n",
    "    try:\n",
    "        gauss_pars, _ = curve_fit(gaussian, xdata=bin_center,\\\n",
    "                                  ydata=n, p0=init_params, sigma=bin_error(n, bins, flux), maxfev= 2000)#, absolute_sigma = True)\n",
    "\n",
    "        gauss_m = op.minimize(Min_PDF, [*gauss_pars], args=(np.array((n,bins),dtype='object'),gaussian),\\\n",
    "                              method='Nelder-Mead', bounds = ((0,np.inf),(gauss_pars[1]-gauss_pars[2],\\\n",
    "                                                                          gauss_pars[1]+gauss_pars[2]),(0.0, np.inf)),\\\n",
    "                              options={'ftol':1e-6,'disp':False})\n",
    "    except:\n",
    "        gauss_m = op.minimize(Min_PDF, [*init_params], args=(np.array((n,bins),dtype='object'),gaussian),\\\n",
    "                                  method='Nelder-Mead', bounds = ((0,np.inf),(np.nanmin(bins),\\\n",
    "                                                                              np.nanmax(bins)),(0.0, np.inf)),\\\n",
    "                              options={'ftol':1e-6,'disp':False})\n",
    "    \n",
    "    gauss_pars = gauss_m['x']\n",
    "        \n",
    "    fit_mean = gauss_pars[1]\n",
    "    fit_stdev = np.abs(gauss_pars[2])\n",
    "\n",
    "    KS = KStest(fit_mean,fit_stdev,flux)\n",
    "\n",
    "#     fit_FWHM = 2.0*np.sqrt(2.0*np.log(2.0))*fit_stdev ## assuming gaussian distribution\n",
    "\n",
    "    plt.figure(figsize=(12,6), constrained_layout=True)\n",
    "    # plt.figure(figsize=(15,6))\n",
    "\n",
    "    ## Plot flux histogram as bar chart for special width and error bars\n",
    "\n",
    "    fill_bins = np.hstack(np.array([[x,x] if (np.where(bins_real == x)[0] > 0) & (np.where(bins_real == x)[0] < len(bins_real)-1) else [x] for x in bins_real]))\n",
    "    fill_n = np.hstack(np.array([[x,x] for x in n_real]))\n",
    "    \n",
    "    plt.fill_between(fill_bins,0.,fill_n, alpha=0.75,label = r'$F_{observed}$',hatch = '/', zorder = 0)\n",
    "#     plt.bar(bin_center, n_real, width = 0.85*(bin_center[1]-bin_center[0]), alpha=0.75,\\\n",
    "#             align='center',tick_label=tick_labels,label = r'$F_{observed}$',hatch = '/', zorder = 0)\n",
    "#     plt.fill_between(fill_bins,0.,fill_n, alpha=0.75,label = r'$F_{flattened}$',hatch = '/', zorder = 0)\n",
    "    plt.bar(bin_center, n, width = 0.85*(bin_center[1]-bin_center[0]), alpha=0.75,\\\n",
    "            align='center',tick_label=tick_labels,label = r'$F_{flattened}$',hatch = 'o', zorder = 1)\n",
    "\n",
    "    ## Plot Gaussian fit over histogram\n",
    "    fit_flux = np.linspace(bins[0],bins[-1:],num=500)\n",
    "\n",
    "    gaussian_fit = gaussian(fit_flux, *gauss_pars)\n",
    "    fit_max = np.nanmax(gaussian_fit)\n",
    "\n",
    "    c_α = np.sqrt(-np.log(α/2.)/2.)\n",
    "    D_crit = c_α*np.sqrt(2./len(flux))\n",
    "    \n",
    "     ## Mark mean\n",
    "    plt.axvline(fit_mean,color= 'k',linestyle = 'dashed', label = 'Mean = %.3e\\nσ = %.3e'%(fit_mean,fit_stdev))\n",
    "\n",
    "    ## Mark mean +/- stddev\n",
    "    if fit_mean+fit_stdev <= flux_max:\n",
    "        plt.axvline(fit_mean+fit_stdev,color= 'k',linestyle = 'dotted')\n",
    "        plt.annotate(text='', xy=(fit_mean,1.05*maxfreq), xytext=(fit_mean+fit_stdev,1.05*maxfreq),\\\n",
    "                     arrowprops=dict(arrowstyle='<->'))\n",
    "    else:\n",
    "        plt.axvline(fit_mean-fit_stdev,color= 'k',linestyle = 'dotted')\n",
    "        plt.annotate(text='', xy=(fit_mean,1.05*maxfreq), xytext=(fit_mean-fit_stdev,1.05*maxfreq),\\\n",
    "                     arrowprops=dict(arrowstyle='<->'))\n",
    "        \n",
    "    if i < 4 :\n",
    "        if fit_mean+fit_stdev <= flux_max:\n",
    "            plt.text(fit_mean+0.45*fit_stdev,1.07*maxfreq,'σ$_{F}$',fontsize='medium')\n",
    "        else:\n",
    "            plt.text(fit_mean-0.45*fit_stdev,1.07*maxfreq,'σ$_{F}$',fontsize='medium')\n",
    "\n",
    "        plt.suptitle('Flux distibution: '+target)\n",
    "        plt.xlabel('Flux bins',fontsize = 15)\n",
    "\n",
    "    elif i >= 4 :\n",
    "        if fit_mean+fit_stdev <= flux_max:\n",
    "            plt.text(fit_mean+0.45*fit_stdev,1.07*maxfreq,'σ$_{ΔF}$',fontsize='medium')\n",
    "        else:\n",
    "            plt.text(fit_mean-0.45*fit_stdev,1.07*maxfreq,'σ$_{ΔF}$',fontsize='medium')\n",
    "\n",
    "        plt.suptitle('Subsequent Flux distibution: '+target)\n",
    "        plt.xlabel('ΔF$_{ij}$',fontsize = 15)\n",
    "        \n",
    "    if fit_mean >= bins[-1:][0] or fit_mean <= bins[0]:\n",
    "        # Set a clean x-axis limit.\n",
    "        plt.xlim(xmin = bins[0], xmax = bins[-1:][0])\n",
    "        \n",
    "    if KS[0] <= D_crit:\n",
    "        plt.plot(fit_flux,gaussian_fit,color='g',\\\n",
    "                 label='gaussian fit\\n'+r'$\\frac{D}{D_{crit}}$: %.3e; p: %.3e'%(KS[0]/D_crit,KS[1]))\n",
    "    else:\n",
    "        plt.plot(fit_flux,gaussian_fit,color='r',\\\n",
    "                 label='gaussian fit\\n'+r'$\\frac{D}{D_{crit}}$: %.3e; p: %.3e'%(KS[0]/D_crit,KS[1]))\n",
    "    \n",
    "    plt.legend(fontsize = 'x-large')\n",
    "\n",
    "    ###############################################################\n",
    "    ## Create or save to new flux distributions directory\n",
    "    try:\n",
    "        directory = os.path.join(subdir, 'flux_distributions')\n",
    "        os.mkdir(directory)\n",
    "\n",
    "        print(\"Directory '%s' created\\n\" %directory)    \n",
    "    except FileExistsError:\n",
    "        directory = subdir+'/flux_distributions'\n",
    "\n",
    "    if sectbysect == True:\n",
    "        save_tail = '_sectors'+group+'_interpolated.pdf'\n",
    "        try:\n",
    "            directory = os.path.join(subdir, 'flux_distributions/Sector_by_sector')\n",
    "            os.mkdir(directory)\n",
    "\n",
    "            print(\"Directory '%s' created\\n\" %directory)    \n",
    "        except FileExistsError:\n",
    "            directory = subdir+'/flux_distributions/Sector_by_sector'\n",
    "    else:\n",
    "        save_tail = '_flattened.pdf'\n",
    "#         print(directory)\n",
    "    ###############################################################\n",
    "\n",
    "    ## Try to make sure all tick labels show and do not overlap        \n",
    "    if len(n) < 15:\n",
    "        plt.xticks(rotation=30)\n",
    "    else:\n",
    "        plt.xticks(rotation=90)\n",
    "    \n",
    "    plt.tick_params(labelsize = 14)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.ylabel('N',fontsize = 16)\n",
    "\n",
    "    # Set a clean upper y-axis limit.\n",
    "    plt.ylim(ymax = 1.15*maxfreq if maxfreq > fit_max else 1.15*fit_max)\n",
    "\n",
    "    save_figure(directory,target,save_tail,i,bin1,bin2)\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    fit_mean, fit_stdev, KS = simple_stats(np.array(real_flux), i,\\\n",
    "                                           subdir, target, α, bins_real, sectbysect, group, bin1, bin2)\n",
    "    \n",
    "    return(flux_mean, fit_stdev, KS)\n",
    "\n",
    "\n",
    "def interp_gauss_fit(uninterp_df, df, i, subdir, target, α, sectbysect, group, bin1, bin2):\n",
    "\n",
    "    \n",
    "    nonzeroflux = np.nonzero(np.array(df[1]))[0]\n",
    "    time = np.array(df[0][nonzeroflux])\n",
    "    flux = np.array(df[1][nonzeroflux])\n",
    "    err = np.array(df[2][nonzeroflux])\n",
    "    \n",
    "    lc = np.column_stack((time,flux,err))\n",
    "    \n",
    "    try:\n",
    "        flux_mean, flux_stdev = st.norm.fit(np.array(flux), method = \"MM\")\n",
    "        flux_min = np.nanmin(flux)\n",
    "        flux_max = np.nanmax(flux)\n",
    "\n",
    "        fivesig = 5.0*flux_stdev\n",
    "        flux = np.array([x for x in flux if np.abs(flux_mean - x) <= fivesig])\n",
    "\n",
    "        ## Reestimate statistical parameters without outliers\n",
    "        flux_mean, flux_stdev = st.norm.fit(flux, method = \"MM\")\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        flux_mean, flux_stdev = np.nanmean(flux), np.sqrt(np.nanvar(flux))\n",
    "    \n",
    "    n, bins = np.histogram(flux, bins=OptBins(flux), range=(flux_min,flux_max), density=False)\n",
    "      \n",
    "    bin_center = bins[:-1] + np.diff(bins) / 2\n",
    "    maxfreq = np.nanmax(n)    \n",
    "\n",
    "    tick_labels = ticklabels(bin_center)\n",
    "    \n",
    "    init_params = (np.nanmax(n), flux_mean, flux_stdev)\n",
    "    try:\n",
    "        gauss_pars, _ = curve_fit(gaussian, xdata=bin_center, ydata=n, p0=init_params, sigma=bin_error(n, bins, flux), maxfev= 2000)#, absolute_sigma = True)\n",
    "\n",
    "        gauss_m = op.minimize(Min_PDF, [*gauss_pars], args=(np.array((n,bins),dtype='object'),gaussian),\\\n",
    "                              method='Nelder-Mead', bounds = ((0,np.inf),\\\n",
    "                                                              (gauss_pars[1]-gauss_pars[2],gauss_pars[1]+gauss_pars[2]),\\\n",
    "                                                              (0.0, np.inf)), options={'ftol':1e-6,'disp':False})\n",
    "    except:\n",
    "        gauss_m = op.minimize(Min_PDF, [*init_params], args=(np.array((n,bins),dtype='object'),gaussian),\\\n",
    "                                  method='Nelder-Mead', bounds = ((0,np.inf),\\\n",
    "                                                                  (np.nanmin(bins),np.nanmax(bins)),(0.0, np.inf)),\\\n",
    "                              options={'ftol':1e-6,'disp':False})\n",
    "    \n",
    "    gauss_pars = gauss_m['x']\n",
    "        \n",
    "    fit_mean = gauss_pars[1]\n",
    "    fit_stdev = np.abs(gauss_pars[2])\n",
    "\n",
    "    KS = KStest(fit_mean,fit_stdev,flux)\n",
    "\n",
    "#     fit_FWHM = 2.0*np.sqrt(2.0*np.log(2.0))*fit_stdev ## assuming gaussian distribution\n",
    "\n",
    "    plt.figure(figsize=(12,6), constrained_layout=True)\n",
    "    # plt.figure(figsize=(15,6))\n",
    "\n",
    "    ## Plot flux histogram as bar chart for special width and error bars\n",
    "    real_flux = np.array([f for t,f,e in lc if e!=0])\n",
    "    false_flux = np.array([f for t,f,e in lc if e==0])\n",
    "    \n",
    "    n_real, bins_real = np.histogram(real_flux, bins=OptBins(flux), range=(flux_min,flux_max), density=False)\n",
    "    n_false, bins_false = np.histogram(false_flux, bins=OptBins(flux), range=(flux_min,flux_max), density=False)\n",
    "    \n",
    "    plt.bar(bin_center, n_real, width = 0.85*(bin_center[1]-bin_center[0]), alpha=0.8,\\\n",
    "            align='center',tick_label=tick_labels,label = r'$F_{observed}$')\n",
    "    plt.bar(bin_center, n_false, bottom = n_real, width = 0.85*(bin_center[1]-bin_center[0]), alpha=0.9,\\\n",
    "            align='center',tick_label=tick_labels,label = r'$F_{interpolated}$')\n",
    "\n",
    "    ## Plot Gaussian fit over histogram\n",
    "    fit_flux = np.linspace(bins[0],bins[-1:],num=500)\n",
    "\n",
    "    gaussian_fit = gaussian(fit_flux, *gauss_pars)\n",
    "    fit_max = np.nanmax(gaussian_fit)\n",
    "\n",
    "    c_α = np.sqrt(-np.log(α/2.)/2.)\n",
    "    D_crit = c_α*np.sqrt(2./len(flux))\n",
    "    \n",
    "     ## Mark mean\n",
    "    plt.axvline(fit_mean,color= 'k',linestyle = 'dashed', label = 'Mean = %.3e\\nσ = %.3e'%(fit_mean,fit_stdev))\n",
    "\n",
    "    ## Mark mean +/- stddev\n",
    "    if fit_mean+fit_stdev <= flux_max:\n",
    "        plt.axvline(fit_mean+fit_stdev,color= 'k',linestyle = 'dotted')\n",
    "        plt.annotate(text='', xy=(fit_mean,1.05*maxfreq), xytext=(fit_mean+fit_stdev,1.05*maxfreq),\\\n",
    "                     arrowprops=dict(arrowstyle='<->'))\n",
    "    else:\n",
    "        plt.axvline(fit_mean-fit_stdev,color= 'k',linestyle = 'dotted')\n",
    "        plt.annotate(text='', xy=(fit_mean,1.05*maxfreq), xytext=(fit_mean-fit_stdev,1.05*maxfreq),\\\n",
    "                     arrowprops=dict(arrowstyle='<->'))\n",
    "        \n",
    "    if i < 4 :\n",
    "        if fit_mean+fit_stdev <= flux_max:\n",
    "            plt.text(fit_mean+0.45*fit_stdev,1.07*maxfreq,'σ$_{F}$',fontsize='medium')\n",
    "        else:\n",
    "            plt.text(fit_mean-0.45*fit_stdev,1.07*maxfreq,'σ$_{F}$',fontsize='medium')\n",
    "\n",
    "        plt.suptitle('Flux distibution: '+target)\n",
    "        plt.xlabel('Flux bins', fontsize = 16)\n",
    "\n",
    "    elif i >= 4 :\n",
    "        if fit_mean+fit_stdev <= flux_max:\n",
    "            plt.text(fit_mean+0.45*fit_stdev,1.07*maxfreq,'σ$_{ΔF}$',fontsize='medium')\n",
    "        else:\n",
    "            plt.text(fit_mean-0.45*fit_stdev,1.07*maxfreq,'σ$_{ΔF}$',fontsize='medium')\n",
    "\n",
    "        plt.suptitle('Subsequent Flux distibution: '+target)\n",
    "        plt.xlabel('ΔF$_{ij}$', fontsize = 16)\n",
    "        \n",
    "    if fit_mean >= bins[-1:][0] or fit_mean <= bins[0]:\n",
    "        # Set a clean x-axis limit.\n",
    "        plt.xlim(xmin = bins[0], xmax = bins[-1:][0])\n",
    "        \n",
    "    if KS[0] <= D_crit:\n",
    "        plt.plot(fit_flux,gaussian_fit,color='g',\\\n",
    "                 label='gaussian fit\\n'+r'$\\frac{D}{D_{crit}}$: %.3e; p: %.3e'%(KS[0]/D_crit,KS[1]))\n",
    "    else:\n",
    "        plt.plot(fit_flux,gaussian_fit,color='r',\\\n",
    "                 label='gaussian fit\\n'+r'$\\frac{D}{D_{crit}}$: %.3e; p: %.3e'%(KS[0]/D_crit,KS[1]))\n",
    "        fit_mean, fit_stdev, KS = flat_gauss_fit(uninterp_df, i, subdir, target, α, sectbysect, group, bin1, bin2)\n",
    "\n",
    "    plt.legend(fontsize='x-large')\n",
    "\n",
    "    ###############################################################\n",
    "    ## Create or save to new flux distributions directory\n",
    "    try:\n",
    "        directory = os.path.join(subdir, 'flux_distributions')\n",
    "        os.mkdir(directory)\n",
    "\n",
    "        print(\"Directory '%s' created\\n\" %directory)    \n",
    "    except FileExistsError:\n",
    "        directory = subdir+'/flux_distributions'\n",
    "\n",
    "    if sectbysect == True:\n",
    "        save_tail = '_sectors'+group+'_interpolated.pdf'\n",
    "        try:\n",
    "            directory = os.path.join(subdir, 'flux_distributions/Sector_by_sector')\n",
    "            os.mkdir(directory)\n",
    "\n",
    "            print(\"Directory '%s' created\\n\" %directory)    \n",
    "        except FileExistsError:\n",
    "            directory = subdir+'/flux_distributions/Sector_by_sector'\n",
    "    else:\n",
    "        save_tail = '_interpolated.pdf'\n",
    "#         print(directory)\n",
    "    ###############################################################\n",
    "\n",
    "    ## Try to make sure all tick labels show and do not overlap        \n",
    "    if len(n) < 15:\n",
    "        plt.xticks(rotation=30)\n",
    "    else:\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.tick_params(labelsize=14)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.ylabel('N', fontsize = 16)\n",
    "\n",
    "    # Set a clean upper y-axis limit.\n",
    "    plt.ylim(ymax = 1.15*maxfreq if maxfreq > fit_max else 1.15*fit_max)\n",
    "\n",
    "    save_figure(directory,target,save_tail,i,bin1,bin2)\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    return(flux_mean, fit_stdev, KS)\n",
    "\n",
    "def hist_and_fit(uninterp_df, df, i, subdir, target, sectbysect, group='',\\\n",
    "                 bin1=0., bin2=0., α = 0.05,  visual = False):\n",
    "    '''\n",
    "    Algorithm to fit distribution to gaussian, bimodal gaussian, and lognormal curves\n",
    "    \n",
    "     inputs:\n",
    "        flux (array)                 - flux values\n",
    "        i (int)                      - specifier for which version of light curve is being analyzed \n",
    "        subdir (directory)           - The directory in which figures will be saved\n",
    "        target (string)              - target name\n",
    "        sectbysect (boolean)         - sector by sector analysis or not (default is False)\n",
    "        group (string)               - current sectors under analysis if sectbysect is True \n",
    "        bin1 (string)                - string which specified how many hours for one binning scheme\n",
    "        bin2 (string)                - string which specified how many hours for one binning scheme)\n",
    "        α (float)                    - value between 0 and 1 to set significance of KS test\n",
    "        visual (boolean)             - should figures be shown\n",
    "        \n",
    "    outputs:\n",
    "        fit_stdev (float)\n",
    "        flux_mean (float)\n",
    "        flux_min (float)\n",
    "        flux_max (float)\n",
    "        bin_center (array)\n",
    "    '''\n",
    "\n",
    "    if 0 <= i < 4:\n",
    "        nonzeroflux = np.nonzero(np.array(uninterp_df[1]))[0]\n",
    "        flux = np.array(uninterp_df[1][nonzeroflux])\n",
    "    else:\n",
    "        flux = np.array(uninterp_df[1])\n",
    "\n",
    "    ## Estimate initial statistical parameters then remove outliers beyond 5-sigma\n",
    "    try:\n",
    "        flux_mean, flux_stdev = st.norm.fit(np.array(flux), method = \"MM\")\n",
    "        fivesig = 5.0*flux_stdev\n",
    "        flux = [x for x in flux if np.abs(flux_mean - x) <= fivesig]\n",
    "\n",
    "        ## Reestimate statistical parameters without outliers\n",
    "        flux_mean, flux_stdev = st.norm.fit(np.array(flux), method = \"MM\")\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        flux_mean, flux_stdev = np.nanmean(flux), np.sqrt(np.nanvar(flux))\n",
    "    \n",
    "    flux_min = np.nanmin(flux)\n",
    "    flux_max = np.nanmax(flux)\n",
    "        \n",
    "    ###############################################################\n",
    "    \n",
    "    ## Make histograms of data with and without normalization\n",
    "    n, bins = np.histogram(flux, bins=OptBins(flux), range=(flux_min,flux_max), density=False)\n",
    "    bin_err = bin_error(n, bins, flux)\n",
    "      \n",
    "    bin_center = bins[:-1] + np.diff(bins) / 2\n",
    "    maxfreq = np.nanmax(n)\n",
    "    \n",
    "    tick_labels = ticklabels(bin_center)\n",
    "        \n",
    "    ###############################################################\n",
    "    \n",
    "    gauss_fit_good = False\n",
    "    \n",
    "    while gauss_fit_good == False:\n",
    "        \n",
    "        ## Obtain statistical parameters for assumed Gaussian fit\n",
    "        init_params = (np.nanmax(n), flux_mean, flux_stdev)\n",
    "        try:\n",
    "            gauss_pars, _ = curve_fit(gaussian, xdata=bin_center, ydata=n, p0=init_params, sigma=bin_err, maxfev= 1000)#, absolute_sigma = True)\n",
    "        \n",
    "            gauss_m = op.minimize(Min_PDF, [*gauss_pars],\\\n",
    "                                  args=(np.array((n,bins),dtype='object'),gaussian),\\\n",
    "                                  method='Nelder-Mead', bounds = ((0,np.inf),\\\n",
    "                                (gauss_pars[1]-gauss_pars[2],gauss_pars[1]+gauss_pars[2]),(0.0, np.inf)), \\\n",
    "                                  options={'ftol':1e-6,'disp':False})\n",
    "        except:\n",
    "            gauss_m = op.minimize(Min_PDF, [*init_params],\\\n",
    "                                  args=(np.array((n,bins),dtype='object'),gaussian),\\\n",
    "                                  method='Nelder-Mead', bounds = ((0,np.inf),\\\n",
    "                                (np.nanmin(bins),np.nanmax(bins)),(0.0, np.inf)),\\\n",
    "                                  options={'ftol':1e-6,'disp':False})\n",
    "            \n",
    "        gauss_pars = gauss_m['x']\n",
    "        \n",
    "        fit_mean = gauss_pars[1]\n",
    "        fit_stdev = np.abs(gauss_pars[2])\n",
    "        \n",
    "        fit_mean_gauss = gauss_pars[1]\n",
    "        fit_stdev_gauss = np.abs(gauss_pars[2])\n",
    "        \n",
    "        KS = KStest(fit_mean,fit_stdev,flux)\n",
    "                 \n",
    "#         fit_FWHM = 2.0*np.sqrt(2.0*np.log(2.0))*fit_stdev ## assuming gaussian distribution\n",
    "\n",
    "        plt.figure(figsize=(12,6), constrained_layout=True)\n",
    "        # plt.figure(figsize=(15,6))\n",
    "\n",
    "        ## Plot flux histogram as bar chart for special width and error bars\n",
    "        plt.bar(bin_center, n, width = 0.85*(bin_center[1]-bin_center[0]), alpha=0.9, align='center',tick_label=tick_labels)\n",
    "\n",
    "\n",
    "        ## Plot Gaussian fit over histogram\n",
    "        fit_flux = np.linspace(bins[0],bins[-1:],num=500)\n",
    "        \n",
    "        gaussian_fit = gaussian(fit_flux, *gauss_pars)\n",
    "        fit_max = np.nanmax(gaussian_fit)\n",
    "        \n",
    "        c_α = np.sqrt(-0.5*np.log(α/2.))\n",
    "        D_crit = c_α*np.sqrt(2./len(flux))\n",
    "        \n",
    "        plt.axvline(fit_mean,color= 'k',linestyle = 'dashed', label = 'Mean = %.3e\\nσ = %.3e'%(fit_mean,fit_stdev))\n",
    "        \n",
    "        if i < 4 :\n",
    "            if fit_mean+fit_stdev <= flux_max:\n",
    "                plt.text(fit_mean+0.45*fit_stdev,1.07*maxfreq,'σ$_{F}$',fontsize='medium')\n",
    "            else:\n",
    "                plt.text(fit_mean-0.45*fit_stdev,1.07*maxfreq,'σ$_{F}$',fontsize='medium')\n",
    "\n",
    "            plt.suptitle('Flux distibution: '+target)\n",
    "            plt.xlabel('Flux bins', fontsize = 16)\n",
    "\n",
    "        elif i >= 4 :\n",
    "            if fit_mean+fit_stdev <= flux_max:\n",
    "                plt.text(fit_mean+0.45*fit_stdev,1.07*maxfreq,'σ$_{ΔF}$',fontsize='medium')\n",
    "            else:\n",
    "                plt.text(fit_mean-0.45*fit_stdev,1.07*maxfreq,'σ$_{ΔF}$',fontsize='medium')\n",
    "\n",
    "            plt.suptitle('Subsequent Flux distibution: '+target)\n",
    "            plt.xlabel('ΔF$_{ij}$', fontsize = 16)\n",
    "\n",
    "        ## Mark mean +/- stddev\n",
    "        if fit_mean+fit_stdev <= flux_max:\n",
    "            plt.axvline(fit_mean+fit_stdev,color= 'k',linestyle = 'dotted')\n",
    "            plt.annotate(text='', xy=(fit_mean,1.05*maxfreq), xytext=(fit_mean+fit_stdev,1.05*maxfreq),\\\n",
    "                         arrowprops=dict(arrowstyle='<->'))\n",
    "        else:\n",
    "            plt.axvline(fit_mean-fit_stdev,color= 'k',linestyle = 'dotted')\n",
    "            plt.annotate(text='', xy=(fit_mean,1.05*maxfreq), xytext=(fit_mean-fit_stdev,1.05*maxfreq),\\\n",
    "                         arrowprops=dict(arrowstyle='<->'))\n",
    "        \n",
    "        if fit_mean >= bins[-1:][0] or fit_mean <= bins[0]:\n",
    "            # Set a clean x-axis limit.\n",
    "            plt.xlim(xmin = bins[0], xmax = bins[-1:][0])\n",
    "\n",
    "            \n",
    "        if KS[0] <= D_crit:\n",
    "            plt.plot(fit_flux,gaussian_fit,color='g',\\\n",
    "                     label='gaussian fit\\n'+r'$\\frac{D}{D_{crit}}$: %.3e; p: %.3e'%(KS[0]/D_crit,KS[1]))\n",
    "            \n",
    "        else:\n",
    "            plt.plot(fit_flux,gaussian_fit,color='r',\\\n",
    "                     label='gaussian fit\\n'+r'$\\frac{D}{D_{crit}}$: %.3e; p: %.3e'%(KS[0]/D_crit,KS[1]))\n",
    "            \n",
    "            within_bounds = (np.nanmean(flux) - np.sqrt(np.nanvar(flux))) <= flux_mean <= (np.nanmean(flux) - np.sqrt(np.nanvar(flux)))\n",
    "            if 1 <= i <= 3 and within_bounds == True:\n",
    "                flux_mean, fit_stdev, KS = interp_gauss_fit(uninterp_df, df, i,\\\n",
    "                                                            subdir, target, α, sectbysect, group, bin1=bin1, bin2=bin2)\n",
    "            else:\n",
    "                fit_mean_gauss, fit_stdev_gauss, KS = simple_stats(np.array(uninterp_df[1]), i,\\\n",
    "                                                                   subdir, target, α, bins, sectbysect, group, bin1, bin2)\n",
    "            \n",
    "            \n",
    "        plt.legend(fontsize='x-large')\n",
    "\n",
    "        ###############################################################\n",
    "        ## Create or save to new flux distributions directory\n",
    "        try:\n",
    "            directory = os.path.join(subdir, 'flux_distributions')\n",
    "            os.mkdir(directory)\n",
    "\n",
    "            print(\"Directory '%s' created\\n\" %directory)    \n",
    "        except FileExistsError:\n",
    "            directory = subdir+'/flux_distributions'\n",
    "\n",
    "        if sectbysect == True:\n",
    "            save_tail = '_sectors'+group+'.pdf'\n",
    "            try:\n",
    "                directory = os.path.join(subdir, 'flux_distributions/Sector_by_sector')\n",
    "                os.mkdir(directory)\n",
    "\n",
    "                print(\"Directory '%s' created\\n\" %directory)    \n",
    "            except FileExistsError:\n",
    "                directory = subdir+'/flux_distributions/Sector_by_sector'\n",
    "        else:\n",
    "            save_tail = '.pdf'\n",
    "    #         print(directory)\n",
    "        ###############################################################\n",
    "\n",
    "\n",
    "        ## Try to make sure all tick labels show and do not overlap        \n",
    "        if len(n) < 15:\n",
    "            plt.xticks(rotation=30)\n",
    "        else:\n",
    "            plt.xticks(rotation=90)\n",
    "            \n",
    "        plt.tick_params(labelsize = 14)\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.ylabel('Normalized N', fontsize = 16)\n",
    "\n",
    "        # Set a clean upper y-axis limit.\n",
    "        plt.ylim(ymax = 1.15*maxfreq if maxfreq > fit_max else 1.15*fit_max)\n",
    "\n",
    "        # Set a clean 5-sigma x-axis limit.\n",
    "    #     fivesig = 5.0*fit_stdev\n",
    "    #     plt.xlim(xmin = (fit_mean - 1.1*fivesig) if np.abs(fit_mean - np.nanmin(bin_center)) > fivesig else (np.nanmin(bin_center) - 0.1*np.abs(np.nanmin(bin_center))),\\\n",
    "    #         xmax = (fit_mean + 1.1*fivesig) if np.abs(np.nanmax(bin_center) - fit_mean) > fivesig else (np.nanmax(bin_center) + 0.1*np.abs(np.nanmax(bin_center))) )\n",
    "\n",
    "\n",
    "        save_figure(directory,target,save_tail,i,bin1,bin2)\n",
    "        \n",
    "    #         visual = True\n",
    "        if visual == True:\n",
    "            plt.show()\n",
    "\n",
    "            fit_check = input(\"Is gaussian fit satisfactory? [y/n] \")\n",
    "\n",
    "            if fit_check == \"y\" or fit_check == \"Y\" or fit_check == \"yes\" or fit_check == \"YES\":\n",
    "                gauss_fit_good = True\n",
    "            else: \n",
    "                continue\n",
    "        else:\n",
    "            gauss_fit_good = True\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    if i > 1 and i < 4 :\n",
    "        lognorm_fit_good = False\n",
    "        while lognorm_fit_good == False:\n",
    "\n",
    "            lognormal_fit(n, flux, bins, bin_center, bin_err, i, directory, save_tail, bin1, bin2, visual = False)\n",
    "\n",
    "            if visual == True:\n",
    "\n",
    "                fit_check = input(\"Is lognormal fit satisfactory? [y/n] \")\n",
    "\n",
    "                if fit_check == \"y\" or fit_check == \"Y\" or fit_check == \"yes\" or fit_check == \"YES\":\n",
    "                    lognorm_fit_good = True\n",
    "                else: \n",
    "                    continue\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "            else:\n",
    "                lognorm_fit_good = True\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "        bimodal_fit_good = False\n",
    "        while bimodal_fit_good == False:\n",
    "\n",
    "            bimodal_fit(n, flux, bins, bin_center, bin_err, i, directory, save_tail, bin1, bin2, visual = False)\n",
    "\n",
    "            if visual == True:\n",
    "                fit_check = input(\"Is bimodal fit satisfactory? [y/n] \")\n",
    "\n",
    "                if fit_check == \"y\" or fit_check == \"Y\" or fit_check == \"yes\" or fit_check == \"YES\":\n",
    "                    bimodal_fit_good = True\n",
    "                else: \n",
    "                    continue\n",
    "                plt.close()\n",
    "\n",
    "            else:\n",
    "                bimodal_fit_good = True\n",
    "                plt.close()\n",
    "\n",
    "    if 1 <= i <= 3:\n",
    "        return(fit_mean_gauss, fit_stdev_gauss, flux_mean, fit_stdev, flux_min, flux_max, bin_center)\n",
    "    else:\n",
    "        return(fit_mean_gauss, fit_stdev_gauss, flux_min, flux_max, bin_center)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d4db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hyb_samp = ['1RXSJ120417.0-070959','2MASSJ02271658+0202005',\\\n",
    "                 '2MASXJ04390223+0520443','2MASXJ11255199-0742215',\\\n",
    "                 '2MASXJ12571157-1724344','4C+14.23','NGC1218','NVSSJ114117-140447','PKS0217-133','PKS0454+039',\\\n",
    "                 'PKS0855-19','PKS0859-14','PKS1004-217','PKS1045-18','PKS1424-41','PKS1451-375','PKS2142-75',\\\n",
    "                 'WISEJ023951.27+041621.2','WISEJ102243.73-011302.2','WISEJ115217.21-084103.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5382eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample == \"analysis\":\n",
    "    results = 'C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Analysis\\\\LC_variability_analysis.csv'\n",
    "if sample == \"removed\":\n",
    "    results = 'C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Removed_sample\\\\LC_variability_rmv.csv'\n",
    "\n",
    "read_df = pd.read_csv(results)\n",
    "\n",
    "if sample == \"analysis\":\n",
    "    read_df.to_excel('C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Analysis\\\\LC_variability_analysis.xlsx',index=False) \n",
    "if sample == \"removed\":\n",
    "    read_df.to_excel('C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Removed_sample\\\\LC_variability_rmv.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a42f55b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1ES2322-409\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\1ES2322-409\n",
      "\n",
      "Recorded redshift: z = 0.174\n",
      "No recorded BH mass: log(M) = 8.\n",
      "Activity type: BLL\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\1ES2322-409\\lightcurve_datafiles\\1ES2322-409_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Creating file 'LC_variability_analysis.csv'\n",
      "\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.174\n",
      "Full light curve length 23.31 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 0.30 +/- 2.20e-02 days;\n",
      " tau_dec = 0.23 +/- 1.83e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.000e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: 1RXSJ054357.3-553206\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\1RXSJ054357.3-553206\n",
      "\n",
      "Recorded redshift: z = 0.273\n",
      "No recorded BH mass: log(M) = 8.\n",
      "Activity type: BLL\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\1RXSJ054357.3-553206\\lightcurve_datafiles\\1RXSJ054357.3-553206_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.273\n",
      "Full light curve length 280.46 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "Comparing point 1500\n",
      "Comparing point 2000\n",
      "Comparing point 2500\n",
      "Comparing point 3000\n",
      "Comparing point 3500\n",
      "Comparing point 4000\n",
      "Comparing point 4500\n",
      "Comparing point 5000\n",
      "Comparing point 5500\n",
      "Comparing point 6000\n",
      "Comparing point 6500\n",
      "Comparing point 7000\n",
      "Comparing point 7500\n",
      "Comparing point 8000\n",
      "Comparing point 8500\n",
      "Comparing point 9000\n",
      "Comparing point 9500\n",
      "Comparing point 10000\n",
      "Comparing point 10500\n",
      "Comparing point 11000\n",
      "Comparing point 11500\n",
      "tau_inc = 0.53 +/- 6.93e-02 days;\n",
      " tau_dec = 0.77 +/- 1.18e-01 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.000e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: 3C120\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\3C120\n",
      "\n",
      "Recorded redshift: z = 0.033\n",
      "No recorded BH mass: log(M) = 8.\n",
      "Activity type: FSRQ\n",
      "Recorded doppler factor: δ = 4.160\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\3C120\\lightcurve_datafiles\\3C120_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.033\n",
      "Full light curve length 24.20 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 0.55 +/- 2.17e-02 days;\n",
      " tau_dec = 0.56 +/- 2.22e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 4.16\n",
      "M_BH ~ 1.000e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: NGC1218\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\NGC1218\n",
      "\n",
      "Recorded redshift: z = 0.028\n",
      "No recorded BH mass: log(M) = 8.\n",
      "Activity type: BLL\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\NGC1218\\lightcurve_datafiles\\NGC1218_cycle1_full_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.028\n",
      "Full light curve length 24.37 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 130.60 +/- 3.43e+01 days;\n",
      " tau_dec = 113.66 +/- 2.33e+01 days\n",
      "\n",
      "\n",
      "Smoothing light curve with FWHM = 1\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 34.92 +/- 7.00e+00 days;\n",
      " tau_dec = 65.07 +/- 2.01e+01 days\n",
      "\n",
      "\n",
      "Smoothing light curve with FWHM = 0\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 8.79 +/- 1.99e+00 days;\n",
      " tau_dec = 9.69 +/- 2.43e+00 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.000e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0035-252\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0035-252\n",
      "\n",
      "Recorded redshift: z = 0.498\n",
      "Recorded BH mass: log(M) = 8.14 +/- 0.23\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0035-252\\lightcurve_datafiles\\PKS0035-252_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.498\n",
      "Full light curve length 14.87 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 0.08 +/- 2.64e-03 days;\n",
      " tau_dec = 0.13 +/- 4.48e-03 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.380e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0130-17\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0130-17\n",
      "\n",
      "Recorded redshift: z = 1.020\n",
      "Recorded BH mass: log(M) = 8.66 +/- 0.66\n",
      "Activity type: FSRQ\n",
      "Recorded doppler factor: δ = 12.530\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0130-17\\lightcurve_datafiles\\PKS0130-17_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 1.020\n",
      "Full light curve length 11.03 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 0.23 +/- 3.09e-02 days;\n",
      " tau_dec = 0.23 +/- 1.97e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 12.53\n",
      "M_BH ~ 4.571e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0208-512\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0208-512\n",
      "\n",
      "Recorded redshift: z = 0.999\n",
      "Recorded BH mass: log(M) = 9.12 +/- 0.20\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0208-512\\lightcurve_datafiles\\PKS0208-512_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.999\n",
      "Full light curve length 25.97 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "Comparing point 1500\n",
      "Comparing point 2000\n",
      "tau_inc = 0.27 +/- 4.72e-02 days;\n",
      " tau_dec = 0.24 +/- 3.31e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.318e+09 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0226-559\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0226-559\n",
      "\n",
      "Recorded redshift: z = 2.464\n",
      "No recorded BH mass: log(M) = 8.\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0226-559\\lightcurve_datafiles\\PKS0226-559_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 2.464\n",
      "Full light curve length 14.98 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "Comparing point 1500\n",
      "Comparing point 2000\n",
      "tau_inc = 0.07 +/- 1.90e-02 days;\n",
      " tau_dec = 0.05 +/- 1.87e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.000e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0235-618\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0235-618\n",
      "\n",
      "Recorded redshift: z = 0.467\n",
      "Recorded BH mass: log(M) = 7.46 +/- 0.11\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0235-618\\lightcurve_datafiles\\PKS0235-618_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.467\n",
      "Full light curve length 55.09 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "Comparing point 1500\n",
      "Comparing point 2000\n",
      "Comparing point 2500\n",
      "Comparing point 3000\n",
      "tau_inc = 0.51 +/- 5.75e-02 days;\n",
      " tau_dec = 0.81 +/- 8.45e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 2.884e+07 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0301-243\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0301-243\n",
      "\n",
      "Recorded redshift: z = 0.266\n",
      "No recorded BH mass: log(M) = 8.\n",
      "Activity type: BLL\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0301-243\\lightcurve_datafiles\\PKS0301-243_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.266\n",
      "Full light curve length 19.80 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 1.55 +/- 4.34e-01 days;\n",
      " tau_dec = 0.75 +/- 9.64e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.000e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0336-177\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0336-177\n",
      "\n",
      "Recorded redshift: z = 0.066\n",
      "Recorded BH mass: log(M) = 8.98 +/- 0.13\n",
      "Activity type: BLL\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0336-177\\lightcurve_datafiles\\PKS0336-177_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.066\n",
      "Full light curve length 23.64 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 41.95 +/- 1.05e+01 days;\n",
      " tau_dec = 4.70 +/- 1.10e+00 days\n",
      "\n",
      "\n",
      "Smoothing light curve with FWHM = 1\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 29.59 +/- 7.46e+00 days;\n",
      " tau_dec = 4.70 +/- 1.10e+00 days\n",
      "\n",
      "\n",
      "Smoothing light curve with FWHM = 0\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 1.98 +/- 5.79e-01 days;\n",
      " tau_dec = 1.79 +/- 4.74e-01 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 9.550e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0346-27\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0346-27\n",
      "\n",
      "Recorded redshift: z = 0.991\n",
      "Recorded BH mass: log(M) = 8.54 +/- 0.10\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0346-27\\lightcurve_datafiles\\PKS0346-27_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.991\n",
      "Full light curve length 12.59 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 0.16 +/- 2.54e-02 days;\n",
      " tau_dec = 0.12 +/- 2.50e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 3.467e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0420-01\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0420-01\n",
      "\n",
      "Recorded redshift: z = 0.916\n",
      "Recorded BH mass: log(M) = 8.40 +/- 0.23\n",
      "Activity type: FSRQ\n",
      "Recorded doppler factor: δ = 5.310\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0420-01\\lightcurve_datafiles\\PKS0420-01_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.916\n",
      "Full light curve length 12.94 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 0.12 +/- 4.66e-02 days;\n",
      " tau_dec = 0.37 +/- 4.88e+00 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 5.31\n",
      "M_BH ~ 2.512e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0422+00\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0422+00\n",
      "\n",
      "Recorded redshift: z = 0.310\n",
      "No recorded BH mass: log(M) = 8.\n",
      "Activity type: BLL\n",
      "Recorded doppler factor: δ = 5.730\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0422+00\\lightcurve_datafiles\\PKS0422+00_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.310\n",
      "Full light curve length 19.00 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 1.55 +/- 3.59e-01 days;\n",
      " tau_dec = 1.42 +/- 3.59e-01 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 5.73\n",
      "M_BH ~ 1.000e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0426-380\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0426-380\n",
      "\n",
      "Recorded redshift: z = 1.105\n",
      "Recorded BH mass: log(M) = 8.77 +/- 0.37\n",
      "Activity type: BLL\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0426-380\\lightcurve_datafiles\\PKS0426-380_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 1.105\n",
      "Full light curve length 24.95 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "Comparing point 1500\n",
      "tau_inc = 0.29 +/- 6.36e-02 days;\n",
      " tau_dec = 0.21 +/- 4.41e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 5.888e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0454-234\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0454-234\n",
      "\n",
      "Recorded redshift: z = 1.003\n",
      "Recorded BH mass: log(M) = 8.33 +/- 0.14\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0454-234\\lightcurve_datafiles\\PKS0454-234_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 1.003\n",
      "Full light curve length 12.44 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 0.71 +/- 1.08e-01 days;\n",
      " tau_dec = 0.90 +/- 2.13e-01 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 2.138e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0521-36\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0521-36\n",
      "\n",
      "Recorded redshift: z = 0.057\n",
      "Recorded BH mass: log(M) = 7.79 +/- 0.28\n",
      "Activity type: BLL\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0521-36\\lightcurve_datafiles\\PKS0521-36_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.057\n",
      "Full light curve length 48.80 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "Comparing point 1500\n",
      "Comparing point 2000\n",
      "tau_inc = 0.25 +/- 7.81e-03 days;\n",
      " tau_dec = 0.48 +/- 1.87e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 6.166e+07 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0637-75\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0637-75\n",
      "\n",
      "Recorded redshift: z = 0.653\n",
      "Recorded BH mass: log(M) = 8.51 +/- 0.24\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing spliced sectors 1+2+3 from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0637-75\\PKS0637-75_spliced_lightcurve_sectors_1+2+3.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.653\n",
      "Full light curve length 48.84 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "Comparing point 1500\n",
      "Comparing point 2000\n",
      "Comparing point 2500\n",
      "Comparing point 3000\n",
      "tau_inc = 12.75 +/- 2.94e+00 days;\n",
      " tau_dec = 24.82 +/- 8.20e+00 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 3.236e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0637-75\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0637-75\n",
      "\n",
      "Recorded redshift: z = 0.653\n",
      "Recorded BH mass: log(M) = 8.51 +/- 0.24\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing spliced sectors 4+5+6 from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0637-75\\PKS0637-75_spliced_lightcurve_sectors_4+5+6.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.653\n",
      "Full light curve length 47.85 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "Comparing point 1500\n",
      "Comparing point 2000\n",
      "Comparing point 2500\n",
      "tau_inc = 2.02 +/- 7.26e-01 days;\n",
      " tau_dec = 1.41 +/- 1.65e-01 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 3.236e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0637-75\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0637-75\n",
      "\n",
      "Recorded redshift: z = 0.653\n",
      "Recorded BH mass: log(M) = 8.51 +/- 0.24\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing spliced sectors 7+8+9 from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0637-75\\PKS0637-75_spliced_lightcurve_sectors_7+8+9.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.653\n",
      "Full light curve length 46.14 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "Comparing point 1500\n",
      "Comparing point 2000\n",
      "Comparing point 2500\n",
      "tau_inc = 14.55 +/- 4.19e+00 days;\n",
      " tau_dec = 9.35 +/- 2.38e+00 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 3.236e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0736+01\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0736+01\n",
      "\n",
      "Recorded redshift: z = 0.189\n",
      "Recorded BH mass: log(M) = 8.51 +/- 0.24\n",
      "Activity type: FSRQ\n",
      "Recorded doppler factor: δ = 11.440\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0736+01\\lightcurve_datafiles\\PKS0736+01_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.189\n",
      "Full light curve length 20.25 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing point 500\n",
      "tau_inc = 0.02 +/- 4.80e-04 days;\n",
      " tau_dec = 0.03 +/- 5.95e-04 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.44\n",
      "M_BH ~ 3.236e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS0829+046\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0829+046\n",
      "\n",
      "Recorded redshift: z = 0.174\n",
      "Recorded BH mass: log(M) = 8.51 +/- 0.24\n",
      "Activity type: FSRQ\n",
      "Recorded doppler factor: δ = 5.940\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS0829+046\\lightcurve_datafiles\\PKS0829+046_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.174\n",
      "Full light curve length 20.43 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 0.22 +/- 2.87e-02 days;\n",
      " tau_dec = 0.30 +/- 3.56e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 5.94\n",
      "M_BH ~ 3.236e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS1244-255\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS1244-255\n",
      "\n",
      "Recorded redshift: z = 0.633\n",
      "Recorded BH mass: log(M) = 8.04 +/- 0.29\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS1244-255\\lightcurve_datafiles\\PKS1244-255_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.633\n",
      "Full light curve length 14.59 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 0.19 +/- 3.84e-02 days;\n",
      " tau_dec = 0.24 +/- 4.11e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.096e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS2155-304\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS2155-304\n",
      "\n",
      "Recorded redshift: z = 0.117\n",
      "Recorded BH mass: log(M) = 7.00 +/- 0.26\n",
      "Activity type: BLL\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS2155-304\\lightcurve_datafiles\\PKS2155-304_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.117\n",
      "Full light curve length 24.55 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 0.39 +/- 1.85e-02 days;\n",
      " tau_dec = 0.38 +/- 1.47e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.000e+07 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS2155-83\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS2155-83\n",
      "\n",
      "Recorded redshift: z = 1.865\n",
      "Recorded BH mass: log(M) = 7.77 +/- 0.26\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS2155-83\\lightcurve_datafiles\\PKS2155-83_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 1.865\n",
      "Full light curve length 9.90 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 0.06 +/- 1.26e-02 days;\n",
      " tau_dec = 0.02 +/- 1.32e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 5.888e+07 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS2255-282\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS2255-282\n",
      "\n",
      "Recorded redshift: z = 0.926\n",
      "Recorded BH mass: log(M) = 8.91 +/- 0.22\n",
      "Activity type: BLL\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS2255-282\\lightcurve_datafiles\\PKS2255-282_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.926\n",
      "Full light curve length 13.26 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 0.15 +/- 1.49e-02 days;\n",
      " tau_dec = 0.08 +/- 1.15e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 8.128e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS2326-502\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS2326-502\n",
      "\n",
      "Recorded redshift: z = 0.518\n",
      "Recorded BH mass: log(M) = 9.11 +/- 0.22\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS2326-502\\lightcurve_datafiles\\PKS2326-502_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.518\n",
      "Full light curve length 36.60 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "Comparing point 1500\n",
      "Comparing point 2000\n",
      "tau_inc = 0.09 +/- 3.28e-02 days;\n",
      " tau_dec = 0.19 +/- 7.59e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.288e+09 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PKS2345-16\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS2345-16\n",
      "\n",
      "Recorded redshift: z = 0.576\n",
      "Recorded BH mass: log(M) = 9.07 +/- 0.19\n",
      "Activity type: FSRQ\n",
      "Recorded doppler factor: δ = 16.580\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PKS2345-16\\lightcurve_datafiles\\PKS2345-16_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.576\n",
      "Full light curve length 16.85 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 0.11 +/- 1.75e-02 days;\n",
      " tau_dec = 0.07 +/- 1.27e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 16.58\n",
      "M_BH ~ 1.175e+09 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PMNJ0948+0022\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PMNJ0948+0022\n",
      "\n",
      "Recorded redshift: z = 0.584\n",
      "No recorded BH mass: log(M) = 8.\n",
      "Activity type: FSRQ\n",
      "Recorded doppler factor: δ = 29.770\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PMNJ0948+0022\\lightcurve_datafiles\\PMNJ0948+0022_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.584\n",
      "Full light curve length 14.76 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 0.01 +/- 8.65e-03 days;\n",
      " tau_dec = 0.01 +/- 2.41e-03 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 29.77\n",
      "M_BH ~ 1.000e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PMNJ2141-6411\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PMNJ2141-6411\n",
      "\n",
      "Recorded redshift: z = 0.959\n",
      "Recorded BH mass: log(M) = 8.44 +/- 0.25\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PMNJ2141-6411\\lightcurve_datafiles\\PMNJ2141-6411_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.959\n",
      "Full light curve length 14.21 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 0.17 +/- 7.78e-02 days;\n",
      " tau_dec = 0.16 +/- 1.16e-01 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 2.754e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: PMNJ2345-1555\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PMNJ2345-1555\n",
      "\n",
      "Recorded redshift: z = 0.621\n",
      "Recorded BH mass: log(M) = 7.85 +/- 0.14\n",
      "Activity type: FSRQ\n",
      "Recorded doppler factor: δ = 30.230\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\PMNJ2345-1555\\lightcurve_datafiles\\PMNJ2345-1555_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.621\n",
      "Full light curve length 16.88 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "Comparing point 1000\n",
      "tau_inc = 0.05 +/- 8.72e-03 days;\n",
      " tau_dec = 0.02 +/- 3.35e-03 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 30.23\n",
      "M_BH ~ 7.079e+07 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: WISEJ031612.72+090443.3\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\WISEJ031612.72+090443.3\n",
      "\n",
      "Recorded redshift: z = 0.372\n",
      "No recorded BH mass: log(M) = 8.\n",
      "Activity type: FSRQ\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\WISEJ031612.72+090443.3\\lightcurve_datafiles\\WISEJ031612.72+090443.3_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.372\n",
      "Full light curve length 18.45 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 10.30 +/- 2.60e+00 days;\n",
      " tau_dec = 3.05 +/- 5.23e-01 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.000e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: WISEJ085009.64-121335.3\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\WISEJ085009.64-121335.3\n",
      "\n",
      "Recorded redshift: z = 0.566\n",
      "Recorded BH mass: log(M) = 8.51 +/- 0.27\n",
      "Activity type: FSRQ\n",
      "Recorded doppler factor: δ = 17.870\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\WISEJ085009.64-121335.3\\lightcurve_datafiles\\WISEJ085009.64-121335.3_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.566\n",
      "Full light curve length 14.87 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 0.04 +/- 1.70e-02 days;\n",
      " tau_dec = 0.08 +/- 2.21e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 17.87\n",
      "M_BH ~ 3.236e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: WISEJ095302.70-084018.2\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\WISEJ095302.70-084018.2\n",
      "\n",
      "Recorded redshift: z = 0.400\n",
      "No recorded BH mass: log(M) = 8.\n",
      "Activity type: BLL\n",
      "No recorded doppler factor: δ = 11.\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\WISEJ095302.70-084018.2\\lightcurve_datafiles\\WISEJ095302.70-084018.2_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.400\n",
      "Full light curve length 16.74 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n",
      "Comparing point 500\n",
      "tau_inc = 0.61 +/- 1.19e-01 days;\n",
      " tau_dec = 0.96 +/- 5.64e-01 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 11.00\n",
      "M_BH ~ 1.000e+08 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n",
      "Target: WISEJ105912.43-113422.6\n",
      "\n",
      "Working in directory: C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\WISEJ105912.43-113422.6\n",
      "\n",
      "Recorded redshift: z = 0.000\n",
      "Recorded BH mass: log(M) = 9.07 +/- 0.36\n",
      "Activity type: FSRQ\n",
      "Recorded doppler factor: δ = 27.290\n",
      "Analyzing full light curve from file 'C:\\Users\\rdingler\\Desktop\\AGNstudy\\LightCurves\\Analysis\\WISEJ105912.43-113422.6\\lightcurve_datafiles\\WISEJ105912.43-113422.6_cycle1_hybrid_lc.dat'\n",
      "\n",
      "Finding shortest time scales of variablity. This may take a while for long light curves.\n",
      "adjusting time with redshift z = 0.000\n",
      "Full light curve length 23.27 days\n",
      "\n",
      "Smoothing light curve with FWHM = 2\n",
      "Comparing point 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing point 500\n",
      "tau_inc = 0.08 +/- 1.50e-02 days;\n",
      " tau_dec = 0.10 +/- 1.63e-02 days\n",
      "\n",
      "Estimating emission region radius\n",
      "c=2.998e+08 m/s; G=6.674e-11 m^3/(kg s^2)\n",
      "\n",
      "Doppler factor: δ ~ 27.29\n",
      "M_BH ~ 1.175e+09 solar mass\n",
      "\n",
      "Rebinning.\n",
      "\n",
      "\n",
      "Fitting histograms of flux data\n",
      "\n",
      "Calculating excess variance within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating RMS-Flux relation within 6 hr and 12 hr bins\n",
      "\n",
      "Calculating excess variance of full light curves\n",
      "\n",
      "Fitting histograms of change in flux data\n",
      "\n",
      "Calculating chi-squared/dof\n",
      "\n",
      "Saving data\n",
      "\n",
      "Moving to next object\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\ryned\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Analysis\\\\LC_variability_analysis.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 605\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremoved\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    603\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mryned\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mAGNstudy\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLightCurves\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRemoved_sample\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLC_variability_rmv.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 605\u001b[0m read_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(results)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manalysis\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    608\u001b[0m     read_df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mryned\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mAGNstudy\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLightCurves\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mAnalysis\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLC_variability_analysis.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ryned\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Analysis\\\\LC_variability_analysis.csv'"
     ]
    }
   ],
   "source": [
    "###########################################################################################################################################\n",
    "###########################################################################################################################################\n",
    "###########################################################################################################################################\n",
    "\n",
    "## Begin by setting the driectory in which the target files are kept as rootdir\n",
    "\n",
    "## Choose sample \"analysis\" or \"removed\"\n",
    "sample = \"analysis\"\n",
    "# sample = \"removed\"\n",
    "\n",
    "if sample == \"analysis\":\n",
    "    rootdir = 'C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Analysis\\\\'\n",
    "if sample == \"removed\":\n",
    "    rootdir = 'C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Removed_sample\\\\'\n",
    "\n",
    "## User should specficy whether thay would like a secondary data sheet with user-specified modification\n",
    "## Specify modifications at bottom of program\n",
    "## May prove useful for very large or very small numbers\n",
    "adj = True  \n",
    "\n",
    "\n",
    "## Set cycle number and Pricipal Component Method\n",
    "# pcm == 1: principal component analysis\n",
    "# pcm == 2: simple hybrid method\n",
    "# pcm == 3: full hybrid method\n",
    "\n",
    "cycle = '1'\n",
    "\n",
    "## Set binning schema for binned light curve analysis in hours\n",
    "bin1 = '6' #hrs\n",
    "bin2 = '12' #hrs \n",
    "\n",
    "## Set some specific designation which will be used later to identify the spliced light curves as output by quaver\n",
    "## This will pick these files for use if provided. If not available, say, in the case of sector by sector analysis\n",
    "## wherein this file is the etire light curve, this will help the algorithm to know that it needs to collect and \n",
    "## synthesize each sector as specified by the user. User should write use the definition above for \"lc_stitch\"\n",
    "## to manually make stitched light curves for their desired sector groupings if not individual.\n",
    "    \n",
    "file_mid = '_spliced_lightcurve_sectors_'\n",
    "\n",
    "## Counting as preventative measure when only wanting to do a limited number of files. Disable if all files should be read.\n",
    "count = 0\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    \n",
    "    count += 1\n",
    "    # if count == 2:\n",
    "    #     sys.exit()\n",
    "     \n",
    "    ## Get target name from subdirectory name\n",
    "    target = os.path.basename(subdir)\n",
    "    if \"1ES\" in target or \"PKS\" in target or \"PMNJ\" in target or \"3C\" in target or \"4C\" in target or \"NVSS\" in target\\\n",
    "        or \"1RXS\" in target or \"2MAS\" in target or \"WISE\" in target or \"NGC\" in target:\n",
    "        files = np.concatenate([glob.glob(subdir+'/**.dat'),glob.glob(subdir+'/**/**.dat')],axis = 0) #glob.glob(subdir+'/**/**.dat') #\n",
    "\n",
    "    ## Initialize arrays for plotting\n",
    "        for file in files:\n",
    "            pcm = 2\n",
    "            for x in full_hyb_samp:\n",
    "                if target in x: \n",
    "                    pcm = 3\n",
    "                    \n",
    "            if pcm == 1: \n",
    "                file_tail = '_cycle'+cycle+'_PCA_lc.dat'\n",
    "            if pcm == 2: \n",
    "                file_tail = '_cycle'+cycle+'_hybrid_lc.dat'\n",
    "            if pcm == 3: \n",
    "                file_tail = '_cycle'+cycle+'_full_hybrid_lc.dat'\n",
    "\n",
    "            sectbysect = False\n",
    "    #          rmv_file_denote = ''\n",
    "    #         if file.endswith('rmv_file_denote'):  ## lines only included in case of cleanup\n",
    "    #             os.remove(os.path.join(subdir,file))\n",
    "\n",
    "            if file.endswith(file_tail) or file_mid in file:\n",
    "                ## When walking through directories, make sure to specify which directory names are not to be included\n",
    "                ## User should make sure this method works for their arrangement of quaver output files and any other\n",
    "                ## preliminary data stored in the same directory as the quaver output\n",
    "                \n",
    "                print(\"Target: %s\"%target)\n",
    "\n",
    "                print(\"\\nWorking in directory: %s\\n\"%subdir)\n",
    "                \n",
    "                temp = pd.read_excel('C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\sample_data.xlsx')\n",
    "                z = float(temp.loc[np.where(temp['Target'] == target)[0][0],'redshift'])\n",
    "                print(\"Recorded redshift: z = %.3f\"%z)\n",
    "                M = float(temp.loc[np.where(temp['Target'] == target)[0][0],'log(M_BH)'])\n",
    "                ΔM = float(temp.loc[np.where(temp['Target'] == target)[0][0],'Δlog(M_BH)'])\n",
    "                if M == 0:\n",
    "                    M = 8.\n",
    "                    ΔM = -1.\n",
    "                    print(\"No recorded BH mass: log(M) = 8.\")\n",
    "                else:\n",
    "                    print(\"Recorded BH mass: log(M) = %.2f +/- %.2f\"%(M,ΔM))\n",
    "                activity = str(temp.loc[np.where(temp['Target'] == target)[0][0],'Type'])\n",
    "                print(\"Activity type: %s\"%activity)\n",
    "                doppler = float(temp.loc[np.where(temp['Target'] == target)[0][0],'Doppler'])\n",
    "                if doppler == 0.:\n",
    "                    doppler = 11.\n",
    "                    print(\"No recorded doppler factor: δ = 11.\")\n",
    "                else:\n",
    "                    print(\"Recorded doppler factor: δ = %.3f\"%doppler)\n",
    "\n",
    "\n",
    "                group = ''\n",
    "\n",
    "                raw_df = []\n",
    "                try:\n",
    "                    if file_mid in file: ## if True, this object is designated for sector by sector analysis by user-specified designation\n",
    "                        sectbysect = True\n",
    "                        unstitched_lc = []\n",
    "\n",
    "                        group = file.partition('sectors_')[2].partition('.dat')[0]\n",
    "                        print(\"Analyzing spliced sectors \"+group+\" from file '%s\"%file+\"'\")\n",
    "                        sectors = np.array([s for s in group.split('+')])\n",
    "                        for sector in sectors:\n",
    "                            raw_df = pd.read_table(glob.glob(subdir+'/**/**sector'+sector+'_raw_lc.dat')[0],\\\n",
    "                                                   sep = ' ', header=None, dtype='float')\n",
    "                            unstitched_lc.append(np.column_stack((raw_df[0],raw_df[1],raw_df[2])))\n",
    "\n",
    "                        t_raw, f_raw, e_raw = lc_stitch(unstitched_lc)\n",
    "                        raw_df = pd.DataFrame(np.column_stack((t_raw,f_raw,e_raw)),columns = None, index = None)\n",
    "\n",
    "                    else:\n",
    "                        print(\"Analyzing full light curve from file '%s\"%file+\"'\")\n",
    "#                         print(glob.glob(subdir+'/**/'+target+'_full_raw_lc.dat'))\n",
    "                        \n",
    "                        raw_df = pd.read_table(glob.glob(subdir+'/**/**raw_lc.dat')[0], sep = ' ',\\\n",
    "                                               header=None, dtype='float')\n",
    "\n",
    "                    raw = True\n",
    "                except:\n",
    "                    raw = False\n",
    "\n",
    "                check_col_label(rootdir,str(bin1),str(bin2),sample = sample, raw = raw)\n",
    "\n",
    "                if sample == \"analysis\":\n",
    "                    lc_data = open(os.path.join(rootdir,'LC_variability_analysis.csv') , \"a\", newline='', encoding='utf-8')\n",
    "                elif sample == \"removed\":\n",
    "                    lc_data = open(os.path.join(rootdir,'LC_variability_rmv.csv') , \"a\", newline='', encoding='utf-8')\n",
    "\n",
    "                writer = csv.writer(lc_data)\n",
    "\n",
    "                uninterp_df = pd.read_table(os.path.join(subdir, file), sep = ' ', header=None, dtype='float')\n",
    "\n",
    "\n",
    "    ###############################################################################################             \n",
    "    ## Find shortest timescales of variability in days\n",
    "                print(\"\\nFinding shortest time scales of variablity. This may take a while for long light curves.\")        \n",
    "                tau_dec_min, err_tau_dec, delt_dec_min, timescale_dec_min,\\\n",
    "                    tau_inc_min, err_tau_inc, delt_inc_min, timescale_inc_min = shortest_timescale(rootdir,target,\\\n",
    "                                                                                uninterp_df,z,sectbysect,sectors=group)\n",
    "                \n",
    "#                 tau_dec_min, delt_dec_min, err_tau_dec, timescale_dec_min,\\\n",
    "#                         tau_inc_min, delt_inc_min, err_tau_inc, timescale_inc_min = shortest_timescale(rootdir,target,uninterp_df,z,sectbysect,sectors=group)\n",
    "                    #######################################################################################\n",
    "                \n",
    "                if (timescale_dec_min < timescale_inc_min) &\\\n",
    "                    (err_tau_dec <= (np.array(uninterp_df[0])[-1] - np.array(uninterp_df[0])[0])):\n",
    "                \n",
    "                    timescale = tau_dec_min ## Shortest timescale of variability in days\n",
    "                    scale_error = err_tau_dec\n",
    "                    \n",
    "                elif (timescale_dec_min > timescale_inc_min) &\\\n",
    "                    (err_tau_inc <= (np.array(uninterp_df[0])[-1] - np.array(uninterp_df[0])[0])):\n",
    "                    \n",
    "                    timescale = tau_inc_min ## Shortest timescale of variability in days\n",
    "                    scale_error = err_tau_inc\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    timescale = np.nanmin([tau_inc_min, tau_dec_min]) ## Shortest timescale of variability in days\n",
    "                    scale_error = 0.\n",
    "                \n",
    "#                 T_int = 5e10\n",
    "#                 if activity == \"BLL\":\n",
    "#                     T_var = 10**np.log10(T_int * 6.25**3)\n",
    "#                     doppler = (1.+z)*np.cbrt(T_var/T_int)\n",
    "#                 elif activity == \"FSRQ\":\n",
    "#                     T_var = 10**np.log10(T_int * 14.61**3)\n",
    "#                     doppler = (1.+z)*np.cbrt(T_var/T_int)\n",
    "#                 else:\n",
    "#                     doppler = 10.0\n",
    "                \n",
    "                R_low, R_appox, R_high, Rs_low, Rs_appox, Rs_high\\\n",
    "                                        = radii_range(timescale, scale_error, z, δ = doppler,\\\n",
    "                                                      Mbh = 10**M, delM = np.log(10)*M*ΔM, u_mass = 'sol') ## calculate range of BH radii assumin Mbh = 10^8 solar mass doppler =10\n",
    "#             #     R9_low, R9, R9_high, Rs9_low, Rs9, Rs9_high  = radii_range(timescale, error, z, δ = 10.0, Mbh = 1e9, u_mass = 'sol')\n",
    "\n",
    "    ############################################################################################### \n",
    "    ## Find (Smith 2018) statistics and check flux-change distribution, \n",
    "    ## as well as comparing the flux-change in the unbinned raw vs the unbinned corrected data\n",
    "\n",
    "                df = interpolate_data(target,uninterp_df, pcm = pcm, directory = subdir)\n",
    "                binnedflux_bin1, binnedflux_bin2 = rebinning(df,float(bin1),float(bin2))\n",
    "\n",
    "                print(\"\\nFitting histograms of flux data\")\n",
    "                for i in range(0,4):\n",
    "                    if i == 0 and raw == True:\n",
    "                        flux_raw_mean, flux_raw_stdev, flux_raw_min , flux_raw_max,\\\n",
    "                        flux_raw_bins = hist_and_fit(raw_df,df,i,subdir,target,sectbysect,group)\n",
    "                    if i == 1:\n",
    "                        lc_reg_mean, lc_reg_stdev, flux_reg_mean, flux_reg_stdev, flux_reg_min , flux_reg_max,\\\n",
    "                        flux_reg_bins = hist_and_fit(uninterp_df,df,i,subdir,target,sectbysect,group)\n",
    "                    if i == 2:\n",
    "                        lc_bin1_mean, lc_bin1_stdev, flux_bin1_mean, flux_bin1_stdev, flux_bin1_min , flux_bin1_max,\\\n",
    "                        flux_bin1_bins = hist_and_fit(binnedflux_bin1,df,i,\\\n",
    "                                                      subdir,target,sectbysect,group,bin1=bin1,bin2=bin2)\n",
    "                    if i == 3:\n",
    "                        lc_bin2_mean, lc_bin2_stdev, flux_bin2_mean, flux_bin2_stdev, flux_bin2_min , flux_bin2_max,\\\n",
    "                        flux_bin2_bins = hist_and_fit(binnedflux_bin2,df,i,\\\n",
    "                                                      subdir,target,sectbysect,group,bin1=bin1,bin2=bin2)\n",
    "\n",
    "    #######################################################################################\n",
    "    ## Excess variance and fractional rms amplitude calculations for intrabin data\n",
    "\n",
    "                print(\"\\nCalculating excess variance within %s hr and %s hr bins\"%(bin1,bin2))\n",
    "                Xvar_bin1, RMSvar_bin1,\\\n",
    "                    XvarErr_bin1, RMSvarErr_bin1 = calc_excess_variance(binnedflux_bin1[0],binnedflux_bin1[1],binnedflux_bin1[2],\\\n",
    "                        flux_mean = flux_bin1_mean, stdev = binnedflux_bin1[3],\\\n",
    "                            len_lc = binnedflux_bin1[4], MSE = binnedflux_bin1[5] ,\\\n",
    "                                MSE_err = binnedflux_bin1[6] , total = False)\n",
    "                \n",
    "                idx = np.where((Xvar_bin1 != 0.) & (np.isfinite(Xvar_bin1)))[0]\n",
    "                \n",
    "                Xvar_bin1_mean = np.nanmean(Xvar_bin1[idx])\n",
    "                RMSvar_bin1_mean = np.nanmean(RMSvar_bin1[idx])\n",
    "\n",
    "                plot_excess_variance(subdir, uninterp_df, binnedflux_bin1, Xvar_bin1, XvarErr_bin1, Xvar_bin1_mean,\\\n",
    "                                     RMSvar_bin1, RMSvarErr_bin1, RMSvar_bin1_mean, bin1, sectbysect, group)\n",
    "\n",
    "\n",
    "\n",
    "                ##########################################################################\n",
    "                ##########################################################################\n",
    "\n",
    "\n",
    "                Xvar_bin2, RMSvar_bin2,\\\n",
    "                    XvarErr_bin2, RMSvarErr_bin2 = calc_excess_variance(binnedflux_bin2[0],binnedflux_bin2[1],binnedflux_bin2[2],\\\n",
    "                        flux_mean = flux_bin2_mean, stdev = binnedflux_bin2[3],\\\n",
    "                            len_lc = binnedflux_bin2[4], MSE = binnedflux_bin2[5] ,\\\n",
    "                                MSE_err = binnedflux_bin2[6] , total = False)\n",
    "                \n",
    "                idx = np.where((Xvar_bin2 != 0.) & (np.isfinite(Xvar_bin2)))[0]\n",
    "                \n",
    "                Xvar_bin2_mean = np.nanmean(Xvar_bin2[idx])\n",
    "                RMSvar_bin2_mean = np.nanmean(RMSvar_bin2[idx])\n",
    "\n",
    "                plot_excess_variance(subdir, uninterp_df, binnedflux_bin2, Xvar_bin2, XvarErr_bin2, Xvar_bin2_mean,\\\n",
    "                                     RMSvar_bin2, RMSvarErr_bin2, RMSvar_bin2_mean, bin2, sectbysect, group)\n",
    "\n",
    "\n",
    "                ##############################################################################################################################\n",
    "                ## Plot and save resultant RMS-Flux relation \n",
    "                print(\"\\nCalculating RMS-Flux relation within %s hr and %s hr bins\"%(bin1,bin2))\n",
    "\n",
    "                idx = np.isfinite(binnedflux_bin1[1]) & np.isfinite(binnedflux_bin1[7]) & np.greater(binnedflux_bin1[7],0.)\n",
    "                rms_flux = np.array((binnedflux_bin1[1][idx], binnedflux_bin1[7][idx], binnedflux_bin1[8][idx]))\n",
    "\n",
    "                try:\n",
    "                    line1 = np.polyfit(rms_flux[0], rms_flux[1], 1)\n",
    "                    plt.errorbar(rms_flux[0], rms_flux[1],\\\n",
    "                                 yerr = rms_flux[2], color='r', label=bin1+'hr bins, α = %.2e'%line1[0],\\\n",
    "                                 alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "\n",
    "                    x1 = np.linspace(np.nanmin(rms_flux[0]), np.nanmax(rms_flux[0]), num=200)\n",
    "                except: \n",
    "                    try:\n",
    "                        line1 = op.minimize(Min_PDF, [1.,0.],\\\n",
    "                                            args=(np.array((rms_flux[1],rms_flux[0]),dtype='object'),linear),\\\n",
    "                                            method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "                        line1 = line1['x']\n",
    "\n",
    "                        plt.errorbar(rms_flux[0], rms_flux[1],\\\n",
    "                                     yerr= rms_flux[2], color='r', label=bin1+'hr bins, α = %.2e'%line1[0],\\\n",
    "                                     alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                        x1 = np.linspace(np.nanmin(rms_flux[0]), np.nanmax(rms_flux[0]), num=200)\n",
    "                    except:    \n",
    "                        x1 = [0.0,0.0]\n",
    "                        line1 = [0.0,0.0]\n",
    "\n",
    "                if len(x1) > 2:\n",
    "                    idx = np.where(rms_flux[1] != 0.)[0]\n",
    "                    rsq1, rsq1_sig = r_squared(rms_flux[0][idx], rms_flux[1][idx], line1)\n",
    "                    plt.plot(x1,linear(x1,*line1), color='r', linestyle='dotted', label = r\"$r^{2}$ = %.3f\"%rsq1)    \n",
    "                else:\n",
    "                    rsq1_sig = \"none\"\n",
    "                \n",
    "                m1 = line1[0]    \n",
    "                    \n",
    "                idx = np.isfinite(binnedflux_bin2[1]) & np.isfinite(binnedflux_bin2[7]) & np.greater(binnedflux_bin2[7],0.)\n",
    "                rms_flux = np.array((binnedflux_bin2[1][idx], binnedflux_bin2[7][idx], binnedflux_bin2[8][idx]))\n",
    "\n",
    "                try:\n",
    "                    line2 = np.polyfit(rms_flux[0], rms_flux[1], 1)\n",
    "                    plt.errorbar(rms_flux[0], rms_flux[1],\\\n",
    "                                 yerr= rms_flux[2], color='b', label=bin2+'hr bins, α = %.2e'%line2[0],\\\n",
    "                                 alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                    x2 = np.linspace(np.nanmin(rms_flux[0]), np.nanmax(rms_flux[0]), num=200)\n",
    "                    plt.plot(x2,linear(x2,*line2), color='b', linestyle='dotted')\n",
    "                except: \n",
    "                    try:\n",
    "                        line2 = op.minimize(Min_PDF, [1.,0.],\\\n",
    "                                            args=(np.array((rms_flux[1],rms_flux[0]),dtype='object'),linear),\\\n",
    "                                            method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "                        line2 = line2['x']\n",
    "                        plt.errorbar(rms_flux[0], rms_flux[1],\\\n",
    "                                     yerr= rms_flux[2], color='b', label=bin2+'hr bins, α = %.2e'%line2[0],\\\n",
    "                                     alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                        x2 = np.linspace(np.nanmin(rms_flux[0]), np.nanmax(rms_flux[0]), num=200)\n",
    "                        plt.plot(x2,linear(x2,*line2), color='b', linestyle='dotted')\n",
    "                    except:    \n",
    "                        x2 = [0.0,0.0]\n",
    "                        line2 = [0.0,0.0]\n",
    "\n",
    "                if len(x2) > 2:\n",
    "                    idx = np.where(rms_flux[1] != 0.)[0]\n",
    "                    rsq2, rsq2_sig = r_squared(rms_flux[0][idx], rms_flux[1][idx], line2)\n",
    "                    plt.plot(x2,linear(x2,*line2), color='b', linestyle='dotted', label = r\"$r^{2}$ = %.3f\"%rsq2)\n",
    "                else:\n",
    "                    rsq2_sig = \"none\"\n",
    "                \n",
    "                m2 = line2[0]\n",
    "                \n",
    "                try:\n",
    "                    plt.xlabel(\"Average Flux of Bin (cts s$^{-1}$)\")\n",
    "                    plt.ylabel(\"RMS (cts s$^{-1}$)\")\n",
    "                    plt.legend()\n",
    "\n",
    "                    plt.title(\"RMS-flux relation\")\n",
    "                    plt.savefig(subdir+'/rms-flux/'+target+'_rms_flux_dist.pdf', format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "        #             plt.show()\n",
    "                    plt.close()\n",
    "                except:\n",
    "                    plt.close()\n",
    "\n",
    "                ############################################################################################\n",
    "                ############################################################################################\n",
    "\n",
    "                ## Now a flux-binned version of the same relation\n",
    "                try:\n",
    "                    idx = np.isfinite(binnedflux_bin1[1]) & np.isfinite(binnedflux_bin1[7]) & np.greater(binnedflux_bin1[7],0.)\n",
    "                    rms_flux = np.array((binnedflux_bin1[1][idx],\\\n",
    "                                         binnedflux_bin1[7][idx], binnedflux_bin1[8][idx]))\n",
    "\n",
    "                    rms_n, rms_bins = np.histogram(rms_flux[0],\\\n",
    "                                                   bins = OptBins(rms_flux[0]),\\\n",
    "                                                   range=(np.nanmin(rms_flux[0]),np.nanmax(rms_flux[0])))\n",
    "                    bin_center = rms_bins[:-1] + np.diff(rms_bins) / 2\n",
    "\n",
    "                    rms_flux_binned = np.array((bin_center, np.zeros(len(bin_center)), np.zeros(len(bin_center))))\n",
    "\n",
    "                    for i in range(0,len(rms_bins)-1):\n",
    "                        binleft = rms_bins[i]\n",
    "                        binright = rms_bins[i+1]\n",
    "\n",
    "                        temp_RMSvar = []\n",
    "#                         temp_err = []\n",
    "\n",
    "                        for j in range(0,len(rms_flux[0])):\n",
    "\n",
    "                            if rms_flux[0][j] >= binleft and rms_flux[0][j] < binright:\n",
    "                                temp_RMSvar.append(rms_flux[1][j])\n",
    "#                                 temp_err.append(rms_flux[2][j])\n",
    "                            elif i == len(rms_bins)-1 and rms_flux[0][j] == np.nanmax(rms_flux[0]):\n",
    "                                temp_RMSvar.append(rms_flux[1][j])\n",
    "#                                 temp_err.append(rms_flux[2][j])\n",
    "\n",
    "                        rms_flux_binned[1][i] = np.nanmean(temp_RMSvar)\n",
    "                        rms_flux_binned[2][i] = np.sqrt(np.nanvar(temp_RMSvar)/len(temp_RMSvar))\n",
    "                        \n",
    "                    idx = np.isfinite(rms_flux_binned[0]) & np.isfinite(rms_flux_binned[1]) & np.greater(rms_flux_binned[1],0.)\n",
    "                    try:\n",
    "                        line1 = np.polyfit(rms_flux_binned[0][idx],\\\n",
    "                                           rms_flux_binned[1][idx], 1)\n",
    "                        plt.errorbar(rms_flux_binned[0][idx], rms_flux_binned[1][idx], yerr= rms_flux_binned[2][idx],\\\n",
    "                                     color='r', label=bin1+'hr bins, α = %.2e'%line1[0], alpha=0.8,\\\n",
    "                                     linestyle =\"None\",fmt='.', markersize = 8)\n",
    "                        x1 = np.linspace(rms_flux_binned[0].min(), np.nanmax(rms_flux_binned[0]), num=200)\n",
    "                    except: \n",
    "                        try:\n",
    "                            line1 = op.minimize(Min_PDF, [1.,0.], args=(np.array((rms_flux_binned[1][idx],\\\n",
    "                                                                                  rms_bins),dtype='object'),linear),\\\n",
    "                                                method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "                            line1 = line1['x']\n",
    "                            plt.errorbar(rms_flux_binned[0][idx],\\\n",
    "                                         rms_flux_binned[1][idx], yerr= rms_flux_binned[2][idx],\\\n",
    "                                         color='r', label=bin1+'hr bins, α = %.2e'%line1[0], alpha=0.8,\\\n",
    "                                         linestyle =\"None\",fmt='.', markersize = 8)\n",
    "                            x1 = np.linspace(np.nanmin(rms_flux_binned[0][idx]),\\\n",
    "                                             np.nanmax(rms_flux_binned[0][idx]), num=200)\n",
    "                        except:    \n",
    "                            x1 = [0.0,0.0]\n",
    "                            line1 = [0.0,0.0]\n",
    "\n",
    "                    if len(x1) > 2:\n",
    "                        idx = np.where(rms_flux_binned[1] != 0.)[0]\n",
    "                        rsq3, rsq3_sig = r_squared(rms_flux_binned[0][idx], rms_flux_binned[1][idx], line1)\n",
    "                        plt.plot(x1,linear(x1,*line1), color='r', linestyle='dotted', label = r\"$r^{2}$ = %.3f\"%rsq3)\n",
    "                    else:\n",
    "                        rsq3_sig = \"none\"\n",
    "                    m3 = line1[0]\n",
    "                    \n",
    "                    idx = np.isfinite(binnedflux_bin2[1]) & np.isfinite(binnedflux_bin2[7]) & np.greater(binnedflux_bin2[7],0.)\n",
    "                    rms_flux = np.array((binnedflux_bin2[1][idx],\\\n",
    "                                         binnedflux_bin2[7][idx], binnedflux_bin2[8][idx]))\n",
    "\n",
    "                    rms_n, rms_bins = np.histogram(rms_flux[0], bins = OptBins(rms_flux[0]),\\\n",
    "                                                   range=(rms_flux[0].min(),np.nanmax(rms_flux[0])))\n",
    "                    bin_center = rms_bins[:-1] + np.diff(rms_bins) / 2\n",
    "\n",
    "                    rms_flux_binned = np.array((bin_center, np.zeros(len(bin_center)), np.zeros(len(bin_center))))\n",
    "\n",
    "                    for i in range(0,len(rms_bins)-1):\n",
    "                        binleft = rms_bins[i]\n",
    "                        binright = rms_bins[i+1]\n",
    "\n",
    "                        temp_RMSvar = []\n",
    "                        temp_err = []\n",
    "\n",
    "                        for j in range(0,len(rms_flux[0])):\n",
    "\n",
    "                            if rms_flux[0][j] >= binleft and rms_flux[0][j] < binright:\n",
    "                                temp_RMSvar.append(rms_flux[1][j])\n",
    "#                                 temp_err.append(rms_flux[2][j])\n",
    "                            elif i == len(rms_bins)-1 and rms_flux[0][j] == np.nanmax(rms_flux[0]):\n",
    "                                temp_RMSvar.append(rms_flux[1][j])\n",
    "#                                 temp_err.append(rms_flux[2][j])\n",
    "\n",
    "                        rms_flux_binned[1][i] = np.nanmean(temp_RMSvar)\n",
    "                        rms_flux_binned[2][i] = np.sqrt(np.nanvar(temp_RMSvar)/len(temp_RMSvar))\n",
    "                        \n",
    "                    idx = np.isfinite(rms_flux_binned[0]) & np.isfinite(rms_flux_binned[1]) & np.greater(rms_flux_binned[1],0.)\n",
    "                    try:\n",
    "                        line2 = np.polyfit(rms_flux_binned[0][idx],\\\n",
    "                                           rms_flux_binned[1][idx], 1)\n",
    "                        plt.errorbar(rms_flux_binned[0][idx],\\\n",
    "                                     rms_flux_binned[1][idx], yerr= rms_flux_binned[2][idx], color='b',\\\n",
    "                                     label=bin2+'hr bins, α = %.2e'%line2[0], alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                        x2 = np.linspace(rms_flux_binned[0][idx].min(), np.nanmax(rms_flux_binned[0]), num=200)\n",
    "                    except: \n",
    "                        try:\n",
    "                            line2 = op.minimize(Min_PDF, [1.,0.], args=(np.array((rms_flux_binned[1][idx],rms_bins),\\\n",
    "                                                dtype='object'),linear), method='L-BFGS-B',\\\n",
    "                                                    options={'gtol':1e-6,'disp':False})\n",
    "                            line2 = line2['x']\n",
    "                            plt.errorbar(rms_flux_binned[0][idx],\\\n",
    "                                         rms_flux_binned[1][idx], yerr= rms_flux_binned[2][idx], color='b',\\\n",
    "                                         label=bin2+'hr bins, α = %.2e'%line2[0], alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                            x2 = np.linspace(np.nanmin(rms_flux_binned[0][idx]), np.nanmax(rms_flux_binned[0][idx]), num=200)\n",
    "                        except:    \n",
    "                            x2 = [0.0,0.0]\n",
    "                            line2 = [0.0,0.0]\n",
    "\n",
    "                    if len(x2) > 2:\n",
    "                        rsq4, rsq4_sig = r_squared(rms_flux_binned[0][idx], rms_flux_binned[1][idx], line2)\n",
    "                        plt.plot(x2,linear(x2,*line2),color='b', linestyle='dotted', label = r\"$r^{2}$ = %.3f\"%rsq4)\n",
    "                    else:\n",
    "                        rsq4_sig = \"none\"\n",
    "                    m4 = line2[0]\n",
    "                        \n",
    "                    try:\n",
    "                        plt.xlabel(\"Average Flux of Bin (cts s$^{-1}$)\")\n",
    "                        plt.ylabel(\"RMS (cts s$^{-1}$)\")\n",
    "                        plt.legend()\n",
    "\n",
    "                        plt.title(\"RMS-flux relation\")\n",
    "                        plt.savefig(subdir+'/rms-flux/'+target+'_rms_flux_binned_dist.pdf', format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "            #             plt.show()\n",
    "                        plt.close()\n",
    "                    except:\n",
    "                        plt.close()\n",
    "\n",
    "\n",
    "                except:\n",
    "                    print(\"\\nCould not make figures for binned rms-flux relation.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "                #######################################################################################\n",
    "                ## Excess variance and fractional rms amplitude calculations for itotal light curve\n",
    "                print(\"\\nCalculating excess variance of full light curves\")\n",
    "\n",
    "\n",
    "                Xvar_reg, RMSvar_reg,\\\n",
    "                XvarErr_reg, RMSvarErr_reg = calc_excess_variance(uninterp_df[0],uninterp_df[1],\\\n",
    "                                            uninterp_df[2],flux_mean = flux_reg_mean, stdev = flux_reg_stdev)\n",
    "                \n",
    "                Xvar_bin1, RMSvar_bin1,\\\n",
    "                XvarErr_bin1, RMSvarErr_bin1 = calc_excess_variance(binnedflux_bin1[0],binnedflux_bin1[1],\\\n",
    "                                                binnedflux_bin1[2],flux_mean = flux_bin1_mean, stdev = flux_bin1_stdev)\n",
    "\n",
    "                Xvar_bin2, RMSvar_bin2,\\\n",
    "                XvarErr_bin2, RMSvarErr_bin2 = calc_excess_variance(binnedflux_bin2[0],binnedflux_bin2[1],\\\n",
    "                                                binnedflux_bin2[2],flux_mean = flux_bin2_mean, stdev = flux_bin2_stdev)\n",
    "\n",
    "\n",
    "                #######################################################################################\n",
    "                ##Calculate subsequent flux distributions\n",
    "                \n",
    "                idx_raw = np.where((np.diff(raw_df[0]) > 0.02) & (np.diff(raw_df[0]) < 0.0209))[0]\n",
    "                delflux_raw = pd.DataFrame(np.column_stack((np.diff(raw_df[0][idx_raw]),\\\n",
    "                                                            np.diff(raw_df[1][idx_raw]))))\n",
    "\n",
    "                idx_reg = np.where((np.diff(uninterp_df[0]) > 0.02) & (np.diff(uninterp_df[0]) < 0.0209))[0]\n",
    "                delflux_reg = pd.DataFrame(np.column_stack((np.diff(uninterp_df[0][idx_reg]),\\\n",
    "                                                            np.diff(uninterp_df[1][idx_reg]))))\n",
    "\n",
    "                idx_bin1 = np.where((np.diff(binnedflux_bin1[0]) > 0.2) & (np.diff(binnedflux_bin1[0]) < 0.3))[0]\n",
    "                delflux_bin1 = pd.DataFrame(np.column_stack((np.diff(binnedflux_bin1[0][idx_bin1]),\\\n",
    "                                                             np.diff(binnedflux_bin1[1][idx_bin1]))))\n",
    "                    \n",
    "                idx_bin2 = np.where((np.diff(binnedflux_bin2[0]) > 0.45) & (np.diff(binnedflux_bin2[0]) < 0.55))[0]\n",
    "                delflux_bin2 = pd.DataFrame(np.column_stack((np.diff(binnedflux_bin2[0][idx_bin2]),\\\n",
    "                                                             np.diff(binnedflux_bin2[1][idx_bin2]))))\n",
    "\n",
    "\n",
    "                print(\"\\nFitting histograms of change in flux data\")\n",
    "                \n",
    "                for i in range(4,8):\n",
    "                    if i == 4 and raw == True:\n",
    "                        delflux_raw_mean, delflux_raw_stdev, delflux_raw_min, delflux_raw_max,\\\n",
    "                        delflux_raw_bins = hist_and_fit(delflux_raw,df,i,subdir,target,sectbysect,group)\n",
    "                    if i == 5:\n",
    "                        delflux_reg_mean, delflux_reg_stdev, delflux_reg_min, delflux_reg_max,\\\n",
    "                        delflux_reg_bins = hist_and_fit(delflux_reg,df,i,subdir,target,sectbysect,group)\n",
    "                    if i == 6:\n",
    "                        delflux_bin1_mean, delflux_bin1_stdev, delflux_bin1_min, delflux_bin1_max,\\\n",
    "                        delflux_bin1_bins = hist_and_fit(delflux_bin1,df,i,\\\n",
    "                                                         subdir,target,sectbysect,group,bin1=bin1,bin2=bin2)\n",
    "                    if i == 7:\n",
    "                        delflux_bin2_mean, delflux_bin2_stdev, delflux_bin2_min, delflux_bin2_max,\\\n",
    "                        delflux_bin2_bins = hist_and_fit(delflux_bin2,df,i,\\\n",
    "                                                         subdir,target,sectbysect,group,bin1=bin1,bin2=bin2)\n",
    "\n",
    "\n",
    "                #######################################################################################\n",
    "                ## Find the chi-squared per degree of freedom (Sesar 2007)\n",
    "                print(\"\\nCalculating chi-squared/dof\")\n",
    "                mean_dif = np.subtract(uninterp_df[1],np.nanmean(uninterp_df[1]))\n",
    "                chi2_dof = (len(uninterp_df[1])-1)**-1 * np.sum(mean_dif**2/uninterp_df[2]**2)\n",
    "\n",
    "                chi2, dof, chi2_dof = chisquare_per_dof(uninterp_df[1],np.nanmean(uninterp_df[1]),uninterp_df[2])\n",
    "\n",
    "\n",
    "                #######################################################################################\n",
    "                ## Write and save results\n",
    "                print(\"\\nSaving data\")\n",
    "                if sectbysect== True:\n",
    "                    target_name = target+' sectors '+group\n",
    "                else:\n",
    "                    target_name = target\n",
    "\n",
    "                if raw == True:\n",
    "                    row = [target_name, flux_raw_mean, flux_raw_stdev, delflux_raw_mean, delflux_raw_stdev,\\\n",
    "                            lc_reg_mean, lc_reg_stdev, delflux_reg_mean, delflux_reg_stdev,\\\n",
    "                            lc_bin1_mean, lc_bin1_stdev, delflux_bin1_mean, delflux_bin1_stdev,\\\n",
    "                            lc_bin2_mean, lc_bin2_stdev, delflux_bin2_mean, delflux_bin2_stdev,\\\n",
    "                            Xvar_reg, XvarErr_reg,\\\n",
    "                            Xvar_bin1, XvarErr_bin1,\\\n",
    "                            Xvar_bin2, XvarErr_reg,\\\n",
    "                            RMSvar_reg, RMSvarErr_reg,\\\n",
    "                            RMSvar_bin1, RMSvarErr_bin1,\\\n",
    "                            RMSvar_bin2, RMSvarErr_bin2,\\\n",
    "                            m1,rsq1,m2,rsq2,m3,rsq3,m4,rsq4,\\\n",
    "                            tau_inc_min, err_tau_dec, delt_inc_min, timescale_dec_min,\\\n",
    "                            tau_dec_min, err_tau_inc, delt_dec_min, timescale_inc_min,\\\n",
    "                            doppler, R_low, R_appox, R_high, Rs_low, Rs_appox, Rs_high,\\\n",
    "                            chi2, dof, chi2_dof]\n",
    "\n",
    "                           \n",
    "                           \n",
    "\n",
    "\n",
    "                if raw == False:\n",
    "                    row = [target, flux_reg_mean, flux_reg_stdev, delflux_reg_mean, delflux_reg_stdev,\\\n",
    "                            lc_bin1_mean, lc_bin1_stdev, delflux_bin1_mean, delflux_bin1_stdev,\\\n",
    "                            lc_bin2_mean, lc_bin2_stdev, delflux_bin2_mean, delflux_bin2_stdev,\\\n",
    "                            Xvar_reg, XvarErr_reg,\\\n",
    "                            Xvar_bin1, XvarErr_bin1,\\\n",
    "                            Xvar_bin2, XvarErr_reg,\\\n",
    "                            RMSvar_reg, RMSvarErr_reg,\\\n",
    "                            RMSvar_bin1, RMSvarErr_bin1,\\\n",
    "                            RMSvar_bin2, RMSvarErr_bin2,\\\n",
    "                            m1,rsq1,m2,rsq2,m3,rsq3,m4,rsq4,\\\n",
    "                            tau_inc_min, err_tau_dec, delt_inc_min, timescale_dec_min,\\\n",
    "                            tau_dec_min, err_tau_inc, delt_dec_min, timescale_inc_min,\\\n",
    "                            doppler, R_low, R_appox, R_high, Rs_low, Rs_appox, Rs_high,\\\n",
    "                            chi2, dof, chi2_dof]\n",
    "\n",
    "                writer.writerow(row)\n",
    "\n",
    "                lc_data.close()\n",
    "                print(\"\\nMoving to next object\")\n",
    "\n",
    "            \n",
    "            \n",
    "if sample == \"analysis\":\n",
    "    results = 'C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Analysis\\\\LC_variability_analysis.csv'\n",
    "if sample == \"removed\":\n",
    "    results = 'C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Removed_sample\\\\LC_variability_rmv.csv'\n",
    "\n",
    "read_df = pd.read_csv(results)\n",
    "\n",
    "if sample == \"analysis\":\n",
    "    read_df.to_excel('C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Analysis\\\\LC_variability_analysis.xlsx',index=False) \n",
    "if sample == \"removed\":\n",
    "    read_df.to_excel('C:\\\\Users\\\\rdingler\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Removed_sample\\\\LC_variability_rmv.xlsx',index=False)\n",
    "    \n",
    "# if adj == True:            \n",
    "    \n",
    "#     ## User-specified modicfications to data for potential ease of viewing\n",
    "#     print(\"\\nAdjusting final data form\")            \n",
    "    \n",
    "\n",
    "#     for x in [y for y in read_df.columns.values if y != 'Target']:\n",
    "\n",
    "#         idx = np.isfinite(np.array(read_df[x], dtype = 'float64'))\n",
    "#         values = np.abs(np.array(read_df[x][idx], dtype = 'float64'))\n",
    "\n",
    "#         if x == 'σ^2_NXS(unbinned)' or x == 'err(σ^2_NXS)(unbinned)' or x == 'σ^2_NXS('+str(bin1)+'hr)'\\\n",
    "#             or x == 'err(σ^2_NXS)('+str(bin1)+'hr)' or x == 'σ^2_NXS('+str(bin2)+'hr)' or x == 'err(σ^2_NXS)('+str(bin2)+'hr)':\n",
    "\n",
    "#             read_df[x] = np.round(np.log10(read_df[x]),decimals = 4)\n",
    "#             new_column = '$log('+x+')'\n",
    "#             read_df = read_df.rename(columns={x:new_column})\n",
    "#         else:\n",
    "#             mean_median_middle = np.nanmean([np.nanmedian(np.log10([x for x in values if x!=0])),np.nanmean(np.log10([x for x in values if x!=0]))])\n",
    "#             power = int(mean_median_middle + 0.5)\n",
    "\n",
    "#             if power <= 1 and power >= -1:\n",
    "#                 read_df[x] = np.round(read_df[x],decimals = 4)\n",
    "#             else:\n",
    "#                 read_df[x] = np.round(read_df[x]/(10**power),decimals = 4)\n",
    "#                 new_column = x +' [*10^'+str(power)+']'\n",
    "#                 read_df = read_df.rename(columns={x:new_column})\n",
    "\n",
    "\n",
    "#     if sample == \"analysis\":\n",
    "#         read_df.to_csv('/users/rdingler/AGNstudy/LightCurves/Analysis/LC_variability_analysis_adjusted.csv',index=False)\n",
    "#         read_df.to_excel('/users/rdingler/AGNstudy/LightCurves/Analysis/LC_variability_analysis_adjusted.xlsx',index=False)\n",
    "\n",
    "#     if sample == \"removed\":\n",
    "#         read_df.to_csv('/users/rdingler/AGNstudy/LightCurves/Removed_sample/LC_variability_rmv_adjusted.csv',index=False)\n",
    "#         read_df.to_excel('/users/rdingler/AGNstudy/LightCurves/Removed_sample/LC_variability_rmv_adjusted.xlsx',index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8d555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45e378bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = 'C:\\\\Users\\\\ryned\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Analysis\\\\1ES2322-409\\\\lightcurve_datafiles'\n",
    "file = '1ES2322-409_cycle1_simple_hybrid_interpolated_lc.dat'\n",
    "df = pd.read_table(os.path.join(subdir, file), sep = ' ', header=None, dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce29ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stdev = 10.821\n",
      "mean err = 0.749\n"
     ]
    }
   ],
   "source": [
    "stack = np.column_stack((df[0],df[1],df[2]))\n",
    "\n",
    "time = [x for x,y,z in stack if z > 0.]\n",
    "flux = [y for x,y,z in stack if z > 0.]\n",
    "err = [z for x,y,z in stack if z > 0.]\n",
    "\n",
    "print('Stdev = %.3f'%np.sqrt(np.nanvar(flux)))\n",
    "print('mean err = %.3f'%np.nanmean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "rootdir = 'C:\\\\Users\\\\ryned\\\\Desktop\\\\AGNstudy\\\\LightCurves\\\\Analysis\\\\'\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    \n",
    "    target = os.path.basename(subdir)\n",
    "    \n",
    "    if \"1ES\" in target or \"PKS\" in target or \"PMNJ\" in target or \"3C\" in target or \"4C\" in target or \"NVSS\" in target\\\n",
    "        or \"1RXS\" in target or \"2MAS\" in target or \"WISE\" in target or \"NGC\" in target:\n",
    "        \n",
    "        files = np.concatenate([glob.glob(subdir+'/**/**_rms_flux_dist.pdf'),glob.glob(subdir+'/**/**_rms_flux_binned_dist.pdf')],axis = 0) #glob.glob(subdir+'/**/**.dat') #\n",
    "\n",
    "        for file in files:\n",
    "#             print(os.path.basename(file))\n",
    "            shutil.copy(file,rootdir+'rms_flux_figs\\\\'+os.path.basename(file))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc91ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
