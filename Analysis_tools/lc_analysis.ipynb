{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e792066d-0e15-4269-8770-0ebfde592f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lc_analysis.py\n",
    "\n",
    "Created 08/2022\n",
    "\n",
    "Original Author: Ryne Dingler\n",
    "\n",
    "Some functions useful for operations are obtained from \n",
    "Connolly 2015: http://arxiv.org/abs/1503.06676\n",
    "\n",
    "Python version of the light curve variability statistic algorithm from \n",
    "Dingler & Smith 2023.\n",
    "\n",
    "\n",
    "requires:\n",
    "    os, sys, numpy, scipy, pandas, csv, matplotlib\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy.optimize as op\n",
    "import scipy.special as sp\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats as st\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc21ea06-349d-47e2-ba5e-7a67c1085668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1RXSJ120417.0-070959\n",
      "\n",
      "Working in directory: /users/rdingler/AGNstudy/LightCurves/Flat/1RXSJ120417.0-070959\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19265/3060072252.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninterp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0mdelt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muninterp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtmp_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                     \u001b[0mdelf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muninterp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtmp_flux\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phys_3340/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phys_3340/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phys_3340/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;31m# Indexing Methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInt64Index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phys_3340/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_is_thread_alive.py\u001b[0m in \u001b[0;36mis_thread_alive\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_stopped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3.x has this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mis_thread_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Definition of various functions which are used to fit distribution models and linear fits \n",
    "'''\n",
    "\n",
    "def linear(x,m,b):\n",
    "    return(m*x+b)\n",
    "\n",
    "def gaussian(x, A, μ, σ):\n",
    "    return(A * np.exp(-(x - μ)**2 / (2*σ**2)))\n",
    "\n",
    "def lognormal(x, A, μ, σ):\n",
    "    return(1/x * gaussian(np.log(x), A, μ, σ))\n",
    "\n",
    "def bimodal(x, p, A, μ1, σ1, B, μ2, σ2):\n",
    "    ϕ = 0.5 + np.arctan(p)/np.pi\n",
    "    return(ϕ * gaussian(x, A, μ1, σ1) + (1-ϕ) * gaussian(x, B, μ2,σ2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6504e9-c889-4108-8ebf-2b09b3f687a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition of various functions regarding rounding \n",
    "'''\n",
    "\n",
    "def roundedfractionalrange(arr,fraction = 0.5):\n",
    "    \"\"\"\n",
    "    Returns a value for fractional length of an array.\n",
    "    \"\"\"\n",
    "    return(int(fraction*len(arr) + 0.5))\n",
    "\n",
    "def round_up_decimals(num:float, dec:int):\n",
    "    \"\"\"\n",
    "    Returns a value rounded up to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    round_good = False\n",
    "    count = 0\n",
    "    while round_good == False:\n",
    "\n",
    "        if not isinstance(dec, int) or dec < 0:\n",
    "            raise TypeError(\"decimal places must be a positive integer\")\n",
    "            if count != 0:\n",
    "                dec = int(input(\"round to how many decimal places? \"))\n",
    "        elif dec == 0:\n",
    "            return(np.ceil(num))\n",
    "            round_good = True\n",
    "        else:\n",
    "            round_good = True\n",
    "        count += 1   \n",
    "\n",
    "    scale = 10**dec\n",
    "    return(np.ceil(num * scale) / scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff4fa677-055e-45b4-ab01-dd1f9cc1ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Min_PDF(params,hist,model,force_scipy=True):\n",
    "    '''\n",
    "    PDF chi squared function allowing the fitting of a mixture distribution\n",
    "    using a log normal distribution and a gamma distribution\n",
    "    to a histogram of a data set.\n",
    "    \n",
    "    inputs:\n",
    "        params (array)   - function variables - kappa, theta, lnmu,lnsig,weight\n",
    "        hist (array)     - histogram of data set (using numpy.hist)\n",
    "        force_scipy (bool,optional) - force the function to assume a scipy model\n",
    "    outputs:\n",
    "        chi (float) - chi squared\n",
    "        \n",
    "    Ref: Connolly 2015\n",
    "    '''\n",
    "\n",
    "    mids = (hist[1][:-1]+hist[1][1:])/2.0\n",
    "\n",
    "    try:\n",
    "        if model.__name__ == 'Mixture_Dist':\n",
    "            model = model.Value\n",
    "            m = model(mids,params)\n",
    "        elif model.__module__ == 'scipy.stats.distributions' or \\\n",
    "            model.__module__ == 'scipy.stats._continuous_distns' or \\\n",
    "                force_scipy == True:\n",
    "            m = model.pdf    \n",
    "        else:    \n",
    "            m = model(mids,*params)\n",
    "    except AttributeError:\n",
    "        m = model(mids,*params)\n",
    "    \n",
    "    chi = (hist[0] - m)**2.0\n",
    "    \n",
    "    return(np.sum(chi))\n",
    "\n",
    "def OptBins(data,maxM=100):\n",
    "    '''\n",
    "     Python version of the 'optBINS' algorithm by Knuth et al. (2006) - finds \n",
    "     the optimal number of bins for a one-dimensional data set using the \n",
    "     posterior probability for the number of bins. WARNING sometimes doesn't\n",
    "     seem to produce a high enough number by some way...\n",
    "    \n",
    "     inputs:\n",
    "         data (array)           - The data set to be binned\n",
    "         maxM (int, optional)   - The maximum number of bins to consider\n",
    "         \n",
    "     outputs:\n",
    "        maximum (int)           - The optimum number of bins\n",
    "    \n",
    "     Ref: Connolly 2015, K.H. Knuth. 2012. Optimal data-based binning for histograms\n",
    "     and histogram-based probability density models, Entropy.\n",
    "    '''\n",
    "    \n",
    "    N = len(data)\n",
    "    \n",
    "    # loop through the different numbers of bins\n",
    "    # and compute the posterior probability for each.\n",
    "    \n",
    "    logp = np.zeros(maxM)\n",
    "    \n",
    "    for M in range(1,maxM+1):\n",
    "        n = np.histogram(data,bins=M)[0] # Bin the data (equal width bins)\n",
    "        \n",
    "        # calculate posterior probability\n",
    "        part1 = N * np.log(M) + sp.gammaln(M/2.0)\n",
    "        part2 = - M * sp.gammaln(0.5)  - sp.gammaln(N + M/2.0)\n",
    "        part3 = np.sum(sp.gammaln(n+0.5))\n",
    "        logp[M-1] = part1 + part2 + part3 # add to array of posteriors\n",
    "\n",
    "    maximum = np.argmax(logp) + 1 # find bin number of maximum probability\n",
    "    return(maximum + 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c7a27-c25b-4510-9f46-1d5043d3ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_col_label(rootdir,bin1,bin2,sample = \"\", raw = False):\n",
    "    '''\n",
    "    Make sure data file to save results exists and has proper headers\n",
    "    \n",
    "    inputs:\n",
    "        rootdir (directory)       - The directory in which figures will be saved\n",
    "        bin1 (string)             - string which specified how many hours for one binning schema\n",
    "        bin2 (string)             - string which specified how many hours for one binning schema\n",
    "        sample (string)           - user-specified sample selection\n",
    "        raw (boolean)             - whether or not raw light curve is available\n",
    "         \n",
    "   '''\n",
    "    \n",
    "    col_title = False\n",
    "    try:\n",
    "        if sample ==\"analysis\":\n",
    "            lc_data = open(os.path.join(rootdir,'LC_variability_analysis.csv') , \"r+\")\n",
    "        if sample ==\"removed\":\n",
    "            lc_data = open(os.path.join(rootdir,'LC_variability_rmv.csv') , \"r+\")\n",
    "\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        if sample ==\"analysis\":\n",
    "            lc_data = open(os.path.join(rootdir,'LC_variability_analysis.csv') , \"w\")\n",
    "            print(\"\\nCreating file 'LC_variability_analysis.csv'\\n\")\n",
    "        if sample ==\"removed\":\n",
    "            lc_data = open(os.path.join(rootdir,'LC_variability_rmv.csv') , \"w\")\n",
    "        print(\"\\nCreating file 'LC_variability_rmv.csv'\\n\")\n",
    "        \n",
    "        \n",
    "        if raw == True:\n",
    "            header = ['Target','<F>(raw)','σ_F(raw)','<ΔF>(raw)', 'σ_ΔF(raw)',\\\n",
    "            '<F>(unbinned)', '<F>('+bin1+'hr)','<F>('+bin2+'hr)',\\\n",
    "                'σ_F(unbinned)','σ_F('+bin1+'hr)', 'σ_F('+bin2+'hr)',\\\n",
    "                    '<ΔF>(unbinned)','<ΔF>('+bin1+'hr)','<ΔF>('+bin2+'hr)',\\\n",
    "                        'σ_ΔF(unbinned)', 'σ_ΔF('+bin1+'hr)','σ_ΔF('+bin2+'hr)',\\\n",
    "                            'σ^2_NXS(unbinned)','err(σ^2_NXS)(unbinned)','σ^2_NXS('+bin1+'hr)','err(σ^2_NXS)('+bin1+'hr)','σ^2_NXS('+bin2+'hr)','err(σ^2_NXS)('+bin2+'hr)',\\\n",
    "                                'F_var(unbinned)','err(F_var)(unbinned)','F_var('+bin1+'hr)','err(F_var)('+bin1+'hr)','F_var('+bin2+'hr)','err(F_var)('+bin2+'hr)',\\\n",
    "                                    'τ(inc,days)', 'Δt(inc,days)', 'τ(dec,days)', 'Δt(dec,days)','χ^2','dof','χ^2/dof']\n",
    "        \n",
    "        if raw == False:\n",
    "            header = ['Target','<F>(unbinned)', '<F>('+bin1+'hr)','<F>('+bin2+'hr)',\\\n",
    "            'σ_F(unbinned)','σ_F('+bin1+'hr)', 'σ_F('+bin2+'hr)',\\\n",
    "                '<ΔF>(unbinned)','<ΔF>('+bin1+'hr)','<ΔF>('+bin2+'hr)',\\\n",
    "                    'σ_ΔF(unbinned)', 'σ_ΔF('+bin1+'hr)','σ_ΔF('+bin2+'hr)',\\\n",
    "                        '<σ^2_XS>(unbinned)','<σ^2_XS>('+bin1+'hr)','<σ^2_XS>('+bin2+'hr)',\\\n",
    "                            'F_var(unbinned)','<F_var>('+bin1+'hr)','<F_var>('+bin2+'hr)',\\\n",
    "                                'τ(inc,days)', 'Δt(inc,days)', 'τ(dec,days)', 'Δt(dec,days)','χ^2','dof','χ^2/dof']\n",
    "\n",
    "        \n",
    "        writer = csv.writer(lc_data)\n",
    "        writer.writerow(header)\n",
    "\n",
    "    lc_data.close()\n",
    "\n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe847bf-3089-41af-8d94-299beb704926",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition of various functions regarding statistical tests \n",
    "'''\n",
    "\n",
    "def chisquare_per_dof(observed,expected,error):\n",
    "    '''\n",
    "    Chi-squared per degree of freedom test\n",
    "    \n",
    "    inputs:\n",
    "        observed (array or float)    - observed test values\n",
    "        expected (array or float)    - theoretical values\n",
    "        error (array or float)       - observed error on test values\n",
    "    outputs:\n",
    "        test_statistic (float)       - chi-square statistic \n",
    "        dof (float)                  - length of array\n",
    "        test_statistic/dof (float)   - chi-square per dof\n",
    "    '''\n",
    "    \n",
    "    index = np.array(list(np.where(error != 0)[0]), dtype = 'int')\n",
    "    test_statistic = []\n",
    "    for idx in index:\n",
    "        test_statistic.append(np.subtract(observed,expected)[idx]**2 / error[idx]**2)\n",
    "        \n",
    "    dof=len(test_statistic)-1\n",
    "    test_statistic = np.nansum(test_statistic)\n",
    "\n",
    "    return(test_statistic, dof, test_statistic/dof)\n",
    "\n",
    "\n",
    "def shortest_timescale(rootdir, target, uninterp_df, sectbysect = False, sectors = ''): \n",
    "    '''\n",
    "    Find shortest timescale for exponential rise and decay for significant flux change\n",
    "    with decreasing iterative kernel smoothing. Smoothing aid in the reduction of single\n",
    "    cadence flares; however, may eliminate significant flux change, hence the decreasing iterations.\n",
    "    \n",
    "    inputs:\n",
    "         rootdir (directory)          - The directory in which lcs are stored\n",
    "         target (string)              - Name of desired object to analyze\n",
    "         uninterp_df (DataFrame)      - Number of lcs (default = 501)\n",
    "         redshift (float)             - Redshift of AGN\n",
    "         sectbysect (boolean)         - sector by sector analysis or not (default is False)\n",
    "         secors (string)              - current sectors under analysis if sectbysect is True\n",
    "         \n",
    "     outputs:\n",
    "        tau_dec_min (float)           - shortest timescale of exponential decay\n",
    "        delt_dec_min (float)          - assosiacted time seperation for timescale \n",
    "                                            of exponential decay\n",
    "        tau_inc_min (float)           - shortest timescale of exponential growth\n",
    "        delt_inc_min (float)          - assosiacted time seperation for timescale \n",
    "                                            of exponential growth\n",
    "    \n",
    "     Ref:  Chaterjee et al 2021\n",
    "    '''\n",
    "    \n",
    "    nonzeroflux = np.nonzero(np.array(uninterp_df[1]))[0]\n",
    "    time = np.array(uninterp_df[0][nonzeroflux])\n",
    "    unfiltered_flux = np.array(uninterp_df[1][nonzeroflux])\n",
    "    flux = []\n",
    "    err = np.array(uninterp_df[2][nonzeroflux])\n",
    "\n",
    "    tau_dec_min = np.inf\n",
    "    tau_inc_min = np.inf\n",
    "    \n",
    "    delt_dec_min = 0.\n",
    "    delt_inc_min = 0.\n",
    "    \n",
    "    t1_dec_idx = 0\n",
    "    t2_dec = 0\n",
    "    t1_inc_idx = 0\n",
    "    t2_inc = 0\n",
    "    \n",
    "    FWHM = 2\n",
    "\n",
    "    while tau_dec_min == np.inf or tau_inc_min == np.inf:\n",
    "        print(\"\\nSmoothing light curve with FWHM = %i\"%FWHM)\n",
    "        flux = gaussian_filter(unfiltered_flux,sigma=FWHM)\n",
    "        for i in range(0,len(time)-1):\n",
    "            tmp_time = time[i]\n",
    "            tmp_flux = flux[i]\n",
    "            tmp_err = err[i]\n",
    "\n",
    "            if i%500 == 0.:\n",
    "                print(\"Comparing point %i\"%i)\n",
    "\n",
    "            delt = np.subtract(time[i+1:],tmp_time)\n",
    "            delf = np.subtract(flux[i+1:],tmp_flux)\n",
    "\n",
    "            denom = np.log(np.divide(flux[i+1:],tmp_flux))\n",
    "            tau = np.log(2)*np.abs(np.divide(delt,denom))\n",
    "\n",
    "            stats = np.column_stack((delt,delf,tau))\n",
    "\n",
    "            delt_dec = [x for x,y,z in stats if x != 0. and y < -3.*tmp_err and np.isfinite(z)]\n",
    "            tau_dec = [z for x,y,z in stats if x != 0. and y < -3.*tmp_err and np.isfinite(z)]\n",
    "            delt_inc = [x for x,y,z in stats if x != 0. and y > 3.*tmp_err and np.isfinite(z)]\n",
    "            tau_inc = [z for x,y,z in stats if x != 0. and y > 3.*tmp_err and np.isfinite(z)]\n",
    "\n",
    "\n",
    "            if len(tau_dec) != 0:\n",
    "                if np.min(tau_dec) < tau_dec_min:\n",
    "                    tau_dec_min = np.min(tau_dec)\n",
    "                    delt_dec_min = delt_dec[np.argmin(tau_dec)]\n",
    "                    t1_dec_idx = i\n",
    "                    t2_dec = time[t1_dec_idx] + delt_dec_min \n",
    "\n",
    "            if len(tau_inc) != 0:\n",
    "                if np.min(tau_inc) < tau_inc_min:\n",
    "                    tau_inc_min = np.min(tau_inc)\n",
    "                    delt_inc_min = delt_inc[np.argmin(tau_inc)]\n",
    "                    t1_inc_idx = i\n",
    "                    t2_inc = time[t1_inc_idx] + delt_inc_min\n",
    "\n",
    "        if tau_inc_min != np.inf and tau_dec_min != np.inf:\n",
    "            break\n",
    "        elif FWHM == 0:\n",
    "            if tau_inc_min == np.inf or tau_dec_min == np.inf:\n",
    "                break\n",
    "        FWHM-=1\n",
    "                    \n",
    "    plt.figure(figsize=(25,6))\n",
    "    plt.title(target+\": shortest timescales of exponential growth and decay\")\n",
    "    plt.errorbar(time,unfiltered_flux,yerr=err, color = 'k', alpha = 0.75, linestyle = 'None')\n",
    "    plt.vlines((time[t1_dec_idx],t2_dec), np.min(flux)-6, np.max(flux)+6,color = 'r', label = r\"$τ_{dec}$ = %.3f\"%tau_dec_min)\n",
    "    plt.vlines((time[t1_inc_idx],t2_inc), np.min(flux)-6, np.max(flux)+6,color = 'b', label = r\"$τ_{inc}$ = %.3f\"%tau_inc_min)\n",
    "    if FWHM == 0:\n",
    "        plt.plot(time,flux, label = 'Running average')\n",
    "    else:\n",
    "        plt.plot(time,flux, label = r'Smoothed lc $\\sigma$=%i'%FWHM)\n",
    "    plt.ylim(np.min(flux)-5, np.max(flux)+5)\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.tight_layout()\n",
    "    if sectbysect == True:\n",
    "        plt.savefig(rootdir+target+'/'+target+'_sectors'+sectors+'_shortest_timescales_smoothedlc.png')\n",
    "    else:\n",
    "        plt.savefig(rootdir+target+'/'+target+'_shortest_timescales_smoothedlc.png')\n",
    "#         plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(target+\": shortest timescale of exponential decay\")\n",
    "    plt.errorbar(time,unfiltered_flux,yerr=err, color = 'k', alpha = 0.75, linestyle = 'None')\n",
    "    plt.vlines((time[t1_dec_idx],t2_dec), np.min(flux)-6, np.max(flux)+6,color = 'r', label = r\"$τ_{dec}$ = %.3f\"%tau_dec_min)\n",
    "    if FWHM == 0:\n",
    "        plt.plot(time,flux, label = 'Running average')\n",
    "    else:\n",
    "        plt.plot(time,flux, label = r'Smoothed lc $\\sigma$=%i'%FWHM)\n",
    "    plt.xlim(time[t1_dec_idx]-0.5,t2_dec+0.5)\n",
    "    plt.ylim(np.min(flux)-5, np.max(flux)+5)\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.tight_layout()\n",
    "    if sectbysect == True:\n",
    "        plt.savefig(rootdir+target+'/'+target+'_sectors'+sectors+'_shortest_decaytimescale_smoothedlc.png')\n",
    "    else:\n",
    "        plt.savefig(rootdir+target+'/'+target+'_shortest_decaytimescale_smoothedlc.png')\n",
    "#         plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(target+\": shortest timescale of exponential growth\")\n",
    "    plt.errorbar(time,unfiltered_flux,yerr=err, color = 'k', alpha = 0.75, linestyle = 'None')\n",
    "    plt.vlines((time[t1_inc_idx],t2_inc), np.min(flux)-6, np.max(flux)+6,color = 'b', label = r\"$τ_{inc}$ = %.3f\"%tau_inc_min)\n",
    "    if FWHM == 0:\n",
    "        plt.plot(time,flux, label = 'Running average')\n",
    "    else:\n",
    "        plt.plot(time,flux, label = r'Smoothed lc $\\sigma$=%i'%FWHM)\n",
    "    plt.xlim(time[t1_inc_idx]-0.5,t2_inc+0.5)\n",
    "    plt.ylim(np.min(flux)-5, np.max(flux)+5)\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.tight_layout()\n",
    "    if sectbysect == True:\n",
    "        plt.savefig(rootdir+target+'/'+target+'_sectors'+sectors+'_shortest_growthtimescale_smoothedlc.png')\n",
    "    else:\n",
    "        plt.savefig(rootdir+target+'/'+target+'_shortest_growthtimescale_smoothedlc.png')\n",
    "#         plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    return(tau_dec_min, delt_dec_min, tau_inc_min, delt_inc_min)\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "def excess_variance(time, flux, err, stdev = 0, len_lc = 0, MSE = 0, total=True, normalize = True):\n",
    "    '''\n",
    "    Find sExcess variance and fractional variance for either the entire light curve or within user-\n",
    "    specified bins\n",
    "    \n",
    "    inputs:\n",
    "         time (array)             - array of time from the light curve (or segment)\n",
    "         flux (array)             - array of flux from the light curve (or segment)\n",
    "         err (array)              - array of error from the light curve (or segment)\n",
    "         stdev (float)            - standard deviation of entire flux sample\n",
    "         len_lc (float)           - length of the light curve (or segment)\n",
    "         MSE (float or array)     - mean squared error from of error from the light curve (or segment)\n",
    "         total (boolean)          - indicator if analyzing the total light curve or analyzing intrabin\n",
    "         normalize (boolean)      - indicator if excess variance is to be normalized\n",
    "         \n",
    "     outputs (total = False):\n",
    "        Xvar (float)              - Excess Variance\n",
    "        Fvar (float)              - Fractional variance\n",
    "        XvarErr (float)           - error on Excess Variance\n",
    "        FvarErr (float)           - error on Fractional variance\n",
    "        \n",
    "    `outputs (total = True, normalize = True):\n",
    "        NXvar (float)             - Normalized Excess Variance\n",
    "        Fvar (float)              - Fractional variance\n",
    "        NXvarErr (float)          - error on Normalized Excess Variance\n",
    "        FvarErr (float)           - error on Fractional variance\n",
    "    \n",
    "     Ref:  Chaterjee et al 2021\n",
    "    '''\n",
    "    \n",
    "    nonzeroflux = np.nonzero(np.array(flux))[0]\n",
    "    time = np.array(time[nonzeroflux])\n",
    "    flux = np.array(flux[nonzeroflux])\n",
    "    err = np.array(err[nonzeroflux])\n",
    "    \n",
    "    if total == True:\n",
    "        lc_stdev = np.nanstd(flux)\n",
    "        flux_mean = np.nanmean(flux)\n",
    "\n",
    "        len_lc = len(time)\n",
    "        MSE = np.nanmean(err**2)\n",
    "        Xvar = lc_stdev**2 - MSE\n",
    "        \n",
    "        if normalize == True:\n",
    "            NXvar = Xvar/flux_mean**2\n",
    "            Fvar = np.sqrt(NXvar)\n",
    "        else:\n",
    "            NXvar = Xvar\n",
    "            Fvar = np.sqrt(NXvar/flux_mean**2)\n",
    "        \n",
    "        if np.isfinite(Fvar):\n",
    "            NXvarErr = np.sqrt(np.add( (np.sqrt(2/len_lc) * MSE/(flux_mean**2))**2,\\\n",
    "                                              (np.sqrt(MSE/len_lc) * (2*Fvar/flux_mean))**2))\n",
    "        else:\n",
    "            NXvarErr = np.sqrt(2/len_lc) * MSE/(flux_mean**2)\n",
    "            \n",
    "        NXvarErr = np.array(NXvarErr)        \n",
    "        FvarErr = NXvarErr/(2*Fvar)\n",
    "    \n",
    "        return(NXvar, Fvar, NXvarErr, FvarErr)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        Xvar = np.subtract(stdev**2,MSE)\n",
    "        Fvar = np.sqrt(np.divide(Xvar,flux**2))\n",
    "        XvarErr = []\n",
    "        for i in range(0,len(Xvar)):\n",
    "            if np.isfinite(Fvar[i]):\n",
    "                XvarErr.append(np.sqrt( np.add( (np.sqrt(2/len_lc[i]) * MSE[i]/(flux[i]**2))**2,\\\n",
    "                                (np.sqrt(MSE[i]/len_lc[i]) * (2*Fvar[i]/flux[i]))**2)))\n",
    "            else:\n",
    "                XvarErr.append(np.sqrt(2/len_lc[i]) * MSE[i]/(flux[i]**2))\n",
    "\n",
    "        XvarErr = np.array(XvarErr)        \n",
    "        FvarErr = XvarErr/(2*Fvar)\n",
    "    \n",
    "        return(Xvar, Fvar, XvarErr, FvarErr)     \n",
    "            \n",
    "###########################################################################################################################################\n",
    "        \n",
    "def plot_excess_variance(subdir, df, binneddf, Xvar, XvarErr, Xvar_mean, Fvar, FvarErr, Fvar_mean, bin_time, sectbysect, group):\n",
    "    \n",
    "    '''\n",
    "    Plot the light curves, binned light curves, itrabin excess/fractional variance, ad confidence interval plots for \n",
    "    itrabin excess/fractional variance.\n",
    "    \n",
    "    inputs:\n",
    "        subdir (directory)        - The directory in which figures will be saved\n",
    "        df (DataFrame)            - dataframe containing unbinned light curve data (time,flux,err)\n",
    "        binneddf (DataFrame)      - dataframe containing binned light curve data (time,flux,err)\n",
    "        Xvar (float)              - Excess Variance\n",
    "        XvarErr (float)           - error on Excess Variance\n",
    "        Xvar_mean (float)         - mean of Excess Variance\n",
    "        Fvar (float)              - Fractional variance\n",
    "        FvarErr (float)           - error on Fractional variance\n",
    "        Fvar_mean (float)         - mean of Fractional variance\n",
    "        bin_time (string)         - string which specified how many hours are in one bin of binned lc\n",
    "        sectbysect (boolean)      - sector by sector analysis or not (default is False)\n",
    "        group (string)            - current sectors under analysis if sectbysect is True        \n",
    "\n",
    "    '''\n",
    "        \n",
    "\n",
    "    fig = plt.figure(figsize=(8,10))\n",
    "    gs = gridspec.GridSpec(nrows=4, ncols= 1,hspace=0.0)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    ax0 = fig.add_subplot(gs[0, :])\n",
    "    ax0.errorbar(df[0],df[1],yerr=df[2], linestyle =\"None\", color = 'k')\n",
    "    ax0.set_ylabel(\"F\")\n",
    "    ax0.minorticks_on()\n",
    "    ax0.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "    ax0.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "    ax0.set_title(target+r': $σ_{XS}^{2}$ & $F_{var}$, '+bin_time+'hr bins',fontsize='x-large')\n",
    "\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[1, :],sharex=ax0)\n",
    "    ax1.errorbar(binneddf[0],binneddf[1],yerr=np.sqrt(binneddf[2]), linestyle =\"None\",  color = 'k')\n",
    "    ax1.set_ylabel(r\"$\\langle F \\rangle$\")\n",
    "    ax1.minorticks_on()\n",
    "    ax1.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "    ax1.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "\n",
    "\n",
    "    ax2 = fig.add_subplot(gs[2, :],sharex=ax1)\n",
    "    ax2.errorbar(binneddf[0], Xvar, yerr = binneddf[1]*XvarErr, linestyle =\"None\", fmt='+', markersize = 4, color = 'k')\n",
    "\n",
    "    ax2.set_ylabel(r\"$σ_{XS}^{2}$\")\n",
    "    ax2.minorticks_on()\n",
    "    ax2.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "    ax2.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "\n",
    "\n",
    "    ax3 = fig.add_subplot(gs[3, :],sharex=ax2)\n",
    "    ax3.errorbar(binneddf[0], Fvar, yerr= FvarErr, linestyle =\"None\", color = 'k')\n",
    "    ax3.set_ylabel(r\"$F_{var}$\")\n",
    "    ax3.minorticks_on()\n",
    "    ax3.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "    ax3.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "    ax3.set_xlabel('Time (BTJD - days)')\n",
    "\n",
    "    plt.savefig(subdir+'/'+target+'_excess_rms_variance_'+bin_time+'hr.pdf', format = 'pdf',bbox_inches='tight')\n",
    "    #             plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    try:\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        gs = gridspec.GridSpec(nrows=2, ncols= 1,hspace=0.0)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[0, :])\n",
    "        ax2.errorbar(binneddf[0], Xvar, yerr = binneddf[1]*XvarErr, linestyle =\"None\", fmt='+', markersize = 4, color = 'k')\n",
    "        ax2.axhline(Xvar_mean, color = 'k', linestyle = 'solid', label = r'$\\langle σ_{XS}^{2} \\rangle$ = %.2e'%Xvar_mean)\n",
    "\n",
    "        # create custom discrete random variable from data set\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                unique, counts = np.unique(Xvar, return_counts=True)\n",
    "                pk = [x/len(Xvar) for x in counts]\n",
    "                CI_Xvar = st.rv_discrete(a = -np.inf,values=(unique, pk))  \n",
    "            except:\n",
    "                CI_Xvar = st.rv_discrete(a = -np.inf,values=(Xvar, np.array(len(Xvar)*[1/len(Xvar)])))                       \n",
    "            ax2.fill_between([binneddf[0].min()-1, binneddf[0].max()+1], CI_Xvar.interval(0.68)[0], CI_Xvar.interval(0.68)[1], color = 'g', alpha = 0.5)\n",
    "            ax2.fill_between([binneddf[0].min()-1, binneddf[0].max()+1], CI_Xvar.interval(0.95)[0], CI_Xvar.interval(0.95)[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "        except:\n",
    "            CI68_Xvar = st.norm.interval(alpha=0.68, loc= Xvar_mean, scale=np.std(Xvar))\n",
    "            CI95_Xvar = st.norm.interval(alpha=0.95, loc= Xvar_mean, scale=np.std(Xvar))\n",
    "            ax2.fill_between([binneddf[0].min()-1, binneddf[0].max()+1], CI68_Xvar[0], CI68_Xvar[1], color = 'g', alpha = 0.5)\n",
    "            ax2.fill_between([binneddf[0].min()-1, binneddf[0].max()+1], CI95_Xvar[0], CI95_Xvar[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "\n",
    "        ax2.set_ylabel(r\"$σ_{XS}^{2}$\")\n",
    "        ax2.minorticks_on()\n",
    "        ax2.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "        ax2.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "        ax2.set_title(target+r': $σ_{XS}^{2}$ & $F_{var}$, '+bin_time+'hr bins',fontsize='x-large')\n",
    "        ax2.legend(loc = 'upper right')\n",
    "\n",
    "        ax3 = fig.add_subplot(gs[1, :],sharex=ax2)\n",
    "        ax3.errorbar(binneddf[0], Fvar, yerr= FvarErr, linestyle =\"None\", color = 'k')\n",
    "        ax3.axhline(Fvar_mean, color = 'k', linestyle = 'solid', label = r'$\\langle F_{var} \\rangle$ = %.2e'%Fvar_mean)\n",
    "\n",
    "        # create custom discrete random variable from data set\n",
    "        Fvar_finite = [x for x in Fvar if np.isfinite(x)]\n",
    "        try:\n",
    "            try:\n",
    "                unique, counts = np.unique(Fvar_finite , return_counts=True)\n",
    "                pk = [x/len(Fvar_finite) for x in counts]\n",
    "                CI_Fvar = st.rv_discrete(a = -np.inf,values=(unique, pk))  \n",
    "            except:\n",
    "                CI_Fvar = st.rv_discrete(a = -np.inf,values=(Fvar_finite,np.array(len(Fvar_finite)*[1/len(Fvar_finite)])))\n",
    "            ax3.fill_between([binneddf[0].min()-1,binneddf[0].max()+1], CI_Fvar.interval(0.68)[0], CI_Fvar.interval(0.68)[1], color = 'g', alpha = 0.5)\n",
    "            ax3.fill_between([binneddf[0].min()-1,binneddf[0].max()+1], CI_Fvar.interval(0.95)[0], CI_Fvar.interval(0.95)[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "        except:\n",
    "            CI68_Fvar = st.norm.interval(alpha=0.68, loc= Fvar_mean, scale=np.std(Fvar))\n",
    "            CI95_Fvar = st.norm.interval(alpha=0.95, loc= Fvar_mean, scale=np.std(Fvar))\n",
    "            ax3.fill_between([binneddf[0].min()-1,binneddf[0].max()+1], CI68_Fvar[0], CI68_Fvar[1], color = 'g', alpha = 0.5)\n",
    "            ax3.fill_between([binneddf[0].min()-1,binneddf[0].max()+1], CI95_Fvar[0], CI95_Fvar[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "\n",
    "        ax3.set_ylabel(r\"$F_{var}$\")\n",
    "        ax3.minorticks_on()\n",
    "        ax3.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "        ax3.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "        ax3.set_xlim(xmin = binneddf[0].min()-1, xmax = binneddf[0].max()+1)\n",
    "        ax3.legend(loc = 'upper right')\n",
    "        ax3.set_xlabel('Time (BTJD - days)')\n",
    "\n",
    "        if sectbysect == True:\n",
    "            plt.savefig(subdir+'/'+target+'_excess_rms_varianceCI_'+bin_time+'hr_sectors'+group+'.pdf', format = 'pdf',bbox_inches='tight') \n",
    "        else:\n",
    "            plt.savefig(subdir+'/'+target+'_excess_rms_varianceCI_'+bin_time+'hr.pdf', format = 'pdf',bbox_inches='tight')\n",
    "        #                 plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    except:\n",
    "        plt.close()\n",
    "        try:\n",
    "            fig = plt.figure(figsize=(8,4))\n",
    "\n",
    "            plt.errorbar(binneddf[0], Xvar, yerr = binneddf[1]*XvarErr, linestyle =\"None\", fmt='+', markersize = 4, color = 'k')\n",
    "            plt.axhline(Xvar_mean, color = 'k', linestyle = 'solid', label = r'$\\langle σ_{XS}^{2} \\rangle$ = %.2e'%Xvar_mean)\n",
    "            try:\n",
    "                try:\n",
    "                    unique, counts = np.unique(Xvar, return_counts=True)\n",
    "                    pk = [x/len(Xvar) for x in counts]\n",
    "                    CI_Xvar = st.rv_discrete(a = -np.inf,values=(unique, pk))  \n",
    "                except:\n",
    "                    CI_Xvar = st.rv_discrete(a = -np.inf,values=(Xvar, np.array(len(Xvar)*[1/len(Xvar)])))         \n",
    "                plt.fill_between([binneddf[0].min()-1,binneddf[0].max()+1], CI_Xvar.interval(0.68)[0], CI_Xvar.interval(0.68)[1], color = 'g', alpha = 0.5)\n",
    "                plt.fill_between([binneddf[0].min()-1,binneddf[0].max()+1], CI_Xvar.interval(0.95)[0], CI_Xvar.interval(0.95)[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "            except:\n",
    "                CI68_Xvar = st.norm.interval(alpha=0.68, loc= Xvar_mean, scale=np.std(Xvar))                \n",
    "                CI95_Xvar = st.norm.interval(alpha=0.95, loc= Xvar_mean, scale=np.std(Xvar))\n",
    "                plt.fill_between([binneddf[0].min()-1,binneddf[0].max()+1], CI68_Xvar[0], CI68_Xvar[1], color = 'g', alpha = 0.5)\n",
    "                plt.fill_between([binneddf[0].min()-1,binneddf[0].max()+1], CI95_Xvar[0], CI95_Xvar[1], color = 'g', alpha = 0.5)\n",
    "\n",
    "            plt.minorticks_on()\n",
    "            plt.tick_params(axis='x', which = 'major', top = True, direction= 'in', length = 8)\n",
    "            plt.tick_params(axis='x', which = 'minor', top = True, direction= 'in', length = 4)\n",
    "            plt.legend(loc = 'upper right')\n",
    "\n",
    "            plt.xlabel('Time (BTJD - days)')\n",
    "            plt.ylabel(r\"$σ_{XS}^{2}$\")\n",
    "\n",
    "            plt.xlim(xmin = binneddf[0].min()-1, xmax = binneddf[0].max()+1)\n",
    "\n",
    "            if sectbysect == True:\n",
    "                plt.title(target+r': $σ_{XS}^{2}$, '+bin_time+'hr bins sectors '+group,fontsize='x-large')\n",
    "                plt.savefig(subdir+'/'+target+'_excess_rms_varianceCI_'+bin_time+'hr_sectors'+group+'.pdf', format = 'pdf',bbox_inches='tight') \n",
    "            else:\n",
    "                plt.title(target+r': $σ_{XS}^{2}$, '+bin_time+'hr bins',fontsize='x-large')\n",
    "                plt.savefig(subdir+'/'+target+'_excess_rms_varianceCI_'+bin_time+'hr.pdf', format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "        #                     plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        except:\n",
    "            plt.close()\n",
    "            print(\"I was givin' 'er all she's got Cap'n\")\n",
    "\n",
    "    return()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f563f48-7e93-4b9e-b241-7a1c9edc06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition of various functions regarding light curve modification \n",
    "including interpolation, stitching, and rebinning \n",
    "'''\n",
    "\n",
    "def interpolate_data(target, df, pcm):\n",
    "    '''\n",
    "    Interpolation of light curve or light curve secgments\n",
    "    \n",
    "     inputs:\n",
    "         target (string)        - Name of desired object to analyze\n",
    "         df (DataFrame)         - dataframe of uninterpolated light curve\n",
    "         pcm (int)              - specifier of regression pricipal component method\n",
    "         \n",
    "     outputs:\n",
    "        interp_df (DataFrame)   - dataframe of interpolated light curve\n",
    "        \n",
    "    '''\n",
    "\n",
    "    \n",
    "    sampspace = np.round(df[0][1]-df[0][0],6)\n",
    "    delt_crit = round_up_decimals(sampspace,5)\n",
    "#     print(delt_crit)\n",
    "    \n",
    "                        \n",
    "    time = [df[0][0]]\n",
    "    flux = [df[1][0]]\n",
    "    err = [df[2][0]]\n",
    "  \n",
    "    ## Sequence of finding gaps in data, linearly interpolating between gaps, and plotting of new figures.\n",
    "                        \n",
    "    for i in range(1,len(df[0])):\n",
    "        \n",
    "        delt = df[0][i] - df[0][i-1]\n",
    "        \n",
    "        if delt > delt_crit:\n",
    "            buffer_bad = True\n",
    "            pts = 15\n",
    "                        \n",
    "            early_time_buffer = []\n",
    "            late_time_buffer = []\n",
    "            \n",
    "            early_flux_buffer = []\n",
    "            late_flux_buffer = []\n",
    "\n",
    "            while buffer_bad and pts >=1:\n",
    "                try:\n",
    "                    early_time_buffer = df[0][i-pts:i]\n",
    "                    late_time_buffer = df[0][i:i+pts]\n",
    "\n",
    "                    early_flux_buffer = df[1][i-pts:i]\n",
    "                    late_flux_buffer = df[1][i:i+pts]\n",
    "                    \n",
    "                    buffer_bad = False\n",
    "                \n",
    "                    \n",
    "                except:\n",
    "                    pts -= 1\n",
    "                    \n",
    "            \n",
    "            t_gap = np.arange(start = df[0][i-1] + sampspace, stop = df[0][i], step = sampspace)\n",
    "            f_gap = np.interp(x = t_gap, xp = np.append(early_time_buffer, late_time_buffer), fp = np.append(early_flux_buffer,late_flux_buffer))\n",
    "            e_gap = np.zeros(len(t_gap))\n",
    "                               \n",
    "            time.extend(np.array(t_gap))\n",
    "            flux.extend(np.array(f_gap))\n",
    "            err.extend(np.array(e_gap))\n",
    "            \n",
    "        else: \n",
    "            time.append(df[0][i])\n",
    "            flux.append(df[1][i])\n",
    "            err.append(df[2][i])\n",
    "    \n",
    "\n",
    "    interp_df = pd.DataFrame(np.column_stack((time,flux,err)),columns = None, index = None)\n",
    "    \n",
    "    interp_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    interp_df = interp_df.dropna()\n",
    "    \n",
    "    if pcm == 1: \n",
    "        interp_df.to_csv(directory+'/'+target+'_cycle1_PCA_interpolated_lc.dat',sep = ' ',header = False, index = False)\n",
    "    if pcm == 2: \n",
    "        interp_df.to_csv(directory+'/'+target+'_cycle1_simple_hybrid_interpolated_lc.dat',sep = ' ',header = False, index = False)\n",
    "    if pcm == 3: \n",
    "        interp_df.to_csv(directory+'/'+target+'_cycle1_full_hybrid_interpolated_lc.dat',sep = ' ',header = False, index = False)\n",
    "\n",
    "    \n",
    "    return(interp_df)\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "def bin_error(n, bins, flux):\n",
    "    '''\n",
    "    Calculate error on binned photometric flux\n",
    "    \n",
    "     inputs:\n",
    "         n (array)        - bin counts\n",
    "         bins (array)     - flux bins\n",
    "         flux (array)     - flux values\n",
    "         \n",
    "     outputs:\n",
    "        bin_err (array)   - error on flux bins\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    bin_err = np.zeros(len(n))\n",
    "\n",
    "    for i in range(0,len(n)):\n",
    "        bin_flux = [x for x in flux if x >= bins[i] and x < bins[i+1]]\n",
    "        bin_err[i] = np.std(bin_flux)/np.sqrt(n[i])\n",
    "        \n",
    "    return(bin_err)\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "def rebinning(df,bin1,bin2):\n",
    "    '''\n",
    "    Rebin light curve under two user-specified schema (in hours)\n",
    "    \n",
    "     inputs:\n",
    "        n (array)         - bin counts\n",
    "        bin1 (string)     - string which specified how many hours for one binning scheme\n",
    "        bin2 (string)     - string which specified how many hours for one binning scheme\n",
    "        \n",
    "     outputs:\n",
    "        binnedflux_bin1 (DataFrame)   - data frame for binned flux under \n",
    "                                            specified binning scheme (time,flux,error)\n",
    "        binnedflux_bin2 (DataFrame)   - data frame for binned flux under \n",
    "                                            specified binning scheme (time,flux,error)\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    print(\"Rebinning.\\n\")\n",
    "    # Fill gaps in time with NaN as flux values\n",
    "    time, flux, err = df[0], df[1], df[2]\n",
    "    \n",
    "    ## Rebinning:\n",
    "    \n",
    "    time_bin1 = []\n",
    "    time_bin2 = []\n",
    "    \n",
    "    binflux_bin1 = []\n",
    "    binflux_bin2 = []\n",
    "    \n",
    "    binerr_bin1 = []\n",
    "    binerr_bin2 = []\n",
    "    \n",
    "    binstd_bin1 = []\n",
    "    binstd_bin2 = []\n",
    "\n",
    "    binN_bin1 = []\n",
    "    binN_bin2 = []\n",
    "    \n",
    "    binMSE_bin1 = []\n",
    "    binMSE_bin2 = []\n",
    "    \n",
    "\n",
    "    for j in range(0,2):\n",
    "        tmp_time = time[0]\n",
    "        tmp_time_idx = 0\n",
    "        \n",
    "        tbin = [time[0]]\n",
    "        fbin = [flux[0]]\n",
    "        ebin = [err[0]]\n",
    "        \n",
    "        for i in range(1,len(time)):\n",
    "                 \n",
    "            if j == 0 and (time[i] - tmp_time) >= np.round((bin1*0.04166667),4): \n",
    "                \n",
    "                temp_bin = np.column_stack((fbin,ebin))\n",
    "                \n",
    "                time_bin1.append(np.nanmean(tbin))\n",
    "                binflux_bin1.append(np.nanmean([x for x,y in temp_bin if y != 0.0]))\n",
    "                N = len([x for x,y in temp_bin if y != 0.0])\n",
    "                binN_bin1.append(N)\n",
    "                binerr_bin1.append(np.sqrt(np.nansum([y**2 for x,y in temp_bin if y != 0.0]))/N)\n",
    "                binstd_bin1.append(np.nanstd([x for x,y in temp_bin if y != 0.0], ddof = 1))\n",
    "                binMSE_bin1.append(np.nanmean([y**2 for x,y in temp_bin if y != 0.0]))\n",
    "                \n",
    "                \n",
    "                tmp_time = time[i]\n",
    "                tbin = [time[i]]\n",
    "                fbin = [flux[i]]\n",
    "                ebin = [err[i]]\n",
    "                                \n",
    "                 \n",
    "            elif j == 1 and (time[i] - tmp_time) >= np.round((bin2*0.04166667),4): \n",
    "                \n",
    "                temp_bin = np.column_stack((fbin,ebin))\n",
    "                \n",
    "                time_bin2.append(np.nanmean(tbin))\n",
    "                binflux_bin2.append(np.nanmean([x for x,y in temp_bin if y != 0.0]))\n",
    "                N = len([x for x,y in temp_bin if y != 0.0])\n",
    "                binN_bin2.append(N)\n",
    "                binerr_bin2.append(np.sqrt(np.nansum([y**2 for x,y in temp_bin if y != 0.0]))/N)\n",
    "                binstd_bin2.append(np.nanstd([x for x,y in temp_bin if y != 0.0], ddof = 1))\n",
    "                binMSE_bin2.append(np.nanmean([y**2 for x,y in temp_bin if y != 0.0]))\n",
    "                \n",
    "                \n",
    "                tmp_time = time[i]\n",
    "                tbin = [time[i]]\n",
    "                fbin = [flux[i]]\n",
    "                ebin = [err[i]]\n",
    "                                \n",
    "            elif i == len(time):\n",
    "                \n",
    "                if j == 0:\n",
    "                    time_bin1.append(np.nanmean(tbin))\n",
    "                    binflux_bin1.append(np.nanmean([x for x,y in temp_bin if y != 0.0]))\n",
    "                    N = len([x for x,y in temp_bin if y != 0.0])\n",
    "                    binN_bin1.append(N)\n",
    "                    binerr_bin1.append(np.sqrt(np.nansum([y**2 for x,y in temp_bin if y != 0.0]))/N)\n",
    "                    binstd_bin1.append(np.nanstd([x for x,y in temp_bin if y != 0.0], ddof = 1))\n",
    "                    binMSE_bin1.append(np.nanmean([y**2 for x,y in temp_bin if y != 0.0]))\n",
    "                    \n",
    "                elif j == 1:\n",
    "                    time_bin2.append(np.nanmean(tbin))\n",
    "                    binflux_bin2.append(np.nanmean([x for x,y in temp_bin if y != 0.0]))\n",
    "                    N = len([x for x,y in temp_bin if y != 0.0])\n",
    "                    binN_bin2.append(N)\n",
    "                    binerr_bin2.append(np.sqrt(np.nansum([y**2 for x,y in temp_bin if y != 0.0]))/N)\n",
    "                    binstd_bin2.append(np.nanstd([x for x,y in temp_bin if y != 0.0], ddof = 1))\n",
    "                    binMSE_bin2.append(np.nanmean([y**2 for x,y in temp_bin if y != 0.0]))\n",
    "                    \n",
    "            else:\n",
    "                tbin.append(time[i])\n",
    "                fbin.append(flux[i])\n",
    "                ebin.append(err[i])\n",
    "                                \n",
    "                        \n",
    "\n",
    "    binnedflux_bin1 = pd.DataFrame(np.column_stack((time_bin1, binflux_bin1, binerr_bin1, binstd_bin1,binN_bin1,binMSE_bin1)))\n",
    "    binnedflux_bin2 = pd.DataFrame(np.column_stack((time_bin2, binflux_bin2, binerr_bin2, binstd_bin2,binN_bin2,binMSE_bin2)))\n",
    "\n",
    "    binnedflux_bin1.replace([np.inf ,0.0, -np.inf], np.nan)\n",
    "    binnedflux_bin2.replace([np.inf, 0.0, -np.inf], np.nan)\n",
    "    binnedflux_bin1 = binnedflux_bin1.dropna()\n",
    "    binnedflux_bin1 = binnedflux_bin1.reset_index(drop=True)\n",
    "    binnedflux_bin2 = binnedflux_bin2.dropna()\n",
    "    binnedflux_bin2 = binnedflux_bin2.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "\n",
    "    return(binnedflux_bin1,binnedflux_bin2)\n",
    "\n",
    "\n",
    "def lc_stitch(unstitched_lc):\n",
    "    '''\n",
    "    Stitch together multiple sectors of light curve if not already stitched\n",
    "    \n",
    "     inputs:\n",
    "        unstitched_lc (array of arrays)   - multi-sector light curve\n",
    "     outputs:\n",
    "        full_lc_time (array)              - stitched light curve component\n",
    "        full_lc_flux (array)              - stitched light curve component\n",
    "        full_lc_err (array)               - stitched light curve component\n",
    "    '''\n",
    "\n",
    "    for j in range(0,len(unstitched_lc)):\n",
    "        if j!=0:\n",
    "            sector = str(j+1)\n",
    "\n",
    "        lc = unstitched_lc[j]\n",
    "\n",
    "        t = lc[:,0]\n",
    "        f = lc[:,1]\n",
    "        err = lc[:,2]\n",
    "\n",
    "\n",
    "        if j == 0:\n",
    "\n",
    "            full_lc_time = t\n",
    "            full_lc_flux = f\n",
    "            full_lc_err= err\n",
    "\n",
    "        else:\n",
    "\n",
    "            first_flux = np.mean(f[:10])\n",
    "            last_flux = np.mean(full_lc_flux[-10:])\n",
    "\n",
    "            scale_factor= first_flux - last_flux\n",
    "\n",
    "            if scale_factor > 0:\n",
    "\n",
    "                scaled_flux = f - abs(scale_factor)\n",
    "\n",
    "            if scale_factor < 0:\n",
    "\n",
    "                scaled_flux = f + abs(scale_factor)\n",
    "\n",
    "            full_lc_time = np.append(full_lc_time,t)\n",
    "            full_lc_flux = np.append(full_lc_flux,scaled_flux)\n",
    "            full_lc_err = np.append(full_lc_err,err)\n",
    "\n",
    "    return(full_lc_time,full_lc_flux,full_lc_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c819cc-aa7c-41d9-bd31-1037fe1d18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognormal_fit(n, flux, bins, bin_center, bin_err, i, directory, save_tail, bin1, bin2, visual = False):    \n",
    "    '''\n",
    "    Algorithm to fit distribution to lognormal curve\n",
    "    \n",
    "     inputs:\n",
    "        n (array)                    - bin counts\n",
    "        flux (array)                 - flux values\n",
    "        bins (array)                 - flux bins\n",
    "        bin_center (array)           - flux bin centers\n",
    "        bin_err (array)              - bin errors\n",
    "        i (int)                      - specifier for which version of light curve is being analyzed \n",
    "        directory (directory)        - The directory in which figures will be saved\n",
    "        save_tail (string)           - tail of name assigned to file to be saved\n",
    "        bin1 (string)                - string which specified how many hours for one binning scheme\n",
    "        bin2 (string)                - string which specified how many hours for one binning scheme)\n",
    "        visual (boolean)             - should figures be shown\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    maxfreq = n.max()\n",
    "\n",
    "    if len(str(int(bin_center[0] +0.5))) <= 2:\n",
    "        tick_labels = [str(np.round(x,decimals=2)) for x in bin_center]\n",
    "        \n",
    "    elif len(str(int(bin_center[0] + 0.5))) == 3 :\n",
    "        tick_labels = [str(np.round(x,decimals=1)) for x in bin_center]\n",
    "        \n",
    "    else:\n",
    "        tick_labels = [str(int(x + 0.5)) for x in bin_center]\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    shape, loc, scale = st.lognorm.fit(np.array(flux), method = \"MM\")\n",
    "    init_params = (maxfreq, np.log(scale), shape)\n",
    "    \n",
    "    lognorm_m = op.minimize(Min_PDF, [*init_params], args=(np.array((n,bins),dtype='object'),lognormal), method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "    lognorm_pars = lognorm_m['x']\n",
    "    \n",
    "    plt.bar(bin_center, n, width = 0.8*(bin_center[1]-bin_center[0]), alpha=0.9, color= 'b', align='center',tick_label=tick_labels) # yerr=bin_err, \n",
    "\n",
    "       \n",
    "    logbins = np.linspace(bins[0],bins[-1:],num=500)\n",
    "    lognorm_fit = st.lognorm.pdf(logbins,shape,loc,scale)\n",
    "\n",
    "\n",
    "    fit_max = np.max(lognorm_fit)\n",
    "    fit_mean = loc\n",
    "\n",
    "    plt.plot(logbins,lognorm_fit,color='r',label='log-normal fit')#\\n$χ^{2}: %.2e, p: %.2f$'%(lognorm_chi2, lognorm_p))\n",
    "    plt.axvline(fit_mean,color= 'k',linestyle = 'dashed')\n",
    "\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "   \n",
    "    plt.suptitle('Flux distibution: '+target) \n",
    "    plt.xlabel('Flux bins')\n",
    "    plt.ylabel('Normalized N')\n",
    "    \n",
    "    if fit_mean >= bins[-1:][0] or fit_mean <= bins[0]: \n",
    "        # Set a clean x-axis limit.\n",
    "        plt.xlim(xmin = bins[0], xmax = bins[-1:][0])\n",
    "    \n",
    "    # Set a clean upper y-axis limit.\n",
    "    plt.ylim(ymax= 1.15*maxfreq if maxfreq>fit_max else 1.15*fit_max)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    if len(n) < 15:\n",
    "        plt.xticks(rotation=30)\n",
    "    else:\n",
    "        plt.xticks(rotation=90)\n",
    "    \n",
    "    if i==2:\n",
    "        plt.title(bin1+\" hr bins\")\n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_lognorm_'+bin1+'hr'+save_tail, format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "\n",
    "    if i==3:\n",
    "        plt.title(bin2+\" hr bins\")\n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_lognorm_'+bin2+'hr'+save_tail, format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "\n",
    "    if visual == True:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.close()\n",
    "    return()\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "def bimodal_fit(n, flux, bins, bin_center, bin_err, i, directory, save_tail, bin1, bin2, visual = False, init_params = None):\n",
    "    '''\n",
    "    Algorithm to fit distribution to bimodal normal curve\n",
    "    \n",
    "     inputs:\n",
    "        n (array)                    - bin counts\n",
    "        flux (array)                 - flux values\n",
    "        bins (array)                 - flux bins\n",
    "        bin_center (array)           - flux bin centers\n",
    "        bin_err (array)              - bin errors\n",
    "        i (int)                      - specifier for which version of light curve is being analyzed \n",
    "        directory (directory)        - The directory in which figures will be saved\n",
    "        save_tail (string)           - tail of name assigned to file to be saved\n",
    "        bin1 (string)                - string which specified how many hours for one binning scheme\n",
    "        bin2 (string)                - string which specified how many hours for one binning scheme)\n",
    "        visual (boolean)             - should figures be shown\n",
    "    '''\n",
    "    \n",
    "    flux = sorted(flux)\n",
    "    \n",
    "    if len(str(int(bin_center[0] +0.5))) <= 2:\n",
    "        tick_labels = [str(np.round(x,decimals=2)) for x in bin_center]\n",
    "        \n",
    "    elif len(str(int(bin_center[0] + 0.5))) == 3 :\n",
    "        tick_labels = [str(np.round(x,decimals=1)) for x in bin_center]\n",
    "        \n",
    "    else:\n",
    "        tick_labels = [str(int(x + 0.5)) for x in bin_center]\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    plt.bar(bin_center,n, width = 0.8*(bin_center[1]-bin_center[0]), alpha=0.9, color= 'b', align='center',tick_label=tick_labels) # yerr=bin_err,\n",
    "    \n",
    "\n",
    "\n",
    "    if init_params == None:\n",
    "        loc1, scale1 = st.norm.fit(flux[:roundedfractionalrange(flux, np.divide(2,3))])\n",
    "        loc2, scale2 = st.norm.fit(flux[-roundedfractionalrange(flux, np.divide(2,3)):])\n",
    "        init_params = (0.5, sorted(n)[-1:][0], loc1, scale1, sorted(n)[-4:][0], loc2, scale2)\n",
    "    \n",
    "    for j in range(0,len(init_params)):\n",
    "        if np.isnan(init_params[j]) == True:\n",
    "            print(\"nan at init_params[%i]\"%j)\n",
    "\n",
    "    bimod_m = op.minimize(Min_PDF, [*init_params], args=(np.array((n,bins),dtype='object'),bimodal), method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "    bimod_pars = bimod_m['x']\n",
    "    \n",
    "    fit_flux = np.linspace(bins[0],bins[-1:],num=500) \n",
    "    bimod_fit = bimodal(fit_flux, *bimod_pars)\n",
    "    \n",
    "    fit_max = np.max(bimodal(fit_flux,*bimod_pars))\n",
    "    maxfreq = n.max()\n",
    "    \n",
    "    mu1 = bimod_pars[2]\n",
    "    mu2 = bimod_pars[5]\n",
    "    \n",
    "    plt.plot(fit_flux, bimodal(fit_flux,*bimod_pars), color='r', label='bimodal fit')#\\n$χ^{2}: %.2e, p: %.2f$'%(bimod_chi2, bimod_p))\n",
    "    plt.axvline(mu1,color= 'k',linestyle = 'dashed', label = '$μ_{1}$')\n",
    "    plt.axvline(mu2,color= 'k',linestyle = 'dotted', label = '$μ_{2}$')\n",
    "    \n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.suptitle('Flux distibution: '+target) \n",
    "    plt.xlabel('Flux bins')\n",
    "    plt.ylabel('Normalized N')\n",
    "    \n",
    "    if mu1 >= bins[-1:][0] or mu1 <= bins[0] or mu2 >= bins[-1:][0] or mu2 <= bins[0]:\n",
    "        # Set a clean x-axis limit.\n",
    "        plt.xlim(xmin = bins[0], xmax = bins[-1:][0])\n",
    "        \n",
    "    # Set a clean upper y-axis limit.\n",
    "    plt.ylim(ymax= 1.15*maxfreq if maxfreq>fit_max else 1.15*fit_max)\n",
    "    plt.legend()\n",
    "    ticks = [int(np.round(x)) for x in bin_center]\n",
    "\n",
    "    ## Try to make sure all tick labels show and do not overlap        \n",
    "    if len(n) < 15:\n",
    "        plt.xticks(rotation=30)\n",
    "    else:\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "    if i==2:\n",
    "        plt.title(bin1+\" hr bins\")\n",
    "            \n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_bimodal_'+bin1+'hr'+save_tail, format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "    if i==3:\n",
    "        plt.title(bin2+\" hr bins\")\n",
    "            \n",
    "        plt.savefig(directory+'/'+target+'_flux_dist_bimodal_'+bin2+'hr'+save_tail, format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "    \n",
    "    if visual == True:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return()\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "\n",
    "def hist_and_fit(flux, i, subdir, target, sectbysect, group, bin1=0., bin2=0., visual = False):\n",
    "    '''\n",
    "    Algorithm to fit distribution to gaussian, bimodal gaussian, and lognormal curves\n",
    "    \n",
    "     inputs:\n",
    "        flux (array)                 - flux values\n",
    "        i (int)                      - specifier for which version of light curve is being analyzed \n",
    "        subdir (directory)           - The directory in which figures will be saved\n",
    "        target (string)              - target name\n",
    "        sectbysect (boolean)         - sector by sector analysis or not (default is False)\n",
    "        group (string)               - current sectors under analysis if sectbysect is True \n",
    "        bin1 (string)                - string which specified how many hours for one binning scheme\n",
    "        bin2 (string)                - string which specified how many hours for one binning scheme)\n",
    "        visual (boolean)             - should figures be shown\n",
    "    '''\n",
    "\n",
    "    if 0 < i < 4:\n",
    "        nonzeroflux = np.nonzero(np.array(flux))[0]\n",
    "        flux = np.array(uninterp_df[1][nonzeroflux])\n",
    "\n",
    "    ## Estimate initial statistical parameters then remove outliers beyond 5-sigma\n",
    "    try:\n",
    "        flux_mean, flux_stdev = st.norm.fit(np.array(flux), method = \"MM\")\n",
    "#         flux_mean = np.mean(flux)\n",
    "#         flux_stdev = np.std(flux)\n",
    "        flux_min = np.min(flux)\n",
    "        flux_max = np.max(flux)\n",
    "\n",
    "        fivesig = 5.0*flux_stdev\n",
    "        flux = [x for x in flux if np.abs(flux_mean - x) <= fivesig]\n",
    "\n",
    "        ## Reestimate statistical parameters without outliers\n",
    "        flux_mean, flux_stdev = st.norm.fit(np.array(flux), method = \"MM\")\n",
    "        flux_min = np.min(flux)\n",
    "        flux_max = np.max(flux)\n",
    "        \n",
    "    except:\n",
    "#         print(flux)\n",
    "        ## Estimate statistical parameters without outliers\n",
    "        flux_mean, flux_stdev = st.norm.fit(np.array(flux), method = \"MM\")\n",
    "        flux_min = np.min(flux)\n",
    "        flux_max = np.max(flux)\n",
    "        \n",
    "    \n",
    "    ###############################################################\n",
    "    \n",
    "    ## Make histograms of data with and without normalization\n",
    "    n, bins = np.histogram(flux, bins=OptBins(flux), range=(flux_min,flux_max), density=True)\n",
    "    m, bims = np.histogram(flux, bins=OptBins(flux), range=(flux_min,flux_max), density=False)\n",
    "\n",
    "    \n",
    "    bin_err = np.divide(bin_error(m, bims, flux),np.sum(m))\n",
    "#     bin_err = bin_error(m, bims, flux)\n",
    "#     bin_rms = RMS(m, bims, flux)\n",
    "      \n",
    "    bin_center = bins[:-1] + np.diff(bins) / 2\n",
    "    maxfreq = n.max()\n",
    "    \n",
    "\n",
    "    if len(str(int(bin_center[0] +0.5))) <= 2:\n",
    "        tick_labels = [str(np.round(x,decimals=2)) for x in bin_center]\n",
    "        \n",
    "    elif len(str(int(bin_center[0] + 0.5))) == 3 :\n",
    "        tick_labels = [str(np.round(x,decimals=1)) for x in bin_center]\n",
    "        \n",
    "    else:\n",
    "        tick_labels = [str(int(x + 0.5)) for x in bin_center]\n",
    "        \n",
    "    ###############################################################\n",
    "    \n",
    "    gauss_fit_good = False\n",
    "    \n",
    "    while gauss_fit_good == False:\n",
    "        \n",
    "        ## Obtain statistical parameters for assumed Gaussian fit\n",
    "        init_params = (n.max(), flux_mean, flux_stdev)\n",
    "        try:\n",
    "            gauss_pars, _ = curve_fit(gaussian, xdata=bin_center, ydata=n, p0=init_params, sigma=bin_err, maxfev= 1000)#, absolute_sigma = True)\n",
    "        \n",
    "            gauss_m = op.minimize(Min_PDF, [*gauss_pars], args=(np.array((n,bins),dtype='object'),gaussian), method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "        except:\n",
    "            gauss_m = op.minimize(Min_PDF, [*init_params], args=(np.array((n,bins),dtype='object'),gaussian), method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "            \n",
    "        gauss_pars = gauss_m['x']\n",
    "        \n",
    "        fit_mean = gauss_pars[1]\n",
    "        fit_stdev = np.abs(gauss_pars[2])\n",
    "                \n",
    "        fit_FWHM = 2.0*np.sqrt(2.0*np.log(2.0))*fit_stdev ## assuming gaussian distribution\n",
    "\n",
    "        plt.figure(figsize=(12,6), constrained_layout=True)\n",
    "        # plt.figure(figsize=(15,6))\n",
    "\n",
    "        ## Plot flux histogram as bar chart for special width and error bars\n",
    "        plt.bar(bin_center, n, width = 0.85*(bin_center[1]-bin_center[0]), alpha=0.9, color= 'b', align='center',tick_label=tick_labels) #yerr=bin_err,\n",
    "\n",
    "\n",
    "        ## Plot Gaussian fit over histogram\n",
    "        fit_flux = np.linspace(bins[0],bins[-1:],num=500)\n",
    "        \n",
    "        gaussian_fit = gaussian(fit_flux, *gauss_pars)\n",
    "        fit_max = np.max(gaussian_fit)\n",
    "        plt.plot(fit_flux,gaussian_fit,color='r',label='Gaussian fit')#\\n$χ^{2}: %.2e, p: %.2f$'%(gauss_chi2, gauss_p))\n",
    "        \n",
    "        \n",
    "        ## Mark mean\n",
    "        plt.axvline(fit_mean,color= 'k',linestyle = 'dashed', label = 'Mean = %.3e\\nσ = %.3e'%(fit_mean,fit_stdev))\n",
    "\n",
    "        ## Mark mean +/- stddev\n",
    "        if fit_mean+fit_stdev <= flux_max:\n",
    "            plt.axvline(fit_mean+fit_stdev,color= 'k',linestyle = 'dotted')\n",
    "            plt.annotate(text='', xy=(fit_mean,1.05*maxfreq), xytext=(fit_mean+fit_stdev,1.05*maxfreq), arrowprops=dict(arrowstyle='<->'))\n",
    "        else:\n",
    "            plt.axvline(fit_mean-fit_stdev,color= 'k',linestyle = 'dotted')\n",
    "            plt.annotate(text='', xy=(fit_mean,1.05*maxfreq), xytext=(fit_mean-fit_stdev,1.05*maxfreq), arrowprops=dict(arrowstyle='<->'))\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        ###############################################################\n",
    "        ## Create or save to new flux distributions directory\n",
    "        try:\n",
    "            directory = os.path.join(subdir, 'flux_distributions')\n",
    "            os.mkdir(directory)\n",
    "\n",
    "            print(\"Directory '%s' created\\n\" %directory)    \n",
    "        except FileExistsError:\n",
    "            directory = subdir+'/flux_distributions'\n",
    "            \n",
    "        if sectbysect == True:\n",
    "            save_tail = '_sectors'+group+'.pdf'\n",
    "            try:\n",
    "                directory = os.path.join(subdir, 'flux_distributions/Sector_by_sector/')\n",
    "                os.mkdir(directory)\n",
    "\n",
    "                print(\"Directory '%s' created\\n\" %directory)    \n",
    "            except FileExistsError:\n",
    "                directory = subdir+'/flux_distributions/Sector_by_sector/'\n",
    "        else:\n",
    "            save_tail = '.pdf'\n",
    "\n",
    "        ###############################################################\n",
    "\n",
    "        if i < 4 :\n",
    "            if fit_mean+fit_stdev <= flux_max:\n",
    "                plt.text(fit_mean+0.45*fit_stdev,1.07*maxfreq,'σ$_{F}$',fontsize='medium')\n",
    "            else:\n",
    "                plt.text(fit_mean-0.45*fit_stdev,1.07*maxfreq,'σ$_{F}$',fontsize='medium')\n",
    "\n",
    "            plt.suptitle('Flux distibution: '+target)\n",
    "            plt.xlabel('Flux bins')\n",
    "\n",
    "        elif i >= 4 :\n",
    "            if fit_mean+fit_stdev <= flux_max:\n",
    "                plt.text(fit_mean+0.45*fit_stdev,1.07*maxfreq,'σ$_{ΔF}$',fontsize='medium')\n",
    "            else:\n",
    "                plt.text(fit_mean-0.45*fit_stdev,1.07*maxfreq,'σ$_{ΔF}$',fontsize='medium')\n",
    "\n",
    "            plt.suptitle('Subsequent Flux distibution: '+target)\n",
    "            plt.xlabel('ΔF$_{ij}$')\n",
    "\n",
    "        ## Try to make sure all tick labels show and do not overlap        \n",
    "        if len(n) < 15:\n",
    "            plt.xticks(rotation=30)\n",
    "        else:\n",
    "            plt.xticks(rotation=90)\n",
    "\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.ylabel('Normalized N')\n",
    "\n",
    "        if fit_mean >= bins[-1:][0] or fit_mean <= bins[0]:\n",
    "            # Set a clean x-axis limit.\n",
    "            plt.xlim(xmin = bins[0], xmax = bins[-1:][0])\n",
    "        \n",
    "        # Set a clean upper y-axis limit.\n",
    "        plt.ylim(ymax = 1.15*maxfreq if maxfreq > fit_max else 1.15*fit_max)\n",
    "\n",
    "        # Set a clean 5-sigma x-axis limit.\n",
    "    #     fivesig = 5.0*fit_stdev\n",
    "    #     plt.xlim(xmin = (fit_mean - 1.1*fivesig) if np.abs(fit_mean - np.min(bin_center)) > fivesig else (np.min(bin_center) - 0.1*np.abs(np.min(bin_center))),\\\n",
    "    #         xmax = (fit_mean + 1.1*fivesig) if np.abs(np.max(bin_center) - fit_mean) > fivesig else (np.max(bin_center) + 0.1*np.abs(np.max(bin_center))) )\n",
    "\n",
    "\n",
    "        if i == 0:\n",
    "            plt.title(\"Raw light curve, unbinned\")\n",
    "            plt.savefig(directory+'/'+target+'_raw_flux_dist_gauss_unbinned'+save_tail, format = 'pdf')\n",
    "\n",
    "        if i == 1:\n",
    "            plt.title(\"Quaver regression, unbinned\")\n",
    "            plt.savefig(directory+'/'+target+'_flux_dist_gauss_unbinned'+save_tail, format = 'pdf')\n",
    "\n",
    "        if i == 2:\n",
    "            plt.title(\"Quaver regression, \"+bin1+\" hr bins\")\n",
    "            plt.savefig(directory+'/'+target+'_flux_dist_gauss_'+bin1+'hr'+save_tail, format = 'pdf')\n",
    "\n",
    "        if i == 3:\n",
    "            plt.title(\"Quaver regression, \"+bin2+\" hr bins\")\n",
    "            plt.savefig(directory+'/'+target+'_flux_dist_gauss_'+bin2+'hr'+save_tail, format = 'pdf')\n",
    "\n",
    "\n",
    "\n",
    "        if i == 4:\n",
    "            plt.title(\"Raw light curve, unbinned\")\n",
    "            plt.savefig(directory+'/'+target+'_raw_subflux_dist_unbinned'+save_tail, format = 'pdf')\n",
    "\n",
    "        if i == 5:\n",
    "            plt.title(\"Quaver regression, unbinned\")\n",
    "            plt.savefig(directory+'/'+target+'_subflux_dist_unbinned'+save_tail, format = 'pdf')\n",
    "\n",
    "        if i == 6:\n",
    "            plt.title(\"Quaver regression, \"+bin1+\" hr bins\")\n",
    "            plt.savefig(directory+'/'+target+'_subflux_dist_'+bin1+'hr'+save_tail, format = 'pdf')\n",
    "\n",
    "        if i == 7:\n",
    "            plt.title(\"Quaver regression, \"+bin2+\" hr bins\")\n",
    "            plt.savefig(directory+'/'+target+'_subflux_dist_'+bin2+'hr'+save_tail, format = 'pdf')\n",
    "\n",
    "\n",
    "#         visual = True\n",
    "        if visual == True:\n",
    "            plt.show()\n",
    "        \n",
    "            fit_check = input(\"Is gaussian fit satisfactory? [y/n] \")\n",
    "\n",
    "            if fit_check == \"y\" or fit_check == \"Y\" or fit_check == \"yes\" or fit_check == \"YES\":\n",
    "                gauss_fit_good = True\n",
    "            else: \n",
    "                continue\n",
    "        else:\n",
    "            gauss_fit_good = True\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    if i > 1 and i < 4 :\n",
    "        lognorm_fit_good = False\n",
    "        while lognorm_fit_good == False:\n",
    "            \n",
    "            \n",
    "            lognormal_fit(n, flux, bins, bin_center, bin_err, i, directory, save_tail, bin1, bin2, visual = False)\n",
    "            \n",
    "            if visual == True:\n",
    "            \n",
    "                fit_check = input(\"Is lognormal fit satisfactory? [y/n] \")\n",
    "            \n",
    "                if fit_check == \"y\" or fit_check == \"Y\" or fit_check == \"yes\" or fit_check == \"YES\":\n",
    "                    lognorm_fit_good = True\n",
    "                else: \n",
    "                    continue\n",
    "                plt.close()\n",
    "                \n",
    "        \n",
    "            else:\n",
    "                lognorm_fit_good = True\n",
    "                plt.close()\n",
    "        \n",
    "        \n",
    "        bimodal_fit_good = False\n",
    "        while bimodal_fit_good == False:\n",
    "            \n",
    "            bimodal_fit(n, flux, bins, bin_center, bin_err, i, directory, save_tail, bin1, bin2, visual = False)\n",
    "            \n",
    "            if visual == True:\n",
    "                fit_check = input(\"Is bimodal fit satisfactory? [y/n] \")\n",
    "            \n",
    "                if fit_check == \"y\" or fit_check == \"Y\" or fit_check == \"yes\" or fit_check == \"YES\":\n",
    "                    bimodal_fit_good = True\n",
    "                else: \n",
    "                    continue\n",
    "                plt.close()\n",
    "                \n",
    "            else:\n",
    "                bimodal_fit_good = True\n",
    "                plt.close()\n",
    "                \n",
    "            \n",
    "\n",
    "    return(fit_stdev, flux_mean, flux_min, flux_max, bin_center)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25863064-9dc4-4aa0-a5ac-e68a48b885e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin by setting the driectory in which the target files are kept as rootdir\n",
    "\n",
    "## Choose sample \"analysis\" or \"removed\"\n",
    "sample = \"analysis\"\n",
    "\n",
    "if sample == \"analysis\":\n",
    "    rootdir = '/users/rdingler/AGNstudy/LightCurves/Analysis/'\n",
    "if sample == \"removed\":\n",
    "    rootdir = '/users/rdingler/AGNstudy/LightCurves/Removed_sample/'\n",
    "\n",
    "## User should specficy whether thay would like a secondary data sheet with user-specified modification\n",
    "## Specify modifications at bottom of program\n",
    "## May prove useful for very large or very small numbers\n",
    "adj = True  \n",
    "\n",
    "\n",
    "## Set cycle number and Pricipal Component Method\n",
    "# pcm == 1: principal component analysis\n",
    "# pcm == 2: simple hybrid method\n",
    "# pcm == 3: full hybrid method\n",
    "\n",
    "cycle = '1'\n",
    "pcm = 2\n",
    "\n",
    "if pcm == 1: \n",
    "    file_tail = '_cycle'+cycle+'_PCA_lc.dat'\n",
    "if pcm == 2: \n",
    "    file_tail = '_cycle'+cycle+'_hybrid_lc.dat'\n",
    "if pcm == 3: \n",
    "    file_tail = '_cycle'+cycle+'_full_hybrid_lc.dat'\n",
    "\n",
    "## Set binning schema for binned light curve analysis in hours\n",
    "bin1 = '6' #hrs\n",
    "bin2 = '12' #hrs \n",
    "\n",
    "## Set some specific designation which will be used later to identify the spliced light curves as output by quaver\n",
    "## This will pick these files for use if provided. If not available, say, in the case of sector by sector analysis\n",
    "## wherein this file is the etire light curve, this will help the algorithm to know that it needs to collect and \n",
    "## synthesize each sector as specified by the user. User should write use the definition above for \"lc_stitch\"\n",
    "## to manually make stitched light curves for their desired sector groupings if not individual.\n",
    "    \n",
    "file_mid = '_spliced_lightcurve_sectors_'\n",
    "\n",
    "## Counting as preventative measure when only wanting to do a limited number of files. Disable if all files should be read.\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71dc744-ee0a-48c7-8fba-658893c835b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs , files in os.walk(rootdir):\n",
    "    \n",
    "    count += 1\n",
    "    # if count == 2:\n",
    "    #     sys.exit()\n",
    "     \n",
    "    ## Get target name from subdirectory name\n",
    "    target = os.path.basename(subdir)\n",
    "    \n",
    "        \n",
    "    ## Initialize arrays for plotting\n",
    "    for file in files:\n",
    "        sectbysect = False\n",
    "#          rmv_file_denote = ''\n",
    "#         if file.endswith('rmv_file_denote'):  ## lines only included in case of cleanup\n",
    "#             os.remove(os.path.join(subdir,file))\n",
    "\n",
    "        if file.endswith(file_tail) or file_mid in file:\n",
    "            ## When walking through directories, make sure to specify which directory names are not to be included\n",
    "            ## User should make sure this method works for their arrangement of quaver output files and any other\n",
    "            ## preliminary data stored in the same directory as the quaver output\n",
    "            if target != \"\" and target != \"eleanor_apertures\" and target != \"quaver_lc_apertures\" and \\\n",
    "                target != \"flux_distributions\" and target != \"Preliminary_tests\" and target != \"LCs_forpub\" and\\\n",
    "                    target != \".ipynb_checkpoints\" and target != \"Sector_by_sector\":\n",
    "                print(\"Target: %s\"%target)\n",
    "                \n",
    "            print(\"\\nWorking in directory: %s\\n\"%subdir)\n",
    "            \n",
    "            \n",
    "            \n",
    "            group = ''\n",
    "            \n",
    "            try:\n",
    "                if file_mid in file: ## if True, this object is designated for sector by sector analysis by user-specified designation\n",
    "                    sectbysect = True\n",
    "                    unstitched_lc = []\n",
    "\n",
    "                    group = file.partition('sectors_')[2].partition('.dat')[0]\n",
    "                    print(\"Analyzing spliced sectors \"+group+\" from file '%s\"%file+\"'\")\n",
    "                    sectors = np.array([s for s in group.split('+')])\n",
    "                    for sector in sectors:\n",
    "                        raw_df = pd.read_table(os.path.join(subdir, target+'_cycle'+cycle+'_sector'+sector+'_raw_lc.dat'), sep = ' ', header=None, dtype='float')\n",
    "                        unstitched_lc.append(np.column_stack((raw_df[0],raw_df[1],raw_df[2])))\n",
    "\n",
    "                    t_raw, f_raw, e_raw = lc_stitch(unstitched_lc)\n",
    "                    raw_df = pd.DataFrame(np.column_stack((t_raw,f_raw,e_raw)),columns = None, index = None)\n",
    "\n",
    "                else:\n",
    "                    print(\"Analyzing full light curve from file '%s\"%file+\"'\")\n",
    "                    raw_df = pd.read_table(os.path.join(subdir, target+'_full_raw_lc.dat'), sep = ' ', header=None, dtype='float')\n",
    "                raw = True\n",
    "            except:\n",
    "                raw = False\n",
    "                    \n",
    "            check_col_label(rootdir,str(bin1),str(bin2),sample = sample, raw = raw)\n",
    "\n",
    "            if sample == \"analysis\":\n",
    "                lc_data = open(os.path.join(rootdir,'LC_variability_analysis.csv') , \"a\")\n",
    "            if sample == \"removed\":\n",
    "                lc_data = open(os.path.join(rootdir,'LC_variability_rmv.csv') , \"a\")\n",
    "                \n",
    "            writer = csv.writer(lc_data)\n",
    "\n",
    "            uninterp_df = pd.read_table(os.path.join(subdir, file), sep = ' ', header=None, dtype='float')\n",
    "            \n",
    "            \n",
    "###############################################################################################             \n",
    "## Find shortest timescales of exponential rise and decay\n",
    "            print(\"\\nFinding shortest time scales of variablity. This may take a while for light light curves.\")        \n",
    "            tau_dec_min, delt_dec_min, tau_inc_min, delt_inc_min = shortest_timescale(rootdir,target,uninterp_df,sectbysect,sectors=group)\n",
    "            \n",
    "            \n",
    "############################################################################################### \n",
    "## Find (Smith 2018) statistics and check flux-change distribution, \n",
    "## as well as comparing the flux-change in the unbinned raw vs the unbinned corrected data\n",
    "\n",
    "            df = interpolate_data(target,uninterp_df)\n",
    "            binnedflux_bin1, binnedflux_bin2 = rebinning(df,float(bin1),float(bin2))\n",
    "            \n",
    "            print(\"\\nFitting histograms of flux data\")\n",
    "            for i in range(0,4):\n",
    "                if i == 0 and raw == True:\n",
    "                    lc_raw_stdev, flux_raw_mean, flux_raw_min , flux_raw_max, flux_raw_bins= hist_and_fit(raw_df[1],i,subdir,target,sectbysect,group)\n",
    "                if i == 1:\n",
    "                    lc_reg_stdev, flux_reg_mean, flux_reg_min , flux_reg_max, flux_reg_bins = hist_and_fit(uninterp_df[1],i,subdir,target,sectbysect,group)\n",
    "                if i == 2:\n",
    "                    lc_bin1_stdev, flux_bin1_mean, flux_bin1_min , flux_bin1_max, flux_bin1_bins = hist_and_fit(binnedflux_bin1[1],i,subdir,target,sectbysect,group,bin1=bin1,bin2=bin2)\n",
    "                if i == 3:\n",
    "                    lc_bin2_stdev, flux_bin2_mean, flux_bin2_min , flux_bin2_max, flux_bin2_bins = hist_and_fit(binnedflux_bin2[1],i,subdir,target,sectbysect,group,bin1=bin1,bin2=bin2)\n",
    "\n",
    "#######################################################################################                    \n",
    "## Find F-parameters\n",
    "## Potentially useful staistic but not in this case\n",
    "\n",
    "#             F_param_reg = lc_reg_stdev**2 / np.nanmean(df[2]**2)\n",
    "#             F_param_bin1 = lc_bin1_stdev**2 / np.nanmean(binnedflux_bin1[2])\n",
    "#             F_param_bin2 = lc_bin2_stdev**2 / np.nanmean(binnedflux_bin2[2])\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "## Excess variance and fractional rms amplitude calculations for intrabin data\n",
    "            \n",
    "            print(\"\\nCalculating excess variance within %s hr and %s hr bins\"%(bin1,bin2))\n",
    "            Xvar_bin1, Fvar_bin1, XvarErr_bin1, FvarErr_bin1 = excess_variance(binnedflux_bin1[0],binnedflux_bin1[1],binnedflux_bin1[2],\\\n",
    "                                                                            stdev = binnedflux_bin1[3], len_lc = binnedflux_bin1[4], MSE = binnedflux_bin1[5] , total = False)\n",
    "            \n",
    "            Xvar_bin1_mean = np.nanmean(Xvar_bin1)\n",
    "            Fvar_bin1_mean = np.nanmean(Fvar_bin1)\n",
    "            \n",
    "            plot_excess_variance(subdir, df, binnedflux_bin1, Xvar_bin1, XvarErr_bin1, Xvar_bin1_mean, Fvar_bin1, FvarErr_bin1, Fvar_bin1_mean, bin1, sectbysect, group)\n",
    "            \n",
    "            \n",
    "            \n",
    "            ##########################################################################\n",
    "            ##########################################################################\n",
    "\n",
    "\n",
    "            Xvar_bin2, Fvar_bin2, XvarErr_bin2, FvarErr_bin2 = excess_variance(binnedflux_bin2[0],binnedflux_bin2[1],binnedflux_bin2[2],\\\n",
    "                                                                            stdev = binnedflux_bin2[3], len_lc = binnedflux_bin2[4], MSE = binnedflux_bin2[5] , total = False)\n",
    "\n",
    "            Xvar_bin2_mean = np.nanmean(Xvar_bin2)\n",
    "            Fvar_bin2_mean = np.nanmean(Fvar_bin2)\n",
    "            \n",
    "            \n",
    "            plot_excess_variance(subdir, df, binnedflux_bin2, Xvar_bin2, XvarErr_bin2, Xvar_bin2_mean, Fvar_bin2, FvarErr_bin2, Fvar_bin2_mean, bin2, sectbysect, group)\n",
    "                  \n",
    "                    \n",
    "            ##############################################################################################################################\n",
    "            ## Plot and save resultant RMS-Flux relation \n",
    "            print(\"\\nCalculating RMS-Flux relation within %s hr and %s hr bins\"%(bin1,bin2))\n",
    "        \n",
    "            idx = np.isfinite(binnedflux_bin1[1]) & np.isfinite(Fvar_bin1)\n",
    "            rms_flux = np.array((binnedflux_bin1[1][idx], Fvar_bin1[idx], FvarErr_bin1[idx]))\n",
    "            \n",
    "            try:\n",
    "                line1 = np.polyfit(rms_flux[0], rms_flux[1], 1)\n",
    "                plt.errorbar(rms_flux[0], rms_flux[1], yerr= rms_flux[2], color='r', label=bin1+'hr bins, α = %.2e'%line1[0], alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                \n",
    "                x1 = np.linspace(rms_flux[0].min(), rms_flux[0].max(), num=200)\n",
    "                plt.plot(x1,linear(x1,*line1), color='r', linestyle='dotted')\n",
    "            except: \n",
    "                try:\n",
    "                    line1 = op.minimize(Min_PDF, [1.,0.], args=(np.array((rms_flux[1],rms_flux[0]),dtype='object'),linear), method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "                    line1 = line1['x']\n",
    "                    \n",
    "                    plt.errorbar(rms_flux[0], rms_flux[1], yerr= rms_flux[2], color='r', label=bin1+'hr bins, α = %.2e'%line1[0], alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                    x1 = np.linspace(rms_flux[0].min(), rms_flux[0].max(), num=200)\n",
    "                    plt.plot(x1,linear(x1,*line1), color='r', linestyle='dotted')\n",
    "                except:    \n",
    "                    line1 = [0.0,0.0]\n",
    "                \n",
    "            \n",
    "\n",
    "            idx = np.isfinite(binnedflux_bin2[1]) & np.isfinite(Fvar_bin2)\n",
    "            rms_flux = np.array((binnedflux_bin2[1][idx], Fvar_bin2[idx], FvarErr_bin2[idx]))\n",
    "\n",
    "            try:\n",
    "                line2 = np.polyfit(rms_flux[0], rms_flux[1], 1)\n",
    "                plt.errorbar(rms_flux[0], rms_flux[1], yerr= rms_flux[2], color='b', label=bin2+'hr bins, α = %.2e'%line2[0], alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                x2 = np.linspace(rms_flux[0].min(), rms_flux[0].max(), num=200)\n",
    "                plt.plot(x2,linear(x2,*line2), color='b', linestyle='dotted')\n",
    "            except: \n",
    "                try:\n",
    "                    line2 = op.minimize(Min_PDF, [1.,0.], args=(np.array((rms_flux[1],rms_flux[0]),dtype='object'),linear), method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "                    line2 = line2['x']\n",
    "                    plt.errorbar(rms_flux[0], rms_flux[1], yerr= rms_flux[2], color='b', label=bin2+'hr bins, α = %.2e'%line2[0], alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                    x2 = np.linspace(rms_flux[0].min(), rms_flux[0].max(), num=200)\n",
    "                    plt.plot(x2,linear(x2,*line2), color='b', linestyle='dotted')\n",
    "                except:    \n",
    "                    line2 = [0.0,0.0]\n",
    "\n",
    "            \n",
    "\n",
    "            try:\n",
    "                plt.xlabel(\"Average Flux of Bin (cts s$^{-1}$)\")\n",
    "                plt.ylabel(\"RMS (cts s$^{-1}$)\")\n",
    "                plt.legend()\n",
    "\n",
    "                plt.title(\"RMS-flux relation\")\n",
    "                plt.savefig(subdir+'/'+target+'_rms_flux_dist.pdf', format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "    #             plt.show()\n",
    "                plt.close()\n",
    "            except:\n",
    "                plt.close()\n",
    "            \n",
    "            ############################################################################################\n",
    "            ############################################################################################\n",
    "            \n",
    "            ## Now a flux-binned version of the same relation\n",
    "            try:\n",
    "                idx = np.isfinite(binnedflux_bin1[1]) & np.isfinite(Fvar_bin1)\n",
    "                rms_flux = np.array((binnedflux_bin1[1][idx], Fvar_bin1[idx], FvarErr_bin1[idx]))\n",
    "\n",
    "                rms_n, rms_bins = np.histogram(rms_flux[0], bins = OptBins(rms_flux[0]), range=(rms_flux[0].min(),rms_flux[0].max()))\n",
    "                bin_center = rms_bins[:-1] + np.diff(rms_bins) / 2\n",
    "\n",
    "                rms_flux_binned = np.array((bin_center, np.zeros(len(bin_center)), np.zeros(len(bin_center))))\n",
    "\n",
    "                for i in range(0,len(rms_bins)-1):\n",
    "                    binleft = rms_bins[i]\n",
    "                    binright = rms_bins[i+1]\n",
    "\n",
    "                    temp_Fvar = []\n",
    "                    temp_err = []\n",
    "\n",
    "                    for j in range(0,len(rms_flux[0])):\n",
    "\n",
    "                        if rms_flux[0][j] >= binleft and rms_flux[0][j] < binright:\n",
    "                            temp_Fvar.append(rms_flux[1][j])\n",
    "                            temp_err.append(rms_flux[2][j])\n",
    "                        elif i == len(rms_bins)-1 and rms_flux[0][j] == rms_flux[0].max():\n",
    "                            temp_Fvar.append(rms_flux[1][j])\n",
    "                            temp_err.append(rms_flux[2][j])\n",
    "\n",
    "                    rms_flux_binned[1][i] = np.nanmean(temp_Fvar)\n",
    "                    rms_flux_binned[2][i] = np.sqrt(np.nansum(np.array(temp_err)**2)/len(temp_err)**2)\n",
    "\n",
    "                try:\n",
    "                    line1 = np.polyfit(rms_flux[0], rms_flux[1], 1)\n",
    "                    plt.errorbar(rms_flux_binned[0], rms_flux_binned[1], yerr= rms_flux_binned[2], color='r', label=bin1+'hr bins, α = %.2e'%line1[0], alpha=0.8, linestyle =\"None\",\\\n",
    "                                 fmt='.', markersize = 8)\n",
    "                    x1 = np.linspace(rms_flux_binned[0].min(), rms_flux_binned[0].max(), num=200)\n",
    "                    plt.plot(x1,linear(x1,*line1), color='r', linestyle='dotted')\n",
    "                except: \n",
    "                    try:\n",
    "                        line1 = op.minimize(Min_PDF, [1.,0.], args=(np.array((rms_flux_binned[1],rms_bins),dtype='object'),linear), method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "                        line1 = line1['x']\n",
    "                        plt.errorbar(rms_flux_binned[0], rms_flux_binned[1], yerr= rms_flux_binned[2], color='r', label=bin1+'hr bins, α = %.2e'%line1[0], alpha=0.8, linestyle =\"None\",\\\n",
    "                                     fmt='.', markersize = 8)\n",
    "                        x1 = np.linspace(rms_flux_binned[0].min(), rms_flux_binned[0].max(), num=200)\n",
    "                        plt.plot(x1,linear(x1,*line1), color='r', linestyle='dotted')\n",
    "                    except:    \n",
    "                        line1 = [0.0,0.0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                idx = np.isfinite(binnedflux_bin2[1]) & np.isfinite(Fvar_bin2)\n",
    "                rms_flux = np.array((binnedflux_bin2[1][idx], Fvar_bin2[idx], FvarErr_bin2[idx]))\n",
    "\n",
    "                rms_n, rms_bins = np.histogram(rms_flux[0], bins = OptBins(rms_flux[0]), range=(rms_flux[0].min(),rms_flux[0].max()))\n",
    "                bin_center = rms_bins[:-1] + np.diff(rms_bins) / 2\n",
    "                \n",
    "                rms_flux_binned = np.array((bin_center, np.zeros(len(bin_center)), np.zeros(len(bin_center))))\n",
    "\n",
    "                for i in range(0,len(rms_bins)-1):\n",
    "                    binleft = rms_bins[i]\n",
    "                    binright = rms_bins[i+1]\n",
    "\n",
    "                    temp_Fvar = []\n",
    "                    temp_err = []\n",
    "\n",
    "                    for j in range(0,len(rms_flux[0])):\n",
    "\n",
    "                        if rms_flux[0][j] >= binleft and rms_flux[0][j] < binright:\n",
    "                            temp_Fvar.append(rms_flux[1][j])\n",
    "                            temp_err.append(rms_flux[2][j])\n",
    "                        elif i == len(rms_bins)-1 and rms_flux[0][j] == rms_flux[0].max():\n",
    "                            temp_Fvar.append(rms_flux[1][j])\n",
    "                            temp_err.append(rms_flux[2][j])\n",
    "\n",
    "                    rms_flux_binned[1][i] = np.nanmean(temp_Fvar)\n",
    "                    rms_flux_binned[2][i] = np.sqrt(np.nansum(np.array(temp_err)**2)/len(temp_err)**2)\n",
    "\n",
    "                try:\n",
    "                    line2 = np.polyfit(rms_flux[0], rms_flux[1], 1)\n",
    "                    plt.errorbar(rms_flux_binned[0], rms_flux_binned[1], yerr= rms_flux_binned[2], color='b', label=bin2+'hr bins, α = %.2e'%line2[0], alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                    x2 = np.linspace(rms_flux_binned[0].min(), rms_flux_binned[0].max(), num=200)\n",
    "                    plt.plot(x2,linear(x2,*line2), color='b', linestyle='dotted')\n",
    "                except: \n",
    "                    try:\n",
    "                        line2 = op.minimize(Min_PDF, [1.,0.], args=(np.array((rms_flux_binned[1],rms_bins),dtype='object'),linear), method='L-BFGS-B', options={'gtol':1e-6,'disp':False})\n",
    "                        line2 = line2['x']\n",
    "                        plt.errorbar(rms_flux_binned[0], rms_flux_binned[1], yerr= rms_flux_binned[2], color='b', label=bin2+'hr bins, α = %.2e'%line2[0], alpha=0.8, linestyle =\"None\", fmt='.', markersize = 8)\n",
    "                        x2 = np.linspace(rms_flux_binned[0].min(), rms_flux_binned[0].max(), num=200)\n",
    "                        plt.plot(x2,linear(x2,*line2), color='b', linestyle='dotted')\n",
    "                    except:    \n",
    "                        line2 = [0.0,0.0]\n",
    "\n",
    "                try:\n",
    "                    plt.xlabel(\"Average Flux of Bin (cts s$^{-1}$)\")\n",
    "                    plt.ylabel(\"RMS (cts s$^{-1}$)\")\n",
    "                    plt.legend()\n",
    "\n",
    "                    plt.title(\"RMS-flux relation\")\n",
    "                    plt.savefig(subdir+'/'+target+'_rms_flux_binned_dist.pdf', format = 'pdf',bbox_inches='tight')\n",
    "\n",
    "        #             plt.show()\n",
    "                    plt.close()\n",
    "                except:\n",
    "                    plt.close()\n",
    "                    \n",
    "                    \n",
    "            except:\n",
    "                print(\"\\nCould not make figures for binned rms-flux relation.\\n\")\n",
    "                \n",
    "                \n",
    "            \n",
    "#######################################################################################\n",
    " ## Excess variance and fractional rms amplitude calculations for itotal light curve\n",
    "            print(\"\\nCalculating excess variance of full light curves\")\n",
    "            \n",
    "\n",
    "            NXvar_reg, Fvar_reg, NXvarErr_reg, FvarErr_reg = excess_variance(uninterp_df[0],uninterp_df[1],uninterp_df[2])\n",
    " \n",
    "            NXvar_bin1, Fvar_bin1, NXvarErr_bin1, FvarErr_bin1 = excess_variance(binnedflux_bin1[0],binnedflux_bin1[1],binnedflux_bin1[2])\n",
    "\n",
    "            NXvar_bin2, Fvar_bin2, NXvarErr_bin2, FvarErr_bin2 = excess_variance(binnedflux_bin2[0],binnedflux_bin2[1],binnedflux_bin2[2])\n",
    "        \n",
    "        \n",
    "#######################################################################################\n",
    "##Calculate subsequent flux distributions\n",
    "                        \n",
    "            delflux_raw = [y for x,y in np.column_stack((np.diff(raw_df[0]),np.diff(raw_df[1])))\\\n",
    "                           if x > 0.02 and x < 0.0209 ]\n",
    "\n",
    "\n",
    "            delflux_reg = [y for x,y in np.column_stack((np.diff(uninterp_df[0]),np.diff(uninterp_df[1])))\\\n",
    "                           if x > 0.02 and x < 0.0209 ]\n",
    "\n",
    "            \n",
    "            delflux_bin1 = [y for x,y in np.column_stack((np.diff(binnedflux_bin1[0]),np.diff(binnedflux_bin1[1])))\\\n",
    "                           if x > 0.1 and x < 0.3 ]\n",
    "\n",
    "            delflux_bin2 = [y for x,y in np.column_stack((np.diff(binnedflux_bin2[0]),np.diff(binnedflux_bin2[1])))\\\n",
    "                           if x > 0.3 and x < 0.7 ]\n",
    "            \n",
    "\n",
    "            print(\"\\nFitting histograms of change in flux data\")\n",
    "            for i in range(4,8):\n",
    "                if i == 4 and raw == True:\n",
    "                    fit_raw_stdev, delflux_raw_mean, delflux_raw_min, delflux_raw_max, delflux_raw_bins = hist_and_fit(delflux_raw,i,subdir,target,sectbysect,group)\n",
    "                if i == 5:\n",
    "                    fit_reg_stdev, delflux_reg_mean, delflux_reg_min, delflux_reg_max, delflux_reg_bins = hist_and_fit(delflux_reg,i,subdir,target,sectbysect,group)\n",
    "                if i == 6:\n",
    "                    fit_bin1_stdev, delflux_bin1_mean, delflux_bin1_min, delflux_bin1_max, delflux_bin1_bins = hist_and_fit(delflux_bin1,i,subdir,target,sectbysect,group,bin1=bin1,bin2=bin2)\n",
    "                if i == 7:\n",
    "                    fit_bin2_stdev, delflux_bin2_mean, delflux_bin2_min, delflux_bin2_max, delflux_bin2_bins = hist_and_fit(delflux_bin2,i,subdir,target,sectbysect,group,bin1=bin1,bin2=bin2)\n",
    "                \n",
    "                \n",
    "#######################################################################################\n",
    "## Find the chi-squared per degree of freedom (Sesar 2007)\n",
    "            print(\"\\nCalculating chi-squared/dof\")\n",
    "            mean_dif = np.subtract(uninterp_df[1],np.nanmean(uninterp_df[1]))\n",
    "            chi2_dof = (len(uninterp_df[1])-1)**-1 * np.sum(mean_dif**2/uninterp_df[2]**2)\n",
    "\n",
    "            chi2, dof, chi2_dof = chisquare_per_dof(uninterp_df[1],np.mean(uninterp_df[1]),uninterp_df[2])\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "#######################################################################################\n",
    "## Write and save results\n",
    "            print(\"\\nSaving data\")\n",
    "            if sectbysect == True:\n",
    "                target_name = target+' sectors '+group\n",
    "            else:\n",
    "                target_name = target\n",
    "           \n",
    "            if raw == True:\n",
    "                row = [target_name, flux_raw_mean, lc_raw_stdev, delflux_raw_mean, fit_raw_stdev,\\\n",
    "                    flux_reg_mean, flux_bin1_mean, flux_bin2_mean,\\\n",
    "                       lc_reg_stdev, lc_bin1_stdev, lc_bin2_stdev,\\\n",
    "                           delflux_reg_mean, delflux_bin1_mean, delflux_bin2_mean,\\\n",
    "                               fit_reg_stdev, fit_bin1_stdev, fit_bin2_stdev,\\\n",
    "                                    NXvar_reg, NXvarErr_reg, NXvar_bin1, NXvarErr_bin1, NXvar_bin2, NXvarErr_reg,\\\n",
    "                                        Fvar_reg, FvarErr_reg, Fvar_bin1, FvarErr_bin1, Fvar_bin2, FvarErr_bin2,\\\n",
    "                                            tau_inc_min, delt_inc_min, tau_dec_min, delt_dec_min,\\\n",
    "                                                chi2, dof, chi2_dof]\n",
    "            \n",
    "            if raw == False:\n",
    "                row = [target, flux_reg_mean, flux_bin1_mean, flux_bin2_mean,\\\n",
    "                   lc_reg_stdev, lc_bin1_stdev, lc_bin2_stdev,\\\n",
    "                       delflux_reg_mean, delflux_bin1_mean, delflux_bin2_mean,\\\n",
    "                           fit_reg_stdev,fit_bin1_stdev, fit_bin2_stdev,\\\n",
    "                                Xvar_reg, Xvar_bin1_mean, Xvar_bin2_mean,\\\n",
    "                                    Fvar_reg, Fvar_bin1_mean, Fvar_bin2_mean,\n",
    "                                        tau_inc_min, delt_inc_min, tau_dec_min, delt_dec_min,\\\n",
    "                                           chi2, dof, chi2_dof]\n",
    "\n",
    "            writer.writerow(row)\n",
    "\n",
    "            lc_data.close()\n",
    "            print(\"\\nMoving to next object\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47fefb-b156-4c88-8655-ea7683953d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample == \"analysis\":\n",
    "    results = '/users/rdingler/AGNstudy/LightCurves/Analysis/LC_variability_analysis.csv'\n",
    "if sample == \"removed\":\n",
    "    results = '/users/rdingler/AGNstudy/LightCurves/Removed_sample/LC_variability_rmv.csv'\n",
    "\n",
    "read_df = pd.read_csv(results)\n",
    "\n",
    "if sample == \"analysis\":\n",
    "    read_df.to_excel('/users/rdingler/AGNstudy/LightCurves/Analysis/LC_variability_analysis.xlsx',index=False) \n",
    "if sample == \"removed\":\n",
    "    read_df.to_excel('/users/rdingler/AGNstudy/LightCurves/Removed_sample/LC_variability_rmv.xlsx',index=False)\n",
    "    \n",
    "if adj == True:            \n",
    "    \n",
    "    ## User-specified modicfications to data for potential ease of viewing\n",
    "    print(\"\\nAdjusting final data form\")            \n",
    "    \n",
    "\n",
    "    for x in [y for y in read_df.columns.values if y != 'Target']:\n",
    "\n",
    "        idx = np.isfinite(np.array(read_df[x], dtype = 'float64'))\n",
    "        values = np.abs(np.array(read_df[x][idx], dtype = 'float64'))\n",
    "\n",
    "        if x == 'σ^2_NXS(unbinned)' or x == 'err(σ^2_NXS)(unbinned)' or x == 'σ^2_NXS('+str(bin1)+'hr)' or x == 'err(σ^2_NXS)('+str(bin1)+'hr)' or x == 'σ^2_NXS('+str(bin2)+'hr)' or x == 'err(σ^2_NXS)('+str(bin2)+'hr)':\n",
    "\n",
    "            read_df[x] = np.round(np.log10(read_df[x]),decimals = 4)\n",
    "            new_column = '$log('+x+')'\n",
    "            read_df = read_df.rename(columns={x:new_column})\n",
    "        else:\n",
    "            mean_median_middle = np.nanmean([np.nanmedian(np.log10([x for x in values if x!=0])),np.nanmean(np.log10([x for x in values if x!=0]))])\n",
    "            power = int(mean_median_middle + 0.5)\n",
    "\n",
    "            if power <= 1 and power >= -1:\n",
    "                read_df[x] = np.round(read_df[x],decimals = 4)\n",
    "            else:\n",
    "                read_df[x] = np.round(read_df[x]/(10**power),decimals = 4)\n",
    "                new_column = x +' [*10^'+str(power)+']'\n",
    "                read_df = read_df.rename(columns={x:new_column})\n",
    "\n",
    "\n",
    "    if sample == \"analysis\":\n",
    "        read_df.to_csv('/users/rdingler/AGNstudy/LightCurves/Analysis/LC_variability_analysis_adjusted.csv',index=False)\n",
    "        read_df.to_excel('/users/rdingler/AGNstudy/LightCurves/Analysis/LC_variability_analysis_adjusted.xlsx',index=False)\n",
    "\n",
    "    if sample == \"removed\":\n",
    "        read_df.to_csv('/users/rdingler/AGNstudy/LightCurves/Removed_sample/LC_variability_rmv_adjusted.csv',index=False)\n",
    "        read_df.to_excel('/users/rdingler/AGNstudy/LightCurves/Removed_sample/LC_variability_rmv_adjusted.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d5e063-8791-44ab-b9a0-c2bbb1789876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
